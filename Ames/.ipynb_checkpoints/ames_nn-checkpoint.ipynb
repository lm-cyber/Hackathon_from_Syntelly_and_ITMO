{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5622f572-8bc1-4abb-98d2-6ba9816047d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4d327b-cb46-4d8c-be4d-3474c731c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('/data/ames_cat_boost/df_ames_train.csv')\n",
    "df_t = pd.read_csv('/data/ames_cat_boost/df_ames_test.csv')\n",
    "df_v = pd.read_csv('/data/ames_cat_boost/df_ames_valid.csv')\n",
    "x = df_tr.drop(['y','w','ids'],axis=1)\n",
    "y = df_tr['y']\n",
    "xt = df_t.drop(['y','w','ids'],axis=1)\n",
    "x_smiles = df_t['ids'].to_numpy()\n",
    "\n",
    "yt = df_t['y']\n",
    "xv = df_v.drop(['y','w','ids'],axis=1)\n",
    "\n",
    "yv = df_v['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b9a3f1-b1ee-4b79-bc4b-3bda7c8c44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len=len(x.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31267d2-3194-4dce-ace3-91255c80eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s):\n",
    "    K.clear_session()\n",
    "    seed_value= s\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(seed_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f237cbf6-a455-4066-81fe-63f3922bad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82938259-c61a-4ac6-8c9d-53188c284c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_len, len1, len2, len3, regular, activ_f,momentum_batch_norm):\n",
    "\n",
    "    #dropout\n",
    "    prob_h1 = 0.25\n",
    "    prob_h2 = 0.15\n",
    "    prob_h3 = 0.1\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(input_len), dtype='float32'))\n",
    "    model.add(keras.layers.Dense(len1, input_dim=input_len, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h1))\n",
    "\n",
    "    model.add(keras.layers.Dense(len2, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h2))\n",
    "    \n",
    "    model.add(keras.layers.Dense(len2, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h2))\n",
    "\n",
    "    model.add(keras.layers.Dense(len3, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h2))\n",
    "\n",
    "    model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd64e6e-dbd1-4714-930d-343dfc3e201a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 219,361\n",
      "Trainable params: 218,741\n",
      "Non-trainable params: 620\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reg = tf.keras.regularizers.l1_l2(0.0008,0.0008)\n",
    "model = build_model(input_len,200,50,10,reg,'relu',0.9)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a5978f-a399-400c-8e83-ff066bc5fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(0.0001)\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['AUC'])\n",
    "# # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef972fdc-0557-4fc4-986a-471eaf773c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 219,361\n",
      "Trainable params: 218,741\n",
      "Non-trainable params: 620\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9bb1ad9-f87e-43e5-a815-06f94091c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_history(hist):\n",
    "    acc = hist.history['AUC']\n",
    "    val_acc = hist.history['val_AUC']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, '-', label='AUC')\n",
    "    plt.plot(epochs, val_acc, ':', label='Validation AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c00f92-dc05-4254-81df-69d15bc845b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_delta_val = 0.0005\n",
    "patience_val = 1000\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=min_delta_val, \n",
    "                              patience=patience_val, \n",
    "                              verbose=0, \n",
    "                              mode='min',\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fbcc1b9-28e5-4d8c-adc5-16eb09871c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5934 samples, validate on 742 samples\n",
      "Epoch 1/500\n",
      "5520/5934 [==========================>...] - ETA: 0s - loss: 8.0680 - AUC: 0.4586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5934/5934 [==============================] - 2s 394us/sample - loss: 8.0677 - AUC: 0.4603 - val_loss: 7.9233 - val_AUC: 0.4827\n",
      "Epoch 2/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 8.0078 - AUC: 0.4842 - val_loss: 7.9024 - val_AUC: 0.4897\n",
      "Epoch 3/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 7.9717 - AUC: 0.4986 - val_loss: 7.8646 - val_AUC: 0.5028\n",
      "Epoch 4/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 7.9550 - AUC: 0.5006 - val_loss: 7.8385 - val_AUC: 0.5194\n",
      "Epoch 5/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 7.9202 - AUC: 0.5106 - val_loss: 7.8105 - val_AUC: 0.5296\n",
      "Epoch 6/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 7.8711 - AUC: 0.5280 - val_loss: 7.7641 - val_AUC: 0.5444\n",
      "Epoch 7/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 7.8324 - AUC: 0.5461 - val_loss: 7.7456 - val_AUC: 0.5522\n",
      "Epoch 8/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 7.8143 - AUC: 0.5442 - val_loss: 7.7233 - val_AUC: 0.5654\n",
      "Epoch 9/500\n",
      "5934/5934 [==============================] - 1s 134us/sample - loss: 7.7800 - AUC: 0.5612 - val_loss: 7.7004 - val_AUC: 0.5683\n",
      "Epoch 10/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 7.7497 - AUC: 0.5724 - val_loss: 7.6682 - val_AUC: 0.5813\n",
      "Epoch 11/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 7.7300 - AUC: 0.5743 - val_loss: 7.6608 - val_AUC: 0.5850\n",
      "Epoch 12/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 7.6853 - AUC: 0.5941 - val_loss: 7.6216 - val_AUC: 0.5900\n",
      "Epoch 13/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 7.6652 - AUC: 0.5956 - val_loss: 7.6218 - val_AUC: 0.5928\n",
      "Epoch 14/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 7.6471 - AUC: 0.5969 - val_loss: 7.5914 - val_AUC: 0.5991\n",
      "Epoch 15/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 7.6340 - AUC: 0.6048 - val_loss: 7.5680 - val_AUC: 0.6097\n",
      "Epoch 16/500\n",
      "5934/5934 [==============================] - 1s 127us/sample - loss: 7.5950 - AUC: 0.6191 - val_loss: 7.5584 - val_AUC: 0.6110\n",
      "Epoch 17/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 7.5706 - AUC: 0.6229 - val_loss: 7.5357 - val_AUC: 0.6225\n",
      "Epoch 18/500\n",
      "5934/5934 [==============================] - 1s 129us/sample - loss: 7.5599 - AUC: 0.6234 - val_loss: 7.5156 - val_AUC: 0.6225\n",
      "Epoch 19/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 7.5255 - AUC: 0.6339 - val_loss: 7.4924 - val_AUC: 0.6207\n",
      "Epoch 20/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 7.5144 - AUC: 0.6326 - val_loss: 7.4710 - val_AUC: 0.6368\n",
      "Epoch 21/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 7.4775 - AUC: 0.6482 - val_loss: 7.4456 - val_AUC: 0.6375\n",
      "Epoch 22/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 7.4698 - AUC: 0.6402 - val_loss: 7.4349 - val_AUC: 0.6449\n",
      "Epoch 23/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 7.4402 - AUC: 0.6561 - val_loss: 7.4173 - val_AUC: 0.6506\n",
      "Epoch 24/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 7.4084 - AUC: 0.6704 - val_loss: 7.3951 - val_AUC: 0.6447\n",
      "Epoch 25/500\n",
      "5934/5934 [==============================] - 1s 125us/sample - loss: 7.3983 - AUC: 0.6666 - val_loss: 7.3812 - val_AUC: 0.6514\n",
      "Epoch 26/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 7.3834 - AUC: 0.6680 - val_loss: 7.3692 - val_AUC: 0.6588\n",
      "Epoch 27/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 7.3424 - AUC: 0.6839 - val_loss: 7.3503 - val_AUC: 0.6583\n",
      "Epoch 28/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 7.3412 - AUC: 0.6713 - val_loss: 7.3230 - val_AUC: 0.6692\n",
      "Epoch 29/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 7.3143 - AUC: 0.6908 - val_loss: 7.3101 - val_AUC: 0.6616\n",
      "Epoch 30/500\n",
      "5934/5934 [==============================] - 1s 128us/sample - loss: 7.2840 - AUC: 0.7000 - val_loss: 7.2919 - val_AUC: 0.6684\n",
      "Epoch 31/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 7.2729 - AUC: 0.6943 - val_loss: 7.2791 - val_AUC: 0.6703\n",
      "Epoch 32/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 7.2453 - AUC: 0.7022 - val_loss: 7.2562 - val_AUC: 0.6731\n",
      "Epoch 33/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 7.2349 - AUC: 0.6990 - val_loss: 7.2386 - val_AUC: 0.6716\n",
      "Epoch 34/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 7.2087 - AUC: 0.7074 - val_loss: 7.2219 - val_AUC: 0.6854\n",
      "Epoch 35/500\n",
      "5934/5934 [==============================] - 1s 105us/sample - loss: 7.1715 - AUC: 0.7225 - val_loss: 7.2013 - val_AUC: 0.6830\n",
      "Epoch 36/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 7.1580 - AUC: 0.7194 - val_loss: 7.1818 - val_AUC: 0.6885\n",
      "Epoch 37/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 7.1468 - AUC: 0.7185 - val_loss: 7.1733 - val_AUC: 0.6906\n",
      "Epoch 38/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 7.1244 - AUC: 0.7224 - val_loss: 7.1494 - val_AUC: 0.6900\n",
      "Epoch 39/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 7.1185 - AUC: 0.7179 - val_loss: 7.1364 - val_AUC: 0.6923\n",
      "Epoch 40/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 7.0907 - AUC: 0.7241 - val_loss: 7.1086 - val_AUC: 0.7007\n",
      "Epoch 41/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 7.0572 - AUC: 0.7388 - val_loss: 7.0930 - val_AUC: 0.7014\n",
      "Epoch 42/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 7.0477 - AUC: 0.7338 - val_loss: 7.0749 - val_AUC: 0.7039\n",
      "Epoch 43/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 7.0199 - AUC: 0.7424 - val_loss: 7.0597 - val_AUC: 0.7030\n",
      "Epoch 44/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 6.9901 - AUC: 0.7509 - val_loss: 7.0392 - val_AUC: 0.7028\n",
      "Epoch 45/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 6.9846 - AUC: 0.7435 - val_loss: 7.0222 - val_AUC: 0.7130\n",
      "Epoch 46/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 6.9661 - AUC: 0.7450 - val_loss: 7.0067 - val_AUC: 0.7071\n",
      "Epoch 47/500\n",
      "5934/5934 [==============================] - 1s 132us/sample - loss: 6.9502 - AUC: 0.7455 - val_loss: 6.9926 - val_AUC: 0.7051\n",
      "Epoch 48/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 6.9048 - AUC: 0.7652 - val_loss: 6.9721 - val_AUC: 0.7053\n",
      "Epoch 49/500\n",
      "5934/5934 [==============================] - 1s 127us/sample - loss: 6.8967 - AUC: 0.7631 - val_loss: 6.9576 - val_AUC: 0.7094\n",
      "Epoch 50/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 6.8783 - AUC: 0.7641 - val_loss: 6.9394 - val_AUC: 0.7121\n",
      "Epoch 51/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 6.8569 - AUC: 0.7646 - val_loss: 6.9137 - val_AUC: 0.7243\n",
      "Epoch 52/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 6.8229 - AUC: 0.7772 - val_loss: 6.8978 - val_AUC: 0.7143\n",
      "Epoch 53/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 6.8197 - AUC: 0.7691 - val_loss: 6.8807 - val_AUC: 0.7169\n",
      "Epoch 54/500\n",
      "5934/5934 [==============================] - 1s 128us/sample - loss: 6.7988 - AUC: 0.7735 - val_loss: 6.8603 - val_AUC: 0.7255\n",
      "Epoch 55/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 6.7764 - AUC: 0.7768 - val_loss: 6.8431 - val_AUC: 0.7231\n",
      "Epoch 56/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 6.7566 - AUC: 0.7756 - val_loss: 6.8250 - val_AUC: 0.7250\n",
      "Epoch 57/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 6.7447 - AUC: 0.7715 - val_loss: 6.8074 - val_AUC: 0.7255\n",
      "Epoch 58/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 6.7205 - AUC: 0.7803 - val_loss: 6.7941 - val_AUC: 0.7238\n",
      "Epoch 59/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 6.6999 - AUC: 0.7831 - val_loss: 6.7737 - val_AUC: 0.7191\n",
      "Epoch 60/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 6.6776 - AUC: 0.7870 - val_loss: 6.7494 - val_AUC: 0.7333\n",
      "Epoch 61/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 6.6600 - AUC: 0.7836 - val_loss: 6.7385 - val_AUC: 0.7273\n",
      "Epoch 62/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 6.6346 - AUC: 0.7891 - val_loss: 6.7099 - val_AUC: 0.7368\n",
      "Epoch 63/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 6.6146 - AUC: 0.7921 - val_loss: 6.6961 - val_AUC: 0.7341\n",
      "Epoch 64/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 6.5931 - AUC: 0.7966 - val_loss: 6.6843 - val_AUC: 0.7313\n",
      "Epoch 65/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 6.5772 - AUC: 0.7943 - val_loss: 6.6609 - val_AUC: 0.7369\n",
      "Epoch 66/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 6.5584 - AUC: 0.7959 - val_loss: 6.6418 - val_AUC: 0.7375\n",
      "Epoch 67/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 6.5241 - AUC: 0.8067 - val_loss: 6.6315 - val_AUC: 0.7354\n",
      "Epoch 68/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 6.5164 - AUC: 0.7988 - val_loss: 6.6025 - val_AUC: 0.7415\n",
      "Epoch 69/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 6.4915 - AUC: 0.8050 - val_loss: 6.5830 - val_AUC: 0.7440\n",
      "Epoch 70/500\n",
      "5934/5934 [==============================] - 1s 101us/sample - loss: 6.4768 - AUC: 0.8004 - val_loss: 6.5625 - val_AUC: 0.7442\n",
      "Epoch 71/500\n",
      "5934/5934 [==============================] - 1s 106us/sample - loss: 6.4472 - AUC: 0.8110 - val_loss: 6.5460 - val_AUC: 0.7439\n",
      "Epoch 72/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 6.4244 - AUC: 0.8160 - val_loss: 6.5312 - val_AUC: 0.7443\n",
      "Epoch 73/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 6.4169 - AUC: 0.8048 - val_loss: 6.5060 - val_AUC: 0.7429\n",
      "Epoch 74/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 6.3891 - AUC: 0.8151 - val_loss: 6.4905 - val_AUC: 0.7422\n",
      "Epoch 75/500\n",
      "5934/5934 [==============================] - 1s 105us/sample - loss: 6.3691 - AUC: 0.8151 - val_loss: 6.4752 - val_AUC: 0.7474\n",
      "Epoch 76/500\n",
      "5934/5934 [==============================] - 1s 103us/sample - loss: 6.3356 - AUC: 0.8281 - val_loss: 6.4558 - val_AUC: 0.7480\n",
      "Epoch 77/500\n",
      "5934/5934 [==============================] - 1s 104us/sample - loss: 6.3271 - AUC: 0.8179 - val_loss: 6.4344 - val_AUC: 0.7459\n",
      "Epoch 78/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 6.3069 - AUC: 0.8198 - val_loss: 6.4150 - val_AUC: 0.7516\n",
      "Epoch 79/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 6.2840 - AUC: 0.8240 - val_loss: 6.3965 - val_AUC: 0.7496\n",
      "Epoch 80/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 6.2633 - AUC: 0.8262 - val_loss: 6.3818 - val_AUC: 0.7566\n",
      "Epoch 81/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 6.2391 - AUC: 0.8314 - val_loss: 6.3578 - val_AUC: 0.7535\n",
      "Epoch 82/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 6.2207 - AUC: 0.8307 - val_loss: 6.3369 - val_AUC: 0.7550\n",
      "Epoch 83/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 6.1869 - AUC: 0.8402 - val_loss: 6.3231 - val_AUC: 0.7530\n",
      "Epoch 84/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 6.1814 - AUC: 0.8297 - val_loss: 6.3114 - val_AUC: 0.7502\n",
      "Epoch 85/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 6.1524 - AUC: 0.8381 - val_loss: 6.2767 - val_AUC: 0.7604\n",
      "Epoch 86/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 6.1388 - AUC: 0.8328 - val_loss: 6.2637 - val_AUC: 0.7592\n",
      "Epoch 87/500\n",
      "5934/5934 [==============================] - 1s 125us/sample - loss: 6.1182 - AUC: 0.8354 - val_loss: 6.2383 - val_AUC: 0.7584\n",
      "Epoch 88/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 6.0898 - AUC: 0.8422 - val_loss: 6.2162 - val_AUC: 0.7599\n",
      "Epoch 89/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 6.0694 - AUC: 0.8452 - val_loss: 6.2074 - val_AUC: 0.7575\n",
      "Epoch 90/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 6.0581 - AUC: 0.8372 - val_loss: 6.1873 - val_AUC: 0.7632\n",
      "Epoch 91/500\n",
      "5934/5934 [==============================] - 1s 128us/sample - loss: 6.0422 - AUC: 0.8378 - val_loss: 6.1606 - val_AUC: 0.7646\n",
      "Epoch 92/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 5.9951 - AUC: 0.8581 - val_loss: 6.1441 - val_AUC: 0.7630\n",
      "Epoch 93/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 5.9886 - AUC: 0.8479 - val_loss: 6.1375 - val_AUC: 0.7609\n",
      "Epoch 94/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 5.9683 - AUC: 0.8486 - val_loss: 6.1190 - val_AUC: 0.7613\n",
      "Epoch 95/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 5.9508 - AUC: 0.8496 - val_loss: 6.0952 - val_AUC: 0.7620\n",
      "Epoch 96/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 5.9286 - AUC: 0.8514 - val_loss: 6.0688 - val_AUC: 0.7621\n",
      "Epoch 97/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 5.9102 - AUC: 0.8498 - val_loss: 6.0505 - val_AUC: 0.7620\n",
      "Epoch 98/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 5.8839 - AUC: 0.8563 - val_loss: 6.0345 - val_AUC: 0.7630\n",
      "Epoch 99/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 5.8656 - AUC: 0.8548 - val_loss: 6.0056 - val_AUC: 0.7700\n",
      "Epoch 100/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 5.8361 - AUC: 0.8608 - val_loss: 5.9883 - val_AUC: 0.7725\n",
      "Epoch 101/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 5.8234 - AUC: 0.8560 - val_loss: 5.9735 - val_AUC: 0.7725\n",
      "Epoch 102/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 5.8065 - AUC: 0.8552 - val_loss: 5.9520 - val_AUC: 0.7691\n",
      "Epoch 103/500\n",
      "5934/5934 [==============================] - 1s 104us/sample - loss: 5.7731 - AUC: 0.8641 - val_loss: 5.9331 - val_AUC: 0.7695\n",
      "Epoch 104/500\n",
      "5934/5934 [==============================] - 1s 105us/sample - loss: 5.7576 - AUC: 0.8623 - val_loss: 5.9084 - val_AUC: 0.7714\n",
      "Epoch 105/500\n",
      "5934/5934 [==============================] - 1s 106us/sample - loss: 5.7260 - AUC: 0.8727 - val_loss: 5.8954 - val_AUC: 0.7717\n",
      "Epoch 106/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 5.7114 - AUC: 0.8686 - val_loss: 5.8823 - val_AUC: 0.7731\n",
      "Epoch 107/500\n",
      "5934/5934 [==============================] - 1s 104us/sample - loss: 5.7016 - AUC: 0.8638 - val_loss: 5.8560 - val_AUC: 0.7741\n",
      "Epoch 108/500\n",
      "5934/5934 [==============================] - 1s 105us/sample - loss: 5.6789 - AUC: 0.8630 - val_loss: 5.8471 - val_AUC: 0.7726\n",
      "Epoch 109/500\n",
      "5934/5934 [==============================] - 1s 103us/sample - loss: 5.6539 - AUC: 0.8677 - val_loss: 5.8190 - val_AUC: 0.7739\n",
      "Epoch 110/500\n",
      "5934/5934 [==============================] - 1s 103us/sample - loss: 5.6320 - AUC: 0.8690 - val_loss: 5.8018 - val_AUC: 0.7720\n",
      "Epoch 111/500\n",
      "5934/5934 [==============================] - 1s 105us/sample - loss: 5.6036 - AUC: 0.8756 - val_loss: 5.7795 - val_AUC: 0.7773\n",
      "Epoch 112/500\n",
      "5934/5934 [==============================] - 1s 106us/sample - loss: 5.5906 - AUC: 0.8713 - val_loss: 5.7597 - val_AUC: 0.7768\n",
      "Epoch 113/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 5.5709 - AUC: 0.8741 - val_loss: 5.7331 - val_AUC: 0.7776\n",
      "Epoch 114/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 5.5555 - AUC: 0.8717 - val_loss: 5.7115 - val_AUC: 0.7807\n",
      "Epoch 115/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 5.5251 - AUC: 0.8800 - val_loss: 5.7025 - val_AUC: 0.7778\n",
      "Epoch 116/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 5.5140 - AUC: 0.8740 - val_loss: 5.6849 - val_AUC: 0.7826\n",
      "Epoch 117/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 5.4869 - AUC: 0.8782 - val_loss: 5.6693 - val_AUC: 0.7747\n",
      "Epoch 118/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 5.4647 - AUC: 0.8802 - val_loss: 5.6596 - val_AUC: 0.7783\n",
      "Epoch 119/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 5.4417 - AUC: 0.8823 - val_loss: 5.6233 - val_AUC: 0.7803\n",
      "Epoch 120/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 5.4275 - AUC: 0.8791 - val_loss: 5.6098 - val_AUC: 0.7807\n",
      "Epoch 121/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 5.4024 - AUC: 0.8854 - val_loss: 5.5798 - val_AUC: 0.7818\n",
      "Epoch 122/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 5.3816 - AUC: 0.8842 - val_loss: 5.5603 - val_AUC: 0.7827\n",
      "Epoch 123/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 5.3620 - AUC: 0.8857 - val_loss: 5.5388 - val_AUC: 0.7878\n",
      "Epoch 124/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 5.3382 - AUC: 0.8889 - val_loss: 5.5331 - val_AUC: 0.7850\n",
      "Epoch 125/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 5.3256 - AUC: 0.8842 - val_loss: 5.5166 - val_AUC: 0.7796\n",
      "Epoch 126/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 5.3072 - AUC: 0.8846 - val_loss: 5.5030 - val_AUC: 0.7856\n",
      "Epoch 127/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 5.2933 - AUC: 0.8818 - val_loss: 5.4713 - val_AUC: 0.7844\n",
      "Epoch 128/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 5.2618 - AUC: 0.8904 - val_loss: 5.4622 - val_AUC: 0.7828\n",
      "Epoch 129/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 5.2449 - AUC: 0.8889 - val_loss: 5.4369 - val_AUC: 0.7847\n",
      "Epoch 130/500\n",
      "5934/5934 [==============================] - 1s 125us/sample - loss: 5.2220 - AUC: 0.8907 - val_loss: 5.4323 - val_AUC: 0.7832\n",
      "Epoch 131/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 5.2008 - AUC: 0.8918 - val_loss: 5.4116 - val_AUC: 0.7832\n",
      "Epoch 132/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 5.1806 - AUC: 0.8939 - val_loss: 5.3839 - val_AUC: 0.7842\n",
      "Epoch 133/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 5.1560 - AUC: 0.8968 - val_loss: 5.3647 - val_AUC: 0.7892\n",
      "Epoch 134/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 5.1429 - AUC: 0.8937 - val_loss: 5.3382 - val_AUC: 0.7872\n",
      "Epoch 135/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 5.1114 - AUC: 0.9020 - val_loss: 5.3271 - val_AUC: 0.7858\n",
      "Epoch 136/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 5.1050 - AUC: 0.8952 - val_loss: 5.3017 - val_AUC: 0.7903\n",
      "Epoch 137/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 5.0797 - AUC: 0.8987 - val_loss: 5.2947 - val_AUC: 0.7893\n",
      "Epoch 138/500\n",
      "5934/5934 [==============================] - 1s 129us/sample - loss: 5.0561 - AUC: 0.9008 - val_loss: 5.2751 - val_AUC: 0.7885\n",
      "Epoch 139/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 5.0338 - AUC: 0.9021 - val_loss: 5.2418 - val_AUC: 0.7934\n",
      "Epoch 140/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 5.0158 - AUC: 0.9033 - val_loss: 5.2293 - val_AUC: 0.7889\n",
      "Epoch 141/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 5.0051 - AUC: 0.8975 - val_loss: 5.2120 - val_AUC: 0.7914\n",
      "Epoch 142/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.9813 - AUC: 0.9018 - val_loss: 5.1857 - val_AUC: 0.7946\n",
      "Epoch 143/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.9687 - AUC: 0.8982 - val_loss: 5.1908 - val_AUC: 0.7891\n",
      "Epoch 144/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 4.9376 - AUC: 0.9057 - val_loss: 5.1535 - val_AUC: 0.7957\n",
      "Epoch 145/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 4.9138 - AUC: 0.9086 - val_loss: 5.1418 - val_AUC: 0.7903\n",
      "Epoch 146/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.9003 - AUC: 0.9052 - val_loss: 5.1169 - val_AUC: 0.7929\n",
      "Epoch 147/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 4.8816 - AUC: 0.9053 - val_loss: 5.1157 - val_AUC: 0.7945\n",
      "Epoch 148/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 4.8678 - AUC: 0.9030 - val_loss: 5.0886 - val_AUC: 0.7930\n",
      "Epoch 149/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 4.8455 - AUC: 0.9057 - val_loss: 5.0659 - val_AUC: 0.7938\n",
      "Epoch 150/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.8243 - AUC: 0.9074 - val_loss: 5.0494 - val_AUC: 0.7969\n",
      "Epoch 151/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.7987 - AUC: 0.9113 - val_loss: 5.0293 - val_AUC: 0.7966\n",
      "Epoch 152/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 4.7819 - AUC: 0.9112 - val_loss: 5.0137 - val_AUC: 0.7943\n",
      "Epoch 153/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 4.7700 - AUC: 0.9090 - val_loss: 4.9942 - val_AUC: 0.7955\n",
      "Epoch 154/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 4.7475 - AUC: 0.9104 - val_loss: 4.9897 - val_AUC: 0.7938\n",
      "Epoch 155/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 4.7303 - AUC: 0.9098 - val_loss: 4.9600 - val_AUC: 0.7956\n",
      "Epoch 156/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 4.7037 - AUC: 0.9149 - val_loss: 4.9452 - val_AUC: 0.7970\n",
      "Epoch 157/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 4.6858 - AUC: 0.9167 - val_loss: 4.9292 - val_AUC: 0.7926\n",
      "Epoch 158/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.6657 - AUC: 0.9164 - val_loss: 4.9166 - val_AUC: 0.7940\n",
      "Epoch 159/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 4.6520 - AUC: 0.9145 - val_loss: 4.8802 - val_AUC: 0.7972\n",
      "Epoch 160/500\n",
      "5934/5934 [==============================] - 1s 125us/sample - loss: 4.6284 - AUC: 0.9173 - val_loss: 4.8891 - val_AUC: 0.7904\n",
      "Epoch 161/500\n",
      "5934/5934 [==============================] - 1s 129us/sample - loss: 4.6174 - AUC: 0.9142 - val_loss: 4.8570 - val_AUC: 0.7965\n",
      "Epoch 162/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 4.5905 - AUC: 0.9199 - val_loss: 4.8329 - val_AUC: 0.7978\n",
      "Epoch 163/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 4.5865 - AUC: 0.9122 - val_loss: 4.8216 - val_AUC: 0.7979\n",
      "Epoch 164/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 4.5492 - AUC: 0.9230 - val_loss: 4.7989 - val_AUC: 0.7985\n",
      "Epoch 165/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.5454 - AUC: 0.9151 - val_loss: 4.7886 - val_AUC: 0.7957\n",
      "Epoch 166/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.5201 - AUC: 0.9198 - val_loss: 4.7688 - val_AUC: 0.7950\n",
      "Epoch 167/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 4.4984 - AUC: 0.9225 - val_loss: 4.7504 - val_AUC: 0.7965\n",
      "Epoch 168/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.4848 - AUC: 0.9202 - val_loss: 4.7348 - val_AUC: 0.7995\n",
      "Epoch 169/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 4.4628 - AUC: 0.9223 - val_loss: 4.7412 - val_AUC: 0.7938\n",
      "Epoch 170/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 4.4453 - AUC: 0.9229 - val_loss: 4.7115 - val_AUC: 0.7953\n",
      "Epoch 171/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 4.4249 - AUC: 0.9248 - val_loss: 4.6916 - val_AUC: 0.7963\n",
      "Epoch 172/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 4.4119 - AUC: 0.9222 - val_loss: 4.6903 - val_AUC: 0.7977\n",
      "Epoch 173/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 4.3863 - AUC: 0.9274 - val_loss: 4.6520 - val_AUC: 0.7975\n",
      "Epoch 174/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 4.3749 - AUC: 0.9245 - val_loss: 4.6396 - val_AUC: 0.7968\n",
      "Epoch 175/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 4.3629 - AUC: 0.9226 - val_loss: 4.6149 - val_AUC: 0.7997\n",
      "Epoch 176/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 4.3454 - AUC: 0.9229 - val_loss: 4.6162 - val_AUC: 0.7972\n",
      "Epoch 177/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 4.3214 - AUC: 0.9271 - val_loss: 4.5974 - val_AUC: 0.7985\n",
      "Epoch 178/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 4.3041 - AUC: 0.9267 - val_loss: 4.5840 - val_AUC: 0.8003\n",
      "Epoch 179/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 4.2827 - AUC: 0.9303 - val_loss: 4.5676 - val_AUC: 0.7989\n",
      "Epoch 180/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 4.2750 - AUC: 0.9256 - val_loss: 4.5483 - val_AUC: 0.7983\n",
      "Epoch 181/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 4.2529 - AUC: 0.9292 - val_loss: 4.5447 - val_AUC: 0.7957\n",
      "Epoch 182/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 4.2324 - AUC: 0.9312 - val_loss: 4.5128 - val_AUC: 0.7977\n",
      "Epoch 183/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 4.2168 - AUC: 0.9317 - val_loss: 4.5037 - val_AUC: 0.7962\n",
      "Epoch 184/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 4.2076 - AUC: 0.9278 - val_loss: 4.4909 - val_AUC: 0.7972\n",
      "Epoch 185/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 4.1863 - AUC: 0.9299 - val_loss: 4.4853 - val_AUC: 0.7975\n",
      "Epoch 186/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 4.1677 - AUC: 0.9310 - val_loss: 4.4610 - val_AUC: 0.8009\n",
      "Epoch 187/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 4.1553 - AUC: 0.9297 - val_loss: 4.4364 - val_AUC: 0.7996\n",
      "Epoch 188/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 4.1337 - AUC: 0.9323 - val_loss: 4.4358 - val_AUC: 0.7984\n",
      "Epoch 189/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 4.1162 - AUC: 0.9335 - val_loss: 4.4139 - val_AUC: 0.7981\n",
      "Epoch 190/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 4.1040 - AUC: 0.9312 - val_loss: 4.3932 - val_AUC: 0.7972\n",
      "Epoch 191/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 4.0795 - AUC: 0.9357 - val_loss: 4.3862 - val_AUC: 0.7987\n",
      "Epoch 192/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 4.0614 - AUC: 0.9383 - val_loss: 4.3616 - val_AUC: 0.8020\n",
      "Epoch 193/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 4.0515 - AUC: 0.9353 - val_loss: 4.3432 - val_AUC: 0.7997\n",
      "Epoch 194/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 4.0388 - AUC: 0.9334 - val_loss: 4.3448 - val_AUC: 0.8006\n",
      "Epoch 195/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 4.0190 - AUC: 0.9357 - val_loss: 4.3079 - val_AUC: 0.7996\n",
      "Epoch 196/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 4.0041 - AUC: 0.9360 - val_loss: 4.3009 - val_AUC: 0.8014\n",
      "Epoch 197/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.9916 - AUC: 0.9336 - val_loss: 4.2800 - val_AUC: 0.8013\n",
      "Epoch 198/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 3.9665 - AUC: 0.9389 - val_loss: 4.2745 - val_AUC: 0.8001\n",
      "Epoch 199/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 3.9583 - AUC: 0.9354 - val_loss: 4.2575 - val_AUC: 0.8020\n",
      "Epoch 200/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 3.9414 - AUC: 0.9372 - val_loss: 4.2456 - val_AUC: 0.7996\n",
      "Epoch 201/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.9245 - AUC: 0.9378 - val_loss: 4.2231 - val_AUC: 0.8047\n",
      "Epoch 202/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 3.9195 - AUC: 0.9326 - val_loss: 4.2202 - val_AUC: 0.7979\n",
      "Epoch 203/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.8961 - AUC: 0.9379 - val_loss: 4.2127 - val_AUC: 0.7991\n",
      "Epoch 204/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 3.8727 - AUC: 0.9416 - val_loss: 4.1900 - val_AUC: 0.7996\n",
      "Epoch 205/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 3.8597 - AUC: 0.9403 - val_loss: 4.1744 - val_AUC: 0.8005\n",
      "Epoch 206/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 3.8538 - AUC: 0.9355 - val_loss: 4.1569 - val_AUC: 0.8012\n",
      "Epoch 207/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 3.8263 - AUC: 0.9418 - val_loss: 4.1596 - val_AUC: 0.8003\n",
      "Epoch 208/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.8139 - AUC: 0.9410 - val_loss: 4.1346 - val_AUC: 0.8014\n",
      "Epoch 209/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 3.7953 - AUC: 0.9435 - val_loss: 4.1349 - val_AUC: 0.7986\n",
      "Epoch 210/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 3.7845 - AUC: 0.9423 - val_loss: 4.0985 - val_AUC: 0.8029\n",
      "Epoch 211/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 3.7707 - AUC: 0.9410 - val_loss: 4.0929 - val_AUC: 0.7999\n",
      "Epoch 212/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.7514 - AUC: 0.9434 - val_loss: 4.0880 - val_AUC: 0.8022\n",
      "Epoch 213/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 3.7404 - AUC: 0.9425 - val_loss: 4.0692 - val_AUC: 0.7984\n",
      "Epoch 214/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.7242 - AUC: 0.9434 - val_loss: 4.0549 - val_AUC: 0.7978\n",
      "Epoch 215/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 3.7072 - AUC: 0.9449 - val_loss: 4.0336 - val_AUC: 0.8001\n",
      "Epoch 216/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 3.7009 - AUC: 0.9420 - val_loss: 4.0386 - val_AUC: 0.8018\n",
      "Epoch 217/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 3.6815 - AUC: 0.9447 - val_loss: 4.0226 - val_AUC: 0.8017\n",
      "Epoch 218/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 3.6685 - AUC: 0.9436 - val_loss: 4.0187 - val_AUC: 0.7995\n",
      "Epoch 219/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 3.6535 - AUC: 0.9448 - val_loss: 3.9856 - val_AUC: 0.8010\n",
      "Epoch 220/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 3.6353 - AUC: 0.9472 - val_loss: 3.9754 - val_AUC: 0.8015\n",
      "Epoch 221/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 3.6212 - AUC: 0.9467 - val_loss: 3.9746 - val_AUC: 0.8013\n",
      "Epoch 222/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 3.6108 - AUC: 0.9455 - val_loss: 3.9514 - val_AUC: 0.7997\n",
      "Epoch 223/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 3.5983 - AUC: 0.9453 - val_loss: 3.9472 - val_AUC: 0.8013\n",
      "Epoch 224/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 3.5868 - AUC: 0.9450 - val_loss: 3.9253 - val_AUC: 0.8030\n",
      "Epoch 225/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 3.5722 - AUC: 0.9444 - val_loss: 3.9143 - val_AUC: 0.8015\n",
      "Epoch 226/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 3.5491 - AUC: 0.9498 - val_loss: 3.9050 - val_AUC: 0.7990\n",
      "Epoch 227/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 3.5413 - AUC: 0.9477 - val_loss: 3.8971 - val_AUC: 0.7995\n",
      "Epoch 228/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 3.5251 - AUC: 0.9487 - val_loss: 3.8909 - val_AUC: 0.7967\n",
      "Epoch 229/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 3.5075 - AUC: 0.9518 - val_loss: 3.8559 - val_AUC: 0.8003\n",
      "Epoch 230/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.4996 - AUC: 0.9493 - val_loss: 3.8593 - val_AUC: 0.8011\n",
      "Epoch 231/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 3.4886 - AUC: 0.9483 - val_loss: 3.8306 - val_AUC: 0.8040\n",
      "Epoch 232/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 3.4703 - AUC: 0.9517 - val_loss: 3.8451 - val_AUC: 0.7996\n",
      "Epoch 233/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 3.4618 - AUC: 0.9486 - val_loss: 3.8303 - val_AUC: 0.8006\n",
      "Epoch 234/500\n",
      "5934/5934 [==============================] - 1s 128us/sample - loss: 3.4478 - AUC: 0.9499 - val_loss: 3.8097 - val_AUC: 0.8020\n",
      "Epoch 235/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 3.4327 - AUC: 0.9499 - val_loss: 3.7879 - val_AUC: 0.8019\n",
      "Epoch 236/500\n",
      "5934/5934 [==============================] - 1s 128us/sample - loss: 3.4124 - AUC: 0.9543 - val_loss: 3.7764 - val_AUC: 0.7998\n",
      "Epoch 237/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 3.3932 - AUC: 0.9565 - val_loss: 3.7718 - val_AUC: 0.8029\n",
      "Epoch 238/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 3.3797 - AUC: 0.9563 - val_loss: 3.7694 - val_AUC: 0.8015\n",
      "Epoch 239/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 3.3718 - AUC: 0.9547 - val_loss: 3.7600 - val_AUC: 0.7982\n",
      "Epoch 240/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 3.3668 - AUC: 0.9521 - val_loss: 3.7495 - val_AUC: 0.7991\n",
      "Epoch 241/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 3.3514 - AUC: 0.9531 - val_loss: 3.7272 - val_AUC: 0.8019\n",
      "Epoch 242/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 3.3333 - AUC: 0.9559 - val_loss: 3.7247 - val_AUC: 0.8033\n",
      "Epoch 243/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.3351 - AUC: 0.9512 - val_loss: 3.6960 - val_AUC: 0.8037\n",
      "Epoch 244/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 3.3114 - AUC: 0.9546 - val_loss: 3.6984 - val_AUC: 0.8005\n",
      "Epoch 245/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 3.3027 - AUC: 0.9530 - val_loss: 3.6681 - val_AUC: 0.8022\n",
      "Epoch 246/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 3.2957 - AUC: 0.9524 - val_loss: 3.6729 - val_AUC: 0.7990\n",
      "Epoch 247/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 3.2811 - AUC: 0.9528 - val_loss: 3.6491 - val_AUC: 0.8031\n",
      "Epoch 248/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 3.2626 - AUC: 0.9555 - val_loss: 3.6423 - val_AUC: 0.7998\n",
      "Epoch 249/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 3.2526 - AUC: 0.9552 - val_loss: 3.6382 - val_AUC: 0.8007\n",
      "Epoch 250/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 3.2399 - AUC: 0.9551 - val_loss: 3.6092 - val_AUC: 0.8035\n",
      "Epoch 251/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 3.2254 - AUC: 0.9567 - val_loss: 3.6114 - val_AUC: 0.8025\n",
      "Epoch 252/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 3.2195 - AUC: 0.9544 - val_loss: 3.6071 - val_AUC: 0.8011\n",
      "Epoch 253/500\n",
      "5934/5934 [==============================] - 1s 125us/sample - loss: 3.2075 - AUC: 0.9550 - val_loss: 3.6052 - val_AUC: 0.7990\n",
      "Epoch 254/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 3.1858 - AUC: 0.9581 - val_loss: 3.5840 - val_AUC: 0.8033\n",
      "Epoch 255/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 3.1850 - AUC: 0.9548 - val_loss: 3.5585 - val_AUC: 0.8021\n",
      "Epoch 256/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 3.1672 - AUC: 0.9577 - val_loss: 3.5766 - val_AUC: 0.8033\n",
      "Epoch 257/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 3.1590 - AUC: 0.9564 - val_loss: 3.5540 - val_AUC: 0.8018\n",
      "Epoch 258/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 3.1484 - AUC: 0.9566 - val_loss: 3.5444 - val_AUC: 0.8009\n",
      "Epoch 259/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 3.1434 - AUC: 0.9546 - val_loss: 3.5217 - val_AUC: 0.8021\n",
      "Epoch 260/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.1172 - AUC: 0.9598 - val_loss: 3.5239 - val_AUC: 0.8035\n",
      "Epoch 261/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 3.1144 - AUC: 0.9569 - val_loss: 3.5088 - val_AUC: 0.8015\n",
      "Epoch 262/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 3.1013 - AUC: 0.9577 - val_loss: 3.5070 - val_AUC: 0.8017\n",
      "Epoch 263/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 3.0877 - AUC: 0.9588 - val_loss: 3.4894 - val_AUC: 0.8011\n",
      "Epoch 264/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 3.0758 - AUC: 0.9600 - val_loss: 3.4853 - val_AUC: 0.8021\n",
      "Epoch 265/500\n",
      "5934/5934 [==============================] - 1s 128us/sample - loss: 3.0714 - AUC: 0.9572 - val_loss: 3.4720 - val_AUC: 0.8013\n",
      "Epoch 266/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 3.0524 - AUC: 0.9605 - val_loss: 3.4583 - val_AUC: 0.8031\n",
      "Epoch 267/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 3.0502 - AUC: 0.9566 - val_loss: 3.4480 - val_AUC: 0.8060\n",
      "Epoch 268/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 3.0317 - AUC: 0.9603 - val_loss: 3.4438 - val_AUC: 0.8002\n",
      "Epoch 269/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 3.0155 - AUC: 0.9626 - val_loss: 3.4358 - val_AUC: 0.8023\n",
      "Epoch 270/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 3.0050 - AUC: 0.9618 - val_loss: 3.4371 - val_AUC: 0.8004\n",
      "Epoch 271/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.9950 - AUC: 0.9620 - val_loss: 3.4274 - val_AUC: 0.8001\n",
      "Epoch 272/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 2.9861 - AUC: 0.9618 - val_loss: 3.4055 - val_AUC: 0.8027\n",
      "Epoch 273/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 2.9708 - AUC: 0.9629 - val_loss: 3.3999 - val_AUC: 0.8007\n",
      "Epoch 274/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 2.9626 - AUC: 0.9629 - val_loss: 3.3919 - val_AUC: 0.8009\n",
      "Epoch 275/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 2.9570 - AUC: 0.9613 - val_loss: 3.3852 - val_AUC: 0.8017\n",
      "Epoch 276/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 2.9505 - AUC: 0.9598 - val_loss: 3.3771 - val_AUC: 0.8036\n",
      "Epoch 277/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 2.9361 - AUC: 0.9615 - val_loss: 3.3587 - val_AUC: 0.8027\n",
      "Epoch 278/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 2.9211 - AUC: 0.9639 - val_loss: 3.3436 - val_AUC: 0.8035\n",
      "Epoch 279/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 2.9114 - AUC: 0.9637 - val_loss: 3.3492 - val_AUC: 0.7991\n",
      "Epoch 280/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 2.9030 - AUC: 0.9626 - val_loss: 3.3426 - val_AUC: 0.8001\n",
      "Epoch 281/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 2.8995 - AUC: 0.9608 - val_loss: 3.3313 - val_AUC: 0.8020\n",
      "Epoch 282/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 2.8780 - AUC: 0.9646 - val_loss: 3.3099 - val_AUC: 0.8010\n",
      "Epoch 283/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 2.8743 - AUC: 0.9626 - val_loss: 3.3060 - val_AUC: 0.8022\n",
      "Epoch 284/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 2.8630 - AUC: 0.9648 - val_loss: 3.3139 - val_AUC: 0.8017\n",
      "Epoch 285/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 2.8630 - AUC: 0.9606 - val_loss: 3.3007 - val_AUC: 0.7985\n",
      "Epoch 286/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 2.8564 - AUC: 0.9599 - val_loss: 3.2837 - val_AUC: 0.8031\n",
      "Epoch 287/500\n",
      "5934/5934 [==============================] - 1s 128us/sample - loss: 2.8392 - AUC: 0.9625 - val_loss: 3.2836 - val_AUC: 0.8011\n",
      "Epoch 288/500\n",
      "5934/5934 [==============================] - 1s 125us/sample - loss: 2.8177 - AUC: 0.9671 - val_loss: 3.2725 - val_AUC: 0.8004\n",
      "Epoch 289/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 2.8189 - AUC: 0.9634 - val_loss: 3.2748 - val_AUC: 0.8004\n",
      "Epoch 290/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 2.8060 - AUC: 0.9648 - val_loss: 3.2482 - val_AUC: 0.8019\n",
      "Epoch 291/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 2.7984 - AUC: 0.9645 - val_loss: 3.2407 - val_AUC: 0.8037\n",
      "Epoch 292/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 2.7866 - AUC: 0.9653 - val_loss: 3.2418 - val_AUC: 0.8022\n",
      "Epoch 293/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 2.7754 - AUC: 0.9661 - val_loss: 3.2228 - val_AUC: 0.8020\n",
      "Epoch 294/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 2.7673 - AUC: 0.9662 - val_loss: 3.2377 - val_AUC: 0.8015\n",
      "Epoch 295/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 2.7532 - AUC: 0.9678 - val_loss: 3.2354 - val_AUC: 0.7992\n",
      "Epoch 296/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 2.7479 - AUC: 0.9666 - val_loss: 3.2070 - val_AUC: 0.8024\n",
      "Epoch 297/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 2.7373 - AUC: 0.9672 - val_loss: 3.2244 - val_AUC: 0.8026\n",
      "Epoch 298/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 2.7267 - AUC: 0.9682 - val_loss: 3.1850 - val_AUC: 0.8029\n",
      "Epoch 299/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 2.7242 - AUC: 0.9655 - val_loss: 3.1864 - val_AUC: 0.8041\n",
      "Epoch 300/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 2.7103 - AUC: 0.9674 - val_loss: 3.1900 - val_AUC: 0.8035\n",
      "Epoch 301/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 2.6995 - AUC: 0.9683 - val_loss: 3.1810 - val_AUC: 0.8012\n",
      "Epoch 302/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 2.6912 - AUC: 0.9683 - val_loss: 3.1575 - val_AUC: 0.8024\n",
      "Epoch 303/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 2.6780 - AUC: 0.9699 - val_loss: 3.1485 - val_AUC: 0.8005\n",
      "Epoch 304/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.6739 - AUC: 0.9684 - val_loss: 3.1425 - val_AUC: 0.8028\n",
      "Epoch 305/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 2.6695 - AUC: 0.9667 - val_loss: 3.1336 - val_AUC: 0.8038\n",
      "Epoch 306/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 2.6576 - AUC: 0.9683 - val_loss: 3.1322 - val_AUC: 0.8016\n",
      "Epoch 307/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 2.6570 - AUC: 0.9658 - val_loss: 3.1597 - val_AUC: 0.7984\n",
      "Epoch 308/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 2.6458 - AUC: 0.9665 - val_loss: 3.1240 - val_AUC: 0.8021\n",
      "Epoch 309/500\n",
      "5934/5934 [==============================] - 1s 128us/sample - loss: 2.6305 - AUC: 0.9689 - val_loss: 3.1394 - val_AUC: 0.7986\n",
      "Epoch 310/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 2.6203 - AUC: 0.9701 - val_loss: 3.1125 - val_AUC: 0.8002\n",
      "Epoch 311/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 2.6154 - AUC: 0.9689 - val_loss: 3.0844 - val_AUC: 0.8008\n",
      "Epoch 312/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 2.6097 - AUC: 0.9686 - val_loss: 3.0999 - val_AUC: 0.8000\n",
      "Epoch 313/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 2.5926 - AUC: 0.9713 - val_loss: 3.1027 - val_AUC: 0.7991\n",
      "Epoch 314/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 2.5950 - AUC: 0.9676 - val_loss: 3.0890 - val_AUC: 0.7995\n",
      "Epoch 315/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 2.5761 - AUC: 0.9718 - val_loss: 3.0976 - val_AUC: 0.7976\n",
      "Epoch 316/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 2.5755 - AUC: 0.9683 - val_loss: 3.0783 - val_AUC: 0.7983\n",
      "Epoch 317/500\n",
      "5934/5934 [==============================] - 1s 125us/sample - loss: 2.5714 - AUC: 0.9677 - val_loss: 3.0498 - val_AUC: 0.7997\n",
      "Epoch 318/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.5584 - AUC: 0.9700 - val_loss: 3.0631 - val_AUC: 0.8001\n",
      "Epoch 319/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 2.5549 - AUC: 0.9685 - val_loss: 3.0660 - val_AUC: 0.7992\n",
      "Epoch 320/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 2.5423 - AUC: 0.9697 - val_loss: 3.0425 - val_AUC: 0.7985\n",
      "Epoch 321/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 2.5357 - AUC: 0.9698 - val_loss: 3.0433 - val_AUC: 0.8003\n",
      "Epoch 322/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 2.5269 - AUC: 0.9702 - val_loss: 3.0295 - val_AUC: 0.7986\n",
      "Epoch 323/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 2.5183 - AUC: 0.9702 - val_loss: 3.0254 - val_AUC: 0.8005\n",
      "Epoch 324/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 2.5061 - AUC: 0.9721 - val_loss: 3.0100 - val_AUC: 0.8005\n",
      "Epoch 325/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 2.5046 - AUC: 0.9705 - val_loss: 2.9979 - val_AUC: 0.8005\n",
      "Epoch 326/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 2.4986 - AUC: 0.9696 - val_loss: 3.0056 - val_AUC: 0.8005\n",
      "Epoch 327/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 2.4869 - AUC: 0.9721 - val_loss: 3.0263 - val_AUC: 0.8006\n",
      "Epoch 328/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 2.4798 - AUC: 0.9713 - val_loss: 2.9905 - val_AUC: 0.8027\n",
      "Epoch 329/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 2.4679 - AUC: 0.9733 - val_loss: 2.9714 - val_AUC: 0.8001\n",
      "Epoch 330/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.4629 - AUC: 0.9716 - val_loss: 2.9696 - val_AUC: 0.8026\n",
      "Epoch 331/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 2.4482 - AUC: 0.9750 - val_loss: 2.9942 - val_AUC: 0.7987\n",
      "Epoch 332/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 2.4514 - AUC: 0.9711 - val_loss: 2.9591 - val_AUC: 0.8026\n",
      "Epoch 333/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 2.4462 - AUC: 0.9707 - val_loss: 2.9615 - val_AUC: 0.8004\n",
      "Epoch 334/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 2.4318 - AUC: 0.9731 - val_loss: 2.9828 - val_AUC: 0.8024\n",
      "Epoch 335/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 2.4290 - AUC: 0.9712 - val_loss: 2.9622 - val_AUC: 0.8007\n",
      "Epoch 336/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 2.4152 - AUC: 0.9742 - val_loss: 2.9726 - val_AUC: 0.7990\n",
      "Epoch 337/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 2.4054 - AUC: 0.9748 - val_loss: 2.9157 - val_AUC: 0.8036\n",
      "Epoch 338/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 2.4034 - AUC: 0.9733 - val_loss: 2.9252 - val_AUC: 0.7999\n",
      "Epoch 339/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.3937 - AUC: 0.9744 - val_loss: 2.9257 - val_AUC: 0.8028\n",
      "Epoch 340/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 2.3871 - AUC: 0.9740 - val_loss: 2.9084 - val_AUC: 0.8010\n",
      "Epoch 341/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 2.3950 - AUC: 0.9702 - val_loss: 2.9193 - val_AUC: 0.8010\n",
      "Epoch 342/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 2.3783 - AUC: 0.9731 - val_loss: 2.8955 - val_AUC: 0.8020\n",
      "Epoch 343/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 2.3666 - AUC: 0.9750 - val_loss: 2.9120 - val_AUC: 0.7998\n",
      "Epoch 344/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 2.3648 - AUC: 0.9729 - val_loss: 2.9273 - val_AUC: 0.7999\n",
      "Epoch 345/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 2.3577 - AUC: 0.9738 - val_loss: 2.8921 - val_AUC: 0.8002\n",
      "Epoch 346/500\n",
      "5934/5934 [==============================] - 1s 129us/sample - loss: 2.3396 - AUC: 0.9768 - val_loss: 2.8753 - val_AUC: 0.7986\n",
      "Epoch 347/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.3388 - AUC: 0.9753 - val_loss: 2.8736 - val_AUC: 0.8022\n",
      "Epoch 348/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 2.3341 - AUC: 0.9742 - val_loss: 2.8667 - val_AUC: 0.7999\n",
      "Epoch 349/500\n",
      "5934/5934 [==============================] - 1s 127us/sample - loss: 2.3256 - AUC: 0.9762 - val_loss: 2.8607 - val_AUC: 0.8004\n",
      "Epoch 350/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 2.3194 - AUC: 0.9760 - val_loss: 2.8947 - val_AUC: 0.7982\n",
      "Epoch 351/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 2.3041 - AUC: 0.9781 - val_loss: 2.8462 - val_AUC: 0.7996\n",
      "Epoch 352/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 2.3063 - AUC: 0.9758 - val_loss: 2.8856 - val_AUC: 0.7970\n",
      "Epoch 353/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.3036 - AUC: 0.9747 - val_loss: 2.8794 - val_AUC: 0.7960\n",
      "Epoch 354/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 2.3021 - AUC: 0.9740 - val_loss: 2.8914 - val_AUC: 0.7946\n",
      "Epoch 355/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 2.2854 - AUC: 0.9768 - val_loss: 2.8317 - val_AUC: 0.7980\n",
      "Epoch 356/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.2888 - AUC: 0.9738 - val_loss: 2.8182 - val_AUC: 0.8021\n",
      "Epoch 357/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 2.2787 - AUC: 0.9749 - val_loss: 2.8747 - val_AUC: 0.7976\n",
      "Epoch 358/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 2.2673 - AUC: 0.9768 - val_loss: 2.8223 - val_AUC: 0.7981\n",
      "Epoch 359/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 2.2608 - AUC: 0.9766 - val_loss: 2.8177 - val_AUC: 0.7995\n",
      "Epoch 360/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 2.2502 - AUC: 0.9781 - val_loss: 2.8438 - val_AUC: 0.7983\n",
      "Epoch 361/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 2.2533 - AUC: 0.9757 - val_loss: 2.8132 - val_AUC: 0.7977\n",
      "Epoch 362/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.2431 - AUC: 0.9769 - val_loss: 2.8450 - val_AUC: 0.7959\n",
      "Epoch 363/500\n",
      "5934/5934 [==============================] - 1s 106us/sample - loss: 2.2333 - AUC: 0.9778 - val_loss: 2.8042 - val_AUC: 0.8012\n",
      "Epoch 364/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 2.2335 - AUC: 0.9762 - val_loss: 2.8020 - val_AUC: 0.7998\n",
      "Epoch 365/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 2.2323 - AUC: 0.9756 - val_loss: 2.7892 - val_AUC: 0.8004\n",
      "Epoch 366/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 2.2181 - AUC: 0.9777 - val_loss: 2.8035 - val_AUC: 0.7999\n",
      "Epoch 367/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 2.2168 - AUC: 0.9764 - val_loss: 2.7851 - val_AUC: 0.8015\n",
      "Epoch 368/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 2.2059 - AUC: 0.9782 - val_loss: 2.7896 - val_AUC: 0.7997\n",
      "Epoch 369/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 2.2010 - AUC: 0.9785 - val_loss: 2.7810 - val_AUC: 0.7959\n",
      "Epoch 370/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 2.1853 - AUC: 0.9806 - val_loss: 2.7579 - val_AUC: 0.7972\n",
      "Epoch 371/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 2.1855 - AUC: 0.9795 - val_loss: 2.7823 - val_AUC: 0.7954\n",
      "Epoch 372/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 2.1810 - AUC: 0.9788 - val_loss: 2.7515 - val_AUC: 0.7982\n",
      "Epoch 373/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 2.1797 - AUC: 0.9778 - val_loss: 2.7518 - val_AUC: 0.7987\n",
      "Epoch 374/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 2.1747 - AUC: 0.9774 - val_loss: 2.7825 - val_AUC: 0.7964\n",
      "Epoch 375/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.1634 - AUC: 0.9786 - val_loss: 2.7616 - val_AUC: 0.7962\n",
      "Epoch 376/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 2.1704 - AUC: 0.9755 - val_loss: 2.7754 - val_AUC: 0.7952\n",
      "Epoch 377/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 2.1602 - AUC: 0.9776 - val_loss: 2.7620 - val_AUC: 0.7961\n",
      "Epoch 378/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 2.1533 - AUC: 0.9774 - val_loss: 2.7281 - val_AUC: 0.8004\n",
      "Epoch 379/500\n",
      "5934/5934 [==============================] - 1s 104us/sample - loss: 2.1517 - AUC: 0.9767 - val_loss: 2.7512 - val_AUC: 0.7972\n",
      "Epoch 380/500\n",
      "5934/5934 [==============================] - 1s 127us/sample - loss: 2.1299 - AUC: 0.9815 - val_loss: 2.7280 - val_AUC: 0.7979\n",
      "Epoch 381/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 2.1307 - AUC: 0.9795 - val_loss: 2.7092 - val_AUC: 0.7984\n",
      "Epoch 382/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 2.1187 - AUC: 0.9813 - val_loss: 2.7535 - val_AUC: 0.7973\n",
      "Epoch 383/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 2.1199 - AUC: 0.9798 - val_loss: 2.7248 - val_AUC: 0.7980\n",
      "Epoch 384/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 2.1142 - AUC: 0.9796 - val_loss: 2.7000 - val_AUC: 0.8005\n",
      "Epoch 385/500\n",
      "5934/5934 [==============================] - 1s 104us/sample - loss: 2.1172 - AUC: 0.9776 - val_loss: 2.7081 - val_AUC: 0.7994\n",
      "Epoch 386/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 2.1173 - AUC: 0.9753 - val_loss: 2.6926 - val_AUC: 0.8009\n",
      "Epoch 387/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 2.0938 - AUC: 0.9811 - val_loss: 2.6967 - val_AUC: 0.7986\n",
      "Epoch 388/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.0893 - AUC: 0.9811 - val_loss: 2.6997 - val_AUC: 0.7982\n",
      "Epoch 389/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 2.0874 - AUC: 0.9799 - val_loss: 2.6979 - val_AUC: 0.7978\n",
      "Epoch 390/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 2.0868 - AUC: 0.9786 - val_loss: 2.7080 - val_AUC: 0.7964\n",
      "Epoch 391/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 2.0746 - AUC: 0.9810 - val_loss: 2.6790 - val_AUC: 0.8024\n",
      "Epoch 392/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 2.0686 - AUC: 0.9816 - val_loss: 2.7128 - val_AUC: 0.7944\n",
      "Epoch 393/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 2.0644 - AUC: 0.9814 - val_loss: 2.6689 - val_AUC: 0.7970\n",
      "Epoch 394/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 2.0628 - AUC: 0.9802 - val_loss: 2.6802 - val_AUC: 0.7989\n",
      "Epoch 395/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 2.0657 - AUC: 0.9786 - val_loss: 2.6999 - val_AUC: 0.7964\n",
      "Epoch 396/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 2.0599 - AUC: 0.9784 - val_loss: 2.6751 - val_AUC: 0.7997\n",
      "Epoch 397/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 2.0545 - AUC: 0.9783 - val_loss: 2.6531 - val_AUC: 0.7991\n",
      "Epoch 398/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 2.0434 - AUC: 0.9806 - val_loss: 2.6680 - val_AUC: 0.7960\n",
      "Epoch 399/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 2.0376 - AUC: 0.9802 - val_loss: 2.6640 - val_AUC: 0.7965\n",
      "Epoch 400/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 2.0252 - AUC: 0.9817 - val_loss: 2.6574 - val_AUC: 0.7997\n",
      "Epoch 401/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.0288 - AUC: 0.9807 - val_loss: 2.6484 - val_AUC: 0.7982\n",
      "Epoch 402/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.0188 - AUC: 0.9815 - val_loss: 2.6421 - val_AUC: 0.8014\n",
      "Epoch 403/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 2.0235 - AUC: 0.9793 - val_loss: 2.6817 - val_AUC: 0.7947\n",
      "Epoch 404/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 2.0134 - AUC: 0.9804 - val_loss: 2.6438 - val_AUC: 0.8002\n",
      "Epoch 405/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 2.0007 - AUC: 0.9834 - val_loss: 2.6357 - val_AUC: 0.7974\n",
      "Epoch 406/500\n",
      "5934/5934 [==============================] - 1s 136us/sample - loss: 1.9988 - AUC: 0.9823 - val_loss: 2.6308 - val_AUC: 0.7987\n",
      "Epoch 407/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 1.9984 - AUC: 0.9809 - val_loss: 2.6333 - val_AUC: 0.7989\n",
      "Epoch 408/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 1.9874 - AUC: 0.9826 - val_loss: 2.6286 - val_AUC: 0.7969\n",
      "Epoch 409/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 1.9857 - AUC: 0.9816 - val_loss: 2.6135 - val_AUC: 0.7987\n",
      "Epoch 410/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 1.9817 - AUC: 0.9818 - val_loss: 2.6305 - val_AUC: 0.7985\n",
      "Epoch 411/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 1.9780 - AUC: 0.9812 - val_loss: 2.6288 - val_AUC: 0.7973\n",
      "Epoch 412/500\n",
      "5934/5934 [==============================] - 1s 126us/sample - loss: 1.9706 - AUC: 0.9823 - val_loss: 2.5848 - val_AUC: 0.8019\n",
      "Epoch 413/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 1.9677 - AUC: 0.9815 - val_loss: 2.6175 - val_AUC: 0.7969\n",
      "Epoch 414/500\n",
      "5934/5934 [==============================] - 1s 106us/sample - loss: 1.9666 - AUC: 0.9813 - val_loss: 2.6234 - val_AUC: 0.7956\n",
      "Epoch 415/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 1.9638 - AUC: 0.9809 - val_loss: 2.5989 - val_AUC: 0.7965\n",
      "Epoch 416/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 1.9530 - AUC: 0.9828 - val_loss: 2.5966 - val_AUC: 0.7945\n",
      "Epoch 417/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 1.9396 - AUC: 0.9844 - val_loss: 2.5821 - val_AUC: 0.7968\n",
      "Epoch 418/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 1.9429 - AUC: 0.9823 - val_loss: 2.5871 - val_AUC: 0.7950\n",
      "Epoch 419/500\n",
      "5934/5934 [==============================] - 1s 124us/sample - loss: 1.9374 - AUC: 0.9828 - val_loss: 2.6149 - val_AUC: 0.7956\n",
      "Epoch 420/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 1.9249 - AUC: 0.9851 - val_loss: 2.5961 - val_AUC: 0.7956\n",
      "Epoch 421/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 1.9241 - AUC: 0.9841 - val_loss: 2.5776 - val_AUC: 0.7972\n",
      "Epoch 422/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 1.9218 - AUC: 0.9834 - val_loss: 2.6042 - val_AUC: 0.7937\n",
      "Epoch 423/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 1.9216 - AUC: 0.9825 - val_loss: 2.5682 - val_AUC: 0.7953\n",
      "Epoch 424/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 1.9123 - AUC: 0.9840 - val_loss: 2.5916 - val_AUC: 0.7953\n",
      "Epoch 425/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 1.9066 - AUC: 0.9841 - val_loss: 2.5681 - val_AUC: 0.7943\n",
      "Epoch 426/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 1.9083 - AUC: 0.9828 - val_loss: 2.6317 - val_AUC: 0.7917\n",
      "Epoch 427/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 1.8973 - AUC: 0.9846 - val_loss: 2.5916 - val_AUC: 0.7937\n",
      "Epoch 428/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 1.9025 - AUC: 0.9820 - val_loss: 2.5884 - val_AUC: 0.7943\n",
      "Epoch 429/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 1.8929 - AUC: 0.9831 - val_loss: 2.5602 - val_AUC: 0.7947\n",
      "Epoch 430/500\n",
      "5934/5934 [==============================] - 1s 108us/sample - loss: 1.8849 - AUC: 0.9845 - val_loss: 2.5743 - val_AUC: 0.7955\n",
      "Epoch 431/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 1.8918 - AUC: 0.9823 - val_loss: 2.5656 - val_AUC: 0.7950\n",
      "Epoch 432/500\n",
      "5934/5934 [==============================] - 1s 121us/sample - loss: 1.8845 - AUC: 0.9824 - val_loss: 2.5433 - val_AUC: 0.7963\n",
      "Epoch 433/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 1.8796 - AUC: 0.9829 - val_loss: 2.5649 - val_AUC: 0.7950\n",
      "Epoch 434/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 1.8676 - AUC: 0.9849 - val_loss: 2.5608 - val_AUC: 0.7933\n",
      "Epoch 435/500\n",
      "5934/5934 [==============================] - 1s 125us/sample - loss: 1.8702 - AUC: 0.9831 - val_loss: 2.5682 - val_AUC: 0.7931\n",
      "Epoch 436/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 1.8659 - AUC: 0.9833 - val_loss: 2.5504 - val_AUC: 0.7926\n",
      "Epoch 437/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 1.8515 - AUC: 0.9862 - val_loss: 2.5415 - val_AUC: 0.7957\n",
      "Epoch 438/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 1.8585 - AUC: 0.9827 - val_loss: 2.5609 - val_AUC: 0.7944\n",
      "Epoch 439/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 1.8486 - AUC: 0.9846 - val_loss: 2.5321 - val_AUC: 0.7960\n",
      "Epoch 440/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 1.8514 - AUC: 0.9827 - val_loss: 2.5505 - val_AUC: 0.7921\n",
      "Epoch 441/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 1.8404 - AUC: 0.9847 - val_loss: 2.5498 - val_AUC: 0.7941\n",
      "Epoch 442/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 1.8468 - AUC: 0.9820 - val_loss: 2.5466 - val_AUC: 0.7933\n",
      "Epoch 443/500\n",
      "5934/5934 [==============================] - 1s 105us/sample - loss: 1.8431 - AUC: 0.9822 - val_loss: 2.5205 - val_AUC: 0.7919\n",
      "Epoch 444/500\n",
      "5934/5934 [==============================] - 1s 104us/sample - loss: 1.8266 - AUC: 0.9853 - val_loss: 2.5357 - val_AUC: 0.7930\n",
      "Epoch 445/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 1.8255 - AUC: 0.9847 - val_loss: 2.5292 - val_AUC: 0.7911\n",
      "Epoch 446/500\n",
      "5934/5934 [==============================] - 1s 119us/sample - loss: 1.8196 - AUC: 0.9853 - val_loss: 2.5272 - val_AUC: 0.7922\n",
      "Epoch 447/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 1.8209 - AUC: 0.9840 - val_loss: 2.5197 - val_AUC: 0.7916\n",
      "Epoch 448/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 1.8136 - AUC: 0.9852 - val_loss: 2.5009 - val_AUC: 0.7953\n",
      "Epoch 449/500\n",
      "5934/5934 [==============================] - 1s 127us/sample - loss: 1.8116 - AUC: 0.9846 - val_loss: 2.5143 - val_AUC: 0.7937\n",
      "Epoch 450/500\n",
      "5934/5934 [==============================] - 1s 114us/sample - loss: 1.8018 - AUC: 0.9857 - val_loss: 2.5027 - val_AUC: 0.7918\n",
      "Epoch 451/500\n",
      "5934/5934 [==============================] - 1s 120us/sample - loss: 1.8039 - AUC: 0.9844 - val_loss: 2.5159 - val_AUC: 0.7956\n",
      "Epoch 452/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 1.8015 - AUC: 0.9845 - val_loss: 2.5046 - val_AUC: 0.7937\n",
      "Epoch 453/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 1.7882 - AUC: 0.9856 - val_loss: 2.5035 - val_AUC: 0.7925\n",
      "Epoch 454/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 1.7817 - AUC: 0.9872 - val_loss: 2.4839 - val_AUC: 0.7933\n",
      "Epoch 455/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 1.7781 - AUC: 0.9864 - val_loss: 2.5074 - val_AUC: 0.7933\n",
      "Epoch 456/500\n",
      "5934/5934 [==============================] - 1s 117us/sample - loss: 1.7779 - AUC: 0.9864 - val_loss: 2.4937 - val_AUC: 0.7946\n",
      "Epoch 457/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 1.7723 - AUC: 0.9867 - val_loss: 2.4841 - val_AUC: 0.7944\n",
      "Epoch 458/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 1.7702 - AUC: 0.9860 - val_loss: 2.4872 - val_AUC: 0.7931\n",
      "Epoch 459/500\n",
      "5934/5934 [==============================] - 1s 123us/sample - loss: 1.7764 - AUC: 0.9846 - val_loss: 2.4834 - val_AUC: 0.7921\n",
      "Epoch 460/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 1.7598 - AUC: 0.9870 - val_loss: 2.4958 - val_AUC: 0.7922\n",
      "Epoch 461/500\n",
      "5934/5934 [==============================] - 1s 106us/sample - loss: 1.7612 - AUC: 0.9858 - val_loss: 2.4795 - val_AUC: 0.7947\n",
      "Epoch 462/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 1.7624 - AUC: 0.9846 - val_loss: 2.5057 - val_AUC: 0.7943\n",
      "Epoch 463/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 1.7524 - AUC: 0.9866 - val_loss: 2.4630 - val_AUC: 0.7943\n",
      "Epoch 464/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 1.7487 - AUC: 0.9867 - val_loss: 2.4891 - val_AUC: 0.7944\n",
      "Epoch 465/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 1.7450 - AUC: 0.9863 - val_loss: 2.4537 - val_AUC: 0.7944\n",
      "Epoch 466/500\n",
      "5934/5934 [==============================] - 1s 106us/sample - loss: 1.7399 - AUC: 0.9867 - val_loss: 2.4707 - val_AUC: 0.7928\n",
      "Epoch 467/500\n",
      "5934/5934 [==============================] - 1s 104us/sample - loss: 1.7293 - AUC: 0.9890 - val_loss: 2.4671 - val_AUC: 0.7907\n",
      "Epoch 468/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 1.7356 - AUC: 0.9861 - val_loss: 2.5017 - val_AUC: 0.7906\n",
      "Epoch 469/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 1.7349 - AUC: 0.9853 - val_loss: 2.4858 - val_AUC: 0.7902\n",
      "Epoch 470/500\n",
      "5934/5934 [==============================] - 1s 104us/sample - loss: 1.7226 - AUC: 0.9869 - val_loss: 2.4691 - val_AUC: 0.7907\n",
      "Epoch 471/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 1.7234 - AUC: 0.9869 - val_loss: 2.4961 - val_AUC: 0.7919\n",
      "Epoch 472/500\n",
      "5934/5934 [==============================] - 1s 106us/sample - loss: 1.7228 - AUC: 0.9860 - val_loss: 2.4539 - val_AUC: 0.7911\n",
      "Epoch 473/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 1.7221 - AUC: 0.9855 - val_loss: 2.4702 - val_AUC: 0.7902\n",
      "Epoch 474/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 1.7117 - AUC: 0.9876 - val_loss: 2.4673 - val_AUC: 0.7898\n",
      "Epoch 475/500\n",
      "5934/5934 [==============================] - 1s 112us/sample - loss: 1.7110 - AUC: 0.9862 - val_loss: 2.4668 - val_AUC: 0.7892\n",
      "Epoch 476/500\n",
      "5934/5934 [==============================] - 1s 105us/sample - loss: 1.7082 - AUC: 0.9865 - val_loss: 2.4624 - val_AUC: 0.7905\n",
      "Epoch 477/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 1.7021 - AUC: 0.9872 - val_loss: 2.4405 - val_AUC: 0.7903\n",
      "Epoch 478/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 1.6902 - AUC: 0.9886 - val_loss: 2.4720 - val_AUC: 0.7888\n",
      "Epoch 479/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 1.6953 - AUC: 0.9871 - val_loss: 2.4475 - val_AUC: 0.7897\n",
      "Epoch 480/500\n",
      "5934/5934 [==============================] - 1s 110us/sample - loss: 1.6933 - AUC: 0.9868 - val_loss: 2.4550 - val_AUC: 0.7887\n",
      "Epoch 481/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 1.6904 - AUC: 0.9868 - val_loss: 2.4607 - val_AUC: 0.7925\n",
      "Epoch 482/500\n",
      "5934/5934 [==============================] - 1s 122us/sample - loss: 1.6837 - AUC: 0.9876 - val_loss: 2.4373 - val_AUC: 0.7903\n",
      "Epoch 483/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 1.6811 - AUC: 0.9871 - val_loss: 2.4365 - val_AUC: 0.7926\n",
      "Epoch 484/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 1.6815 - AUC: 0.9866 - val_loss: 2.4228 - val_AUC: 0.7920\n",
      "Epoch 485/500\n",
      "5934/5934 [==============================] - 1s 128us/sample - loss: 1.6804 - AUC: 0.9863 - val_loss: 2.4209 - val_AUC: 0.7932\n",
      "Epoch 486/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 1.6699 - AUC: 0.9878 - val_loss: 2.4363 - val_AUC: 0.7931\n",
      "Epoch 487/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 1.6630 - AUC: 0.9883 - val_loss: 2.4520 - val_AUC: 0.7916\n",
      "Epoch 488/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 1.6625 - AUC: 0.9876 - val_loss: 2.4383 - val_AUC: 0.7919\n",
      "Epoch 489/500\n",
      "5934/5934 [==============================] - 1s 116us/sample - loss: 1.6591 - AUC: 0.9880 - val_loss: 2.3910 - val_AUC: 0.7920\n",
      "Epoch 490/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 1.6625 - AUC: 0.9866 - val_loss: 2.4215 - val_AUC: 0.7911\n",
      "Epoch 491/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 1.6544 - AUC: 0.9877 - val_loss: 2.4209 - val_AUC: 0.7904\n",
      "Epoch 492/500\n",
      "5934/5934 [==============================] - 1s 118us/sample - loss: 1.6443 - AUC: 0.9890 - val_loss: 2.4081 - val_AUC: 0.7902\n",
      "Epoch 493/500\n",
      "5934/5934 [==============================] - 1s 102us/sample - loss: 1.6409 - AUC: 0.9890 - val_loss: 2.4037 - val_AUC: 0.7913\n",
      "Epoch 494/500\n",
      "5934/5934 [==============================] - 1s 111us/sample - loss: 1.6523 - AUC: 0.9861 - val_loss: 2.4211 - val_AUC: 0.7893\n",
      "Epoch 495/500\n",
      "5934/5934 [==============================] - 1s 104us/sample - loss: 1.6300 - AUC: 0.9904 - val_loss: 2.4197 - val_AUC: 0.7911\n",
      "Epoch 496/500\n",
      "5934/5934 [==============================] - 1s 113us/sample - loss: 1.6359 - AUC: 0.9885 - val_loss: 2.4074 - val_AUC: 0.7906\n",
      "Epoch 497/500\n",
      "5934/5934 [==============================] - 1s 106us/sample - loss: 1.6335 - AUC: 0.9878 - val_loss: 2.4078 - val_AUC: 0.7917\n",
      "Epoch 498/500\n",
      "5934/5934 [==============================] - 1s 109us/sample - loss: 1.6419 - AUC: 0.9854 - val_loss: 2.4007 - val_AUC: 0.7908\n",
      "Epoch 499/500\n",
      "5934/5934 [==============================] - 1s 107us/sample - loss: 1.6246 - AUC: 0.9890 - val_loss: 2.3782 - val_AUC: 0.7927\n",
      "Epoch 500/500\n",
      "5934/5934 [==============================] - 1s 115us/sample - loss: 1.6267 - AUC: 0.9873 - val_loss: 2.4073 - val_AUC: 0.7908\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, y, validation_data=(xv, yv),\n",
    "                 callbacks=[early_stop],\n",
    "                 epochs=500, batch_size=80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4d12161-b0ac-4f76-9f94-40f4f9002d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1fcb1b-15f9-491e-aef7-60504781bf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425443231184689"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(yt,model.predict(xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7795332b-b697-4cd1-8e47-4516335e20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.where(model.predict(xt)>0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e920cb-4b9f-46d1-b08b-908298fea8ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-87e033bea461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_savey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'smiles'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_smiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_savey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_savey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_classification_ames_nn.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_savey = pd.DataFrame(data={'smiles':list(x_smiles)})\n",
    "df_savey['y']=pred\n",
    "df_savey.to_csv('output_classification_ames_nn.csv',index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc41dd9-a77c-452a-aad8-446c9c591ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
