{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5622f572-8bc1-4abb-98d2-6ba9816047d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import sys\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "from deepchem.molnet.load_function.molnet_loader import TransformerGenerator, _MolnetLoader\n",
    "\n",
    "from deepchem.data import Dataset\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import catboost\n",
    "from catboost import *\n",
    "from catboost import datasets\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04941db1-531b-4711-b45a-82383a711a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import catboost\n",
    "from catboost import *\n",
    "from catboost import datasets\n",
    "feature_field=\"smiles\"\n",
    "TASKS = ['TOXRIC_Toxicity_Value', 'VirginiaSabando_Toxicity_Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334075a7-527d-4807-b968-c95512809386",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"/Solution/Ames/train_ames.csv\"\n",
    "task_dir = \"/Solution/Ames/\"\n",
    "task_save = \"/Solution/Ames/\"\n",
    "df = pd.read_csv(task)\n",
    "class MyLoader(_MolnetLoader):\n",
    "\n",
    "    def create_dataset(self) -> Dataset:\n",
    "        loader = dc.data.CSVLoader(tasks=self.tasks,\n",
    "                                   feature_field=feature_field,\n",
    "                                   featurizer=self.featurizer)\n",
    "        return loader.create_dataset(task, shard_size=8192)\n",
    "\n",
    "\n",
    "def load_tox21(\n",
    "    featurizer: Union[dc.feat.Featurizer, str] = 'ECFP',\n",
    "    splitter: Union[dc.splits.Splitter, str, None] = 'scaffold',\n",
    "    transformers: List[Union[TransformerGenerator, str]] = ['balancing'],\n",
    "    reload: bool = True,\n",
    "    data_dir: Optional[str] = task_dir,\n",
    "    save_dir: Optional[str] = task_save,\n",
    "    **kwargs\n",
    ") -> Tuple[List[str], Tuple[Dataset, ...], List[dc.trans.Transformer]]:\n",
    "    \n",
    "    loader = MyLoader(featurizer, splitter, transformers, TASKS,\n",
    "                          data_dir, save_dir, **kwargs)\n",
    "    return loader.load_dataset(task, reload)\n",
    "tasks, datasets, transformers = load_tox21()\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "df_tr = train_dataset.to_dataframe()\n",
    "\n",
    "df_t = test_dataset.to_dataframe()\n",
    "df_v = valid_dataset.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e4d327b-cb46-4d8c-be4d-3474c731c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_tr.drop(['y1','w1','w2','ids'],axis=1)\n",
    "y = df_tr['y1']\n",
    "xt = df_t.drop(['y1','w1','w2','ids'],axis=1)\n",
    " \n",
    "x_smiles = df_t['ids'].to_numpy()\n",
    "\n",
    "yt = df_t['y1']\n",
    "xv = df_v.drop(['y1','w1','w2','ids'],axis=1)\n",
    "\n",
    "yv = df_v['y1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b9a3f1-b1ee-4b79-bc4b-3bda7c8c44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len=len(x.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31267d2-3194-4dce-ace3-91255c80eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s):\n",
    "    K.clear_session()\n",
    "    seed_value= s\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(seed_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f237cbf6-a455-4066-81fe-63f3922bad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82938259-c61a-4ac6-8c9d-53188c284c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_len, len1, len2, len3, regular, activ_f,momentum_batch_norm):\n",
    "\n",
    "    #dropout\n",
    "    prob_h1 = 0.25\n",
    "    prob_h2 = 0.15\n",
    "    prob_h3 = 0.1\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(input_len), dtype='float32'))\n",
    "    model.add(keras.layers.Dense(len1, input_dim=input_len, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h1))\n",
    "\n",
    "    model.add(keras.layers.Dense(len2, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h2))\n",
    "    \n",
    "    model.add(keras.layers.Dense(len2, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h2))\n",
    "\n",
    "    model.add(keras.layers.Dense(len3, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h2))\n",
    "\n",
    "    model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd64e6e-dbd1-4714-930d-343dfc3e201a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               205200    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 219,561\n",
      "Trainable params: 218,941\n",
      "Non-trainable params: 620\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reg = tf.keras.regularizers.l1_l2(0.0008,0.0008)\n",
    "model = build_model(input_len,200,50,10,reg,'relu',0.9)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a5978f-a399-400c-8e83-ff066bc5fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(0.0001)\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['AUC'])\n",
    "# # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef972fdc-0557-4fc4-986a-471eaf773c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               205200    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 219,561\n",
      "Trainable params: 218,941\n",
      "Non-trainable params: 620\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9bb1ad9-f87e-43e5-a815-06f94091c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_history(hist):\n",
    "    acc = hist.history['AUC']\n",
    "    val_acc = hist.history['val_AUC']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, '-', label='AUC')\n",
    "    plt.plot(epochs, val_acc, ':', label='Validation AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c00f92-dc05-4254-81df-69d15bc845b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_delta_val = 0.0005\n",
    "patience_val = 1000\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=min_delta_val, \n",
    "                              patience=patience_val, \n",
    "                              verbose=0, \n",
    "                              mode='min',\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fbcc1b9-28e5-4d8c-adc5-16eb09871c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6529 samples, validate on 816 samples\n",
      "Epoch 1/500\n",
      "6240/6529 [===========================>..] - ETA: 0s - loss: 8.0646 - AUC: 0.4687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6529/6529 [==============================] - 3s 406us/sample - loss: 8.0647 - AUC: 0.4697 - val_loss: 7.9924 - val_AUC: 0.4441\n",
      "Epoch 2/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 8.0301 - AUC: 0.4703 - val_loss: 7.9427 - val_AUC: 0.4666\n",
      "Epoch 3/500\n",
      "6529/6529 [==============================] - 1s 150us/sample - loss: 7.9777 - AUC: 0.4825 - val_loss: 7.9054 - val_AUC: 0.4847\n",
      "Epoch 4/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 7.9349 - AUC: 0.5059 - val_loss: 7.8630 - val_AUC: 0.4967\n",
      "Epoch 5/500\n",
      "6529/6529 [==============================] - 1s 126us/sample - loss: 7.8810 - AUC: 0.5249 - val_loss: 7.8405 - val_AUC: 0.5126\n",
      "Epoch 6/500\n",
      "6529/6529 [==============================] - 1s 147us/sample - loss: 7.8640 - AUC: 0.5308 - val_loss: 7.8028 - val_AUC: 0.5289\n",
      "Epoch 7/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 7.8212 - AUC: 0.5416 - val_loss: 7.7854 - val_AUC: 0.5412\n",
      "Epoch 8/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 7.7895 - AUC: 0.5530 - val_loss: 7.7465 - val_AUC: 0.5556\n",
      "Epoch 9/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 7.7709 - AUC: 0.5588 - val_loss: 7.7279 - val_AUC: 0.5689\n",
      "Epoch 10/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 7.7203 - AUC: 0.5806 - val_loss: 7.6956 - val_AUC: 0.5828\n",
      "Epoch 11/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 7.7054 - AUC: 0.5829 - val_loss: 7.6777 - val_AUC: 0.5877\n",
      "Epoch 12/500\n",
      "6529/6529 [==============================] - 1s 151us/sample - loss: 7.6713 - AUC: 0.5904 - val_loss: 7.6444 - val_AUC: 0.5999\n",
      "Epoch 13/500\n",
      "6529/6529 [==============================] - 1s 144us/sample - loss: 7.6491 - AUC: 0.5968 - val_loss: 7.6130 - val_AUC: 0.6075\n",
      "Epoch 14/500\n",
      "6529/6529 [==============================] - 1s 144us/sample - loss: 7.6176 - AUC: 0.6114 - val_loss: 7.5967 - val_AUC: 0.6108\n",
      "Epoch 15/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 7.6047 - AUC: 0.6143 - val_loss: 7.5842 - val_AUC: 0.6206\n",
      "Epoch 16/500\n",
      "6529/6529 [==============================] - 1s 153us/sample - loss: 7.5693 - AUC: 0.6208 - val_loss: 7.5540 - val_AUC: 0.6265\n",
      "Epoch 17/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 7.5307 - AUC: 0.6398 - val_loss: 7.5357 - val_AUC: 0.6312\n",
      "Epoch 18/500\n",
      "6529/6529 [==============================] - 1s 154us/sample - loss: 7.5022 - AUC: 0.6484 - val_loss: 7.5093 - val_AUC: 0.6449\n",
      "Epoch 19/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 7.5039 - AUC: 0.6359 - val_loss: 7.4913 - val_AUC: 0.6493\n",
      "Epoch 20/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 7.4654 - AUC: 0.6513 - val_loss: 7.4596 - val_AUC: 0.6524\n",
      "Epoch 21/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 7.4471 - AUC: 0.6520 - val_loss: 7.4404 - val_AUC: 0.6609\n",
      "Epoch 22/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 7.4101 - AUC: 0.6703 - val_loss: 7.4245 - val_AUC: 0.6656\n",
      "Epoch 23/500\n",
      "6529/6529 [==============================] - 1s 144us/sample - loss: 7.3953 - AUC: 0.6650 - val_loss: 7.3955 - val_AUC: 0.6704\n",
      "Epoch 24/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 7.3672 - AUC: 0.6795 - val_loss: 7.3911 - val_AUC: 0.6711\n",
      "Epoch 25/500\n",
      "6529/6529 [==============================] - 1s 147us/sample - loss: 7.3297 - AUC: 0.6910 - val_loss: 7.3703 - val_AUC: 0.6785\n",
      "Epoch 26/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 7.3186 - AUC: 0.6882 - val_loss: 7.3455 - val_AUC: 0.6839\n",
      "Epoch 27/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 7.2943 - AUC: 0.6939 - val_loss: 7.3243 - val_AUC: 0.6859\n",
      "Epoch 28/500\n",
      "6529/6529 [==============================] - 1s 147us/sample - loss: 7.2709 - AUC: 0.6967 - val_loss: 7.3088 - val_AUC: 0.6912\n",
      "Epoch 29/500\n",
      "6529/6529 [==============================] - 1s 137us/sample - loss: 7.2451 - AUC: 0.7064 - val_loss: 7.2839 - val_AUC: 0.6945\n",
      "Epoch 30/500\n",
      "6529/6529 [==============================] - 1s 148us/sample - loss: 7.2311 - AUC: 0.7055 - val_loss: 7.2630 - val_AUC: 0.6948\n",
      "Epoch 31/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 7.2029 - AUC: 0.7146 - val_loss: 7.2560 - val_AUC: 0.6948\n",
      "Epoch 32/500\n",
      "6529/6529 [==============================] - 1s 151us/sample - loss: 7.1797 - AUC: 0.7169 - val_loss: 7.2188 - val_AUC: 0.7061\n",
      "Epoch 33/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 7.1670 - AUC: 0.7142 - val_loss: 7.2000 - val_AUC: 0.7100\n",
      "Epoch 34/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 7.1267 - AUC: 0.7322 - val_loss: 7.1738 - val_AUC: 0.7103\n",
      "Epoch 35/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 7.1196 - AUC: 0.7204 - val_loss: 7.1631 - val_AUC: 0.7084\n",
      "Epoch 36/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 7.0896 - AUC: 0.7325 - val_loss: 7.1377 - val_AUC: 0.7142\n",
      "Epoch 37/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 7.0649 - AUC: 0.7351 - val_loss: 7.1278 - val_AUC: 0.7188\n",
      "Epoch 38/500\n",
      "6529/6529 [==============================] - 1s 152us/sample - loss: 7.0524 - AUC: 0.7351 - val_loss: 7.0942 - val_AUC: 0.7193\n",
      "Epoch 39/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 7.0319 - AUC: 0.7353 - val_loss: 7.0806 - val_AUC: 0.7294\n",
      "Epoch 40/500\n",
      "6529/6529 [==============================] - 1s 148us/sample - loss: 6.9985 - AUC: 0.7467 - val_loss: 7.0472 - val_AUC: 0.7298\n",
      "Epoch 41/500\n",
      "6529/6529 [==============================] - 1s 144us/sample - loss: 6.9691 - AUC: 0.7538 - val_loss: 7.0455 - val_AUC: 0.7317\n",
      "Epoch 42/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 6.9672 - AUC: 0.7400 - val_loss: 7.0176 - val_AUC: 0.7343\n",
      "Epoch 43/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 6.9331 - AUC: 0.7574 - val_loss: 7.0004 - val_AUC: 0.7347\n",
      "Epoch 44/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 6.9110 - AUC: 0.7592 - val_loss: 6.9766 - val_AUC: 0.7426\n",
      "Epoch 45/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 6.8958 - AUC: 0.7505 - val_loss: 6.9430 - val_AUC: 0.7414\n",
      "Epoch 46/500\n",
      "6529/6529 [==============================] - 1s 137us/sample - loss: 6.8498 - AUC: 0.7768 - val_loss: 6.9374 - val_AUC: 0.7488\n",
      "Epoch 47/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 6.8432 - AUC: 0.7675 - val_loss: 6.9135 - val_AUC: 0.7442\n",
      "Epoch 48/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 6.8131 - AUC: 0.7743 - val_loss: 6.8855 - val_AUC: 0.7463\n",
      "Epoch 49/500\n",
      "6529/6529 [==============================] - 1s 139us/sample - loss: 6.7922 - AUC: 0.7772 - val_loss: 6.8678 - val_AUC: 0.7525\n",
      "Epoch 50/500\n",
      "6529/6529 [==============================] - 1s 150us/sample - loss: 6.7779 - AUC: 0.7740 - val_loss: 6.8456 - val_AUC: 0.7494\n",
      "Epoch 51/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 6.7549 - AUC: 0.7760 - val_loss: 6.8282 - val_AUC: 0.7556\n",
      "Epoch 52/500\n",
      "6529/6529 [==============================] - 1s 149us/sample - loss: 6.7330 - AUC: 0.7772 - val_loss: 6.7903 - val_AUC: 0.7593\n",
      "Epoch 53/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 6.7099 - AUC: 0.7822 - val_loss: 6.7930 - val_AUC: 0.7541\n",
      "Epoch 54/500\n",
      "6529/6529 [==============================] - 1s 154us/sample - loss: 6.6844 - AUC: 0.7864 - val_loss: 6.7667 - val_AUC: 0.7606\n",
      "Epoch 55/500\n",
      "6529/6529 [==============================] - 1s 137us/sample - loss: 6.6640 - AUC: 0.7861 - val_loss: 6.7401 - val_AUC: 0.7597\n",
      "Epoch 56/500\n",
      "6529/6529 [==============================] - 1s 154us/sample - loss: 6.6446 - AUC: 0.7880 - val_loss: 6.7214 - val_AUC: 0.7651\n",
      "Epoch 57/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 6.6051 - AUC: 0.8006 - val_loss: 6.7067 - val_AUC: 0.7655\n",
      "Epoch 58/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 6.5918 - AUC: 0.7948 - val_loss: 6.6730 - val_AUC: 0.7695\n",
      "Epoch 59/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 6.5582 - AUC: 0.8048 - val_loss: 6.6472 - val_AUC: 0.7689\n",
      "Epoch 60/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 6.5571 - AUC: 0.7918 - val_loss: 6.6239 - val_AUC: 0.7690\n",
      "Epoch 61/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 6.5229 - AUC: 0.8011 - val_loss: 6.6026 - val_AUC: 0.7775\n",
      "Epoch 62/500\n",
      "6529/6529 [==============================] - 1s 127us/sample - loss: 6.4969 - AUC: 0.8066 - val_loss: 6.5983 - val_AUC: 0.7722\n",
      "Epoch 63/500\n",
      "6529/6529 [==============================] - 1s 146us/sample - loss: 6.4835 - AUC: 0.8026 - val_loss: 6.5674 - val_AUC: 0.7743\n",
      "Epoch 64/500\n",
      "6529/6529 [==============================] - 1s 127us/sample - loss: 6.4439 - AUC: 0.8166 - val_loss: 6.5398 - val_AUC: 0.7778\n",
      "Epoch 65/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 6.4357 - AUC: 0.8070 - val_loss: 6.5133 - val_AUC: 0.7813\n",
      "Epoch 66/500\n",
      "6529/6529 [==============================] - 1s 127us/sample - loss: 6.4095 - AUC: 0.8100 - val_loss: 6.4986 - val_AUC: 0.7823\n",
      "Epoch 67/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 6.3821 - AUC: 0.8169 - val_loss: 6.4705 - val_AUC: 0.7842\n",
      "Epoch 68/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 6.3581 - AUC: 0.8194 - val_loss: 6.4493 - val_AUC: 0.7867\n",
      "Epoch 69/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 6.3374 - AUC: 0.8196 - val_loss: 6.4452 - val_AUC: 0.7850\n",
      "Epoch 70/500\n",
      "6529/6529 [==============================] - 1s 152us/sample - loss: 6.3116 - AUC: 0.8222 - val_loss: 6.4056 - val_AUC: 0.7892\n",
      "Epoch 71/500\n",
      "6529/6529 [==============================] - 1s 146us/sample - loss: 6.2872 - AUC: 0.8243 - val_loss: 6.3830 - val_AUC: 0.7908\n",
      "Epoch 72/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 6.2695 - AUC: 0.8244 - val_loss: 6.3674 - val_AUC: 0.7888\n",
      "Epoch 73/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 6.2422 - AUC: 0.8279 - val_loss: 6.3415 - val_AUC: 0.7925\n",
      "Epoch 74/500\n",
      "6529/6529 [==============================] - 1s 120us/sample - loss: 6.2265 - AUC: 0.8233 - val_loss: 6.3060 - val_AUC: 0.7938\n",
      "Epoch 75/500\n",
      "6529/6529 [==============================] - 1s 130us/sample - loss: 6.2074 - AUC: 0.8239 - val_loss: 6.3041 - val_AUC: 0.7939\n",
      "Epoch 76/500\n",
      "6529/6529 [==============================] - 1s 115us/sample - loss: 6.1719 - AUC: 0.8322 - val_loss: 6.2802 - val_AUC: 0.7957\n",
      "Epoch 77/500\n",
      "6529/6529 [==============================] - 1s 115us/sample - loss: 6.1528 - AUC: 0.8336 - val_loss: 6.2577 - val_AUC: 0.7950\n",
      "Epoch 78/500\n",
      "6529/6529 [==============================] - 1s 122us/sample - loss: 6.1233 - AUC: 0.8391 - val_loss: 6.2419 - val_AUC: 0.7960\n",
      "Epoch 79/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 6.1015 - AUC: 0.8381 - val_loss: 6.2098 - val_AUC: 0.7994\n",
      "Epoch 80/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 6.0786 - AUC: 0.8403 - val_loss: 6.1817 - val_AUC: 0.8019\n",
      "Epoch 81/500\n",
      "6529/6529 [==============================] - 1s 118us/sample - loss: 6.0573 - AUC: 0.8397 - val_loss: 6.1565 - val_AUC: 0.8037\n",
      "Epoch 82/500\n",
      "6529/6529 [==============================] - 1s 113us/sample - loss: 6.0303 - AUC: 0.8412 - val_loss: 6.1518 - val_AUC: 0.8004\n",
      "Epoch 83/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 5.9987 - AUC: 0.8502 - val_loss: 6.1231 - val_AUC: 0.8016\n",
      "Epoch 84/500\n",
      "6529/6529 [==============================] - 1s 137us/sample - loss: 5.9813 - AUC: 0.8459 - val_loss: 6.0879 - val_AUC: 0.8064\n",
      "Epoch 85/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 5.9670 - AUC: 0.8424 - val_loss: 6.0792 - val_AUC: 0.8058\n",
      "Epoch 86/500\n",
      "6529/6529 [==============================] - 1s 150us/sample - loss: 5.9406 - AUC: 0.8466 - val_loss: 6.0490 - val_AUC: 0.8075\n",
      "Epoch 87/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 5.9185 - AUC: 0.8459 - val_loss: 6.0342 - val_AUC: 0.8089\n",
      "Epoch 88/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 5.8893 - AUC: 0.8514 - val_loss: 6.0018 - val_AUC: 0.8088\n",
      "Epoch 89/500\n",
      "6529/6529 [==============================] - 1s 153us/sample - loss: 5.8680 - AUC: 0.8497 - val_loss: 5.9923 - val_AUC: 0.8081\n",
      "Epoch 90/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 5.8326 - AUC: 0.8615 - val_loss: 5.9525 - val_AUC: 0.8112\n",
      "Epoch 91/500\n",
      "6529/6529 [==============================] - 1s 146us/sample - loss: 5.8171 - AUC: 0.8574 - val_loss: 5.9417 - val_AUC: 0.8108\n",
      "Epoch 92/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 5.8002 - AUC: 0.8544 - val_loss: 5.9182 - val_AUC: 0.8123\n",
      "Epoch 93/500\n",
      "6529/6529 [==============================] - 1s 139us/sample - loss: 5.7724 - AUC: 0.8579 - val_loss: 5.9042 - val_AUC: 0.8113\n",
      "Epoch 94/500\n",
      "6529/6529 [==============================] - 1s 151us/sample - loss: 5.7505 - AUC: 0.8590 - val_loss: 5.8813 - val_AUC: 0.8151\n",
      "Epoch 95/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 5.7249 - AUC: 0.8625 - val_loss: 5.8431 - val_AUC: 0.8164\n",
      "Epoch 96/500\n",
      "6529/6529 [==============================] - 1s 154us/sample - loss: 5.7019 - AUC: 0.8624 - val_loss: 5.8318 - val_AUC: 0.8163\n",
      "Epoch 97/500\n",
      "6529/6529 [==============================] - 1s 137us/sample - loss: 5.6755 - AUC: 0.8656 - val_loss: 5.8125 - val_AUC: 0.8172\n",
      "Epoch 98/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 5.6554 - AUC: 0.8649 - val_loss: 5.7807 - val_AUC: 0.8172\n",
      "Epoch 99/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 5.6325 - AUC: 0.8644 - val_loss: 5.7619 - val_AUC: 0.8163\n",
      "Epoch 100/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 5.6059 - AUC: 0.8688 - val_loss: 5.7193 - val_AUC: 0.8201\n",
      "Epoch 101/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 5.5769 - AUC: 0.8744 - val_loss: 5.7224 - val_AUC: 0.8176\n",
      "Epoch 102/500\n",
      "6529/6529 [==============================] - 1s 132us/sample - loss: 5.5605 - AUC: 0.8690 - val_loss: 5.6919 - val_AUC: 0.8191\n",
      "Epoch 103/500\n",
      "6529/6529 [==============================] - 1s 146us/sample - loss: 5.5402 - AUC: 0.8693 - val_loss: 5.6773 - val_AUC: 0.8178\n",
      "Epoch 104/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 5.5174 - AUC: 0.8698 - val_loss: 5.6479 - val_AUC: 0.8189\n",
      "Epoch 105/500\n",
      "6529/6529 [==============================] - 1s 148us/sample - loss: 5.4979 - AUC: 0.8692 - val_loss: 5.6218 - val_AUC: 0.8219\n",
      "Epoch 106/500\n",
      "6529/6529 [==============================] - 1s 147us/sample - loss: 5.4544 - AUC: 0.8822 - val_loss: 5.6170 - val_AUC: 0.8222\n",
      "Epoch 107/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 5.4446 - AUC: 0.8767 - val_loss: 5.5761 - val_AUC: 0.8241\n",
      "Epoch 108/500\n",
      "6529/6529 [==============================] - 1s 148us/sample - loss: 5.4209 - AUC: 0.8777 - val_loss: 5.5713 - val_AUC: 0.8211\n",
      "Epoch 109/500\n",
      "6529/6529 [==============================] - 1s 139us/sample - loss: 5.3971 - AUC: 0.8794 - val_loss: 5.5284 - val_AUC: 0.8246\n",
      "Epoch 110/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 5.3768 - AUC: 0.8780 - val_loss: 5.5209 - val_AUC: 0.8233\n",
      "Epoch 111/500\n",
      "6529/6529 [==============================] - 1s 159us/sample - loss: 5.3527 - AUC: 0.8809 - val_loss: 5.4939 - val_AUC: 0.8251\n",
      "Epoch 112/500\n",
      "6529/6529 [==============================] - 1s 146us/sample - loss: 5.3270 - AUC: 0.8817 - val_loss: 5.4568 - val_AUC: 0.8263\n",
      "Epoch 113/500\n",
      "6529/6529 [==============================] - 1s 155us/sample - loss: 5.3053 - AUC: 0.8821 - val_loss: 5.4538 - val_AUC: 0.8249\n",
      "Epoch 114/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 5.2762 - AUC: 0.8871 - val_loss: 5.4375 - val_AUC: 0.8250\n",
      "Epoch 115/500\n",
      "6529/6529 [==============================] - 1s 147us/sample - loss: 5.2522 - AUC: 0.8904 - val_loss: 5.4212 - val_AUC: 0.8269\n",
      "Epoch 116/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 5.2395 - AUC: 0.8836 - val_loss: 5.3894 - val_AUC: 0.8273\n",
      "Epoch 117/500\n",
      "6529/6529 [==============================] - 1s 129us/sample - loss: 5.2060 - AUC: 0.8908 - val_loss: 5.3603 - val_AUC: 0.8275\n",
      "Epoch 118/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 5.1903 - AUC: 0.8876 - val_loss: 5.3412 - val_AUC: 0.8285\n",
      "Epoch 119/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 5.1618 - AUC: 0.8918 - val_loss: 5.3282 - val_AUC: 0.8289\n",
      "Epoch 120/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 5.1533 - AUC: 0.8860 - val_loss: 5.3077 - val_AUC: 0.8296\n",
      "Epoch 121/500\n",
      "6529/6529 [==============================] - 1s 139us/sample - loss: 5.1234 - AUC: 0.8897 - val_loss: 5.2838 - val_AUC: 0.8311\n",
      "Epoch 122/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 5.0981 - AUC: 0.8926 - val_loss: 5.2411 - val_AUC: 0.8322\n",
      "Epoch 123/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 5.0738 - AUC: 0.8943 - val_loss: 5.2382 - val_AUC: 0.8314\n",
      "Epoch 124/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 5.0565 - AUC: 0.8933 - val_loss: 5.2152 - val_AUC: 0.8300\n",
      "Epoch 125/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 5.0356 - AUC: 0.8920 - val_loss: 5.1993 - val_AUC: 0.8299\n",
      "Epoch 126/500\n",
      "6529/6529 [==============================] - 1s 152us/sample - loss: 5.0161 - AUC: 0.8920 - val_loss: 5.1706 - val_AUC: 0.8317\n",
      "Epoch 127/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 4.9956 - AUC: 0.8923 - val_loss: 5.1410 - val_AUC: 0.8346\n",
      "Epoch 128/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 4.9641 - AUC: 0.8985 - val_loss: 5.1261 - val_AUC: 0.8320\n",
      "Epoch 129/500\n",
      "6529/6529 [==============================] - 1s 147us/sample - loss: 4.9385 - AUC: 0.9008 - val_loss: 5.0981 - val_AUC: 0.8341\n",
      "Epoch 130/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 4.9207 - AUC: 0.8997 - val_loss: 5.0772 - val_AUC: 0.8347\n",
      "Epoch 131/500\n",
      "6529/6529 [==============================] - 1s 151us/sample - loss: 4.9045 - AUC: 0.8969 - val_loss: 5.0626 - val_AUC: 0.8337\n",
      "Epoch 132/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 4.8782 - AUC: 0.8997 - val_loss: 5.0353 - val_AUC: 0.8341\n",
      "Epoch 133/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 4.8533 - AUC: 0.9036 - val_loss: 5.0224 - val_AUC: 0.8351\n",
      "Epoch 134/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 4.8256 - AUC: 0.9075 - val_loss: 5.0223 - val_AUC: 0.8332\n",
      "Epoch 135/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 4.7984 - AUC: 0.9110 - val_loss: 4.9884 - val_AUC: 0.8362\n",
      "Epoch 136/500\n",
      "6529/6529 [==============================] - 1s 147us/sample - loss: 4.8010 - AUC: 0.8977 - val_loss: 4.9625 - val_AUC: 0.8363\n",
      "Epoch 137/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 4.7679 - AUC: 0.9051 - val_loss: 4.9412 - val_AUC: 0.8347\n",
      "Epoch 138/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 4.7516 - AUC: 0.9030 - val_loss: 4.9150 - val_AUC: 0.8367\n",
      "Epoch 139/500\n",
      "6529/6529 [==============================] - 1s 148us/sample - loss: 4.7201 - AUC: 0.9087 - val_loss: 4.9024 - val_AUC: 0.8360\n",
      "Epoch 140/500\n",
      "6529/6529 [==============================] - 1s 137us/sample - loss: 4.7129 - AUC: 0.9022 - val_loss: 4.8810 - val_AUC: 0.8367\n",
      "Epoch 141/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 4.6782 - AUC: 0.9114 - val_loss: 4.8609 - val_AUC: 0.8365\n",
      "Epoch 142/500\n",
      "6529/6529 [==============================] - 1s 146us/sample - loss: 4.6679 - AUC: 0.9058 - val_loss: 4.8365 - val_AUC: 0.8372\n",
      "Epoch 143/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 4.6408 - AUC: 0.9089 - val_loss: 4.8202 - val_AUC: 0.8369\n",
      "Epoch 144/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 4.6169 - AUC: 0.9115 - val_loss: 4.8005 - val_AUC: 0.8369\n",
      "Epoch 145/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 4.6083 - AUC: 0.9054 - val_loss: 4.7741 - val_AUC: 0.8382\n",
      "Epoch 146/500\n",
      "6529/6529 [==============================] - 1s 125us/sample - loss: 4.5729 - AUC: 0.9142 - val_loss: 4.7728 - val_AUC: 0.8371\n",
      "Epoch 147/500\n",
      "6529/6529 [==============================] - 1s 150us/sample - loss: 4.5570 - AUC: 0.9120 - val_loss: 4.7366 - val_AUC: 0.8399\n",
      "Epoch 148/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 4.5354 - AUC: 0.9135 - val_loss: 4.7404 - val_AUC: 0.8372\n",
      "Epoch 149/500\n",
      "6529/6529 [==============================] - 1s 144us/sample - loss: 4.5103 - AUC: 0.9169 - val_loss: 4.6894 - val_AUC: 0.8398\n",
      "Epoch 150/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 4.4877 - AUC: 0.9191 - val_loss: 4.6759 - val_AUC: 0.8396\n",
      "Epoch 151/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 4.4782 - AUC: 0.9128 - val_loss: 4.6568 - val_AUC: 0.8399\n",
      "Epoch 152/500\n",
      "6529/6529 [==============================] - 1s 160us/sample - loss: 4.4574 - AUC: 0.9142 - val_loss: 4.6430 - val_AUC: 0.8401\n",
      "Epoch 153/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 4.4320 - AUC: 0.9174 - val_loss: 4.6358 - val_AUC: 0.8406\n",
      "Epoch 154/500\n",
      "6529/6529 [==============================] - 1s 151us/sample - loss: 4.4079 - AUC: 0.9208 - val_loss: 4.6104 - val_AUC: 0.8408\n",
      "Epoch 155/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 4.3951 - AUC: 0.9176 - val_loss: 4.5975 - val_AUC: 0.8389\n",
      "Epoch 156/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 4.3751 - AUC: 0.9176 - val_loss: 4.5614 - val_AUC: 0.8414\n",
      "Epoch 157/500\n",
      "6529/6529 [==============================] - 1s 144us/sample - loss: 4.3536 - AUC: 0.9198 - val_loss: 4.5739 - val_AUC: 0.8391\n",
      "Epoch 158/500\n",
      "6529/6529 [==============================] - 1s 130us/sample - loss: 4.3299 - AUC: 0.9216 - val_loss: 4.5333 - val_AUC: 0.8413\n",
      "Epoch 159/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 4.3178 - AUC: 0.9186 - val_loss: 4.5255 - val_AUC: 0.8406\n",
      "Epoch 160/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 4.2903 - AUC: 0.9240 - val_loss: 4.5108 - val_AUC: 0.8391\n",
      "Epoch 161/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 4.2802 - AUC: 0.9180 - val_loss: 4.4808 - val_AUC: 0.8414\n",
      "Epoch 162/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 4.2619 - AUC: 0.9182 - val_loss: 4.4586 - val_AUC: 0.8409\n",
      "Epoch 163/500\n",
      "6529/6529 [==============================] - 1s 147us/sample - loss: 4.2403 - AUC: 0.9208 - val_loss: 4.4460 - val_AUC: 0.8419\n",
      "Epoch 164/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 4.2218 - AUC: 0.9212 - val_loss: 4.4158 - val_AUC: 0.8432\n",
      "Epoch 165/500\n",
      "6529/6529 [==============================] - 1s 156us/sample - loss: 4.2005 - AUC: 0.9225 - val_loss: 4.3957 - val_AUC: 0.8437\n",
      "Epoch 166/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 4.1749 - AUC: 0.9265 - val_loss: 4.3909 - val_AUC: 0.8415\n",
      "Epoch 167/500\n",
      "6529/6529 [==============================] - 1s 137us/sample - loss: 4.1725 - AUC: 0.9188 - val_loss: 4.3837 - val_AUC: 0.8407\n",
      "Epoch 168/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 4.1388 - AUC: 0.9261 - val_loss: 4.3568 - val_AUC: 0.8440\n",
      "Epoch 169/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 4.1174 - AUC: 0.9284 - val_loss: 4.3360 - val_AUC: 0.8436\n",
      "Epoch 170/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 4.1013 - AUC: 0.9276 - val_loss: 4.3174 - val_AUC: 0.8426\n",
      "Epoch 171/500\n",
      "6529/6529 [==============================] - 1s 151us/sample - loss: 4.0846 - AUC: 0.9273 - val_loss: 4.2976 - val_AUC: 0.8432\n",
      "Epoch 172/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 4.0626 - AUC: 0.9295 - val_loss: 4.2786 - val_AUC: 0.8426\n",
      "Epoch 173/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 4.0528 - AUC: 0.9253 - val_loss: 4.2629 - val_AUC: 0.8423\n",
      "Epoch 174/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 4.0342 - AUC: 0.9265 - val_loss: 4.2376 - val_AUC: 0.8437\n",
      "Epoch 175/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 4.0105 - AUC: 0.9297 - val_loss: 4.2220 - val_AUC: 0.8430\n",
      "Epoch 176/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 4.0027 - AUC: 0.9246 - val_loss: 4.1851 - val_AUC: 0.8458\n",
      "Epoch 177/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 3.9717 - AUC: 0.9326 - val_loss: 4.2054 - val_AUC: 0.8420\n",
      "Epoch 178/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 3.9612 - AUC: 0.9286 - val_loss: 4.1980 - val_AUC: 0.8427\n",
      "Epoch 179/500\n",
      "6529/6529 [==============================] - 1s 139us/sample - loss: 3.9356 - AUC: 0.9331 - val_loss: 4.1614 - val_AUC: 0.8421\n",
      "Epoch 180/500\n",
      "6529/6529 [==============================] - 1s 122us/sample - loss: 3.9174 - AUC: 0.9334 - val_loss: 4.1466 - val_AUC: 0.8434\n",
      "Epoch 181/500\n",
      "6529/6529 [==============================] - 1s 137us/sample - loss: 3.9030 - AUC: 0.9327 - val_loss: 4.1469 - val_AUC: 0.8442\n",
      "Epoch 182/500\n",
      "6529/6529 [==============================] - 1s 148us/sample - loss: 3.8860 - AUC: 0.9329 - val_loss: 4.1082 - val_AUC: 0.8441\n",
      "Epoch 183/500\n",
      "6529/6529 [==============================] - 1s 129us/sample - loss: 3.8665 - AUC: 0.9343 - val_loss: 4.1013 - val_AUC: 0.8426\n",
      "Epoch 184/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 3.8527 - AUC: 0.9335 - val_loss: 4.0988 - val_AUC: 0.8431\n",
      "Epoch 185/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 3.8260 - AUC: 0.9374 - val_loss: 4.0685 - val_AUC: 0.8431\n",
      "Epoch 186/500\n",
      "6529/6529 [==============================] - 1s 130us/sample - loss: 3.8182 - AUC: 0.9339 - val_loss: 4.0461 - val_AUC: 0.8443\n",
      "Epoch 187/500\n",
      "6529/6529 [==============================] - 1s 146us/sample - loss: 3.7953 - AUC: 0.9368 - val_loss: 4.0423 - val_AUC: 0.8439\n",
      "Epoch 188/500\n",
      "6529/6529 [==============================] - 1s 126us/sample - loss: 3.7762 - AUC: 0.9390 - val_loss: 4.0220 - val_AUC: 0.8429\n",
      "Epoch 189/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 3.7652 - AUC: 0.9362 - val_loss: 3.9982 - val_AUC: 0.8442\n",
      "Epoch 190/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 3.7457 - AUC: 0.9380 - val_loss: 3.9837 - val_AUC: 0.8446\n",
      "Epoch 191/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 3.7200 - AUC: 0.9419 - val_loss: 3.9617 - val_AUC: 0.8446\n",
      "Epoch 192/500\n",
      "6529/6529 [==============================] - 1s 125us/sample - loss: 3.7179 - AUC: 0.9361 - val_loss: 3.9425 - val_AUC: 0.8447\n",
      "Epoch 193/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 3.6966 - AUC: 0.9380 - val_loss: 3.9429 - val_AUC: 0.8446\n",
      "Epoch 194/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 3.6827 - AUC: 0.9373 - val_loss: 3.9190 - val_AUC: 0.8440\n",
      "Epoch 195/500\n",
      "6529/6529 [==============================] - 1s 126us/sample - loss: 3.6643 - AUC: 0.9384 - val_loss: 3.9229 - val_AUC: 0.8436\n",
      "Epoch 196/500\n",
      "6529/6529 [==============================] - 1s 158us/sample - loss: 3.6389 - AUC: 0.9441 - val_loss: 3.9003 - val_AUC: 0.8440\n",
      "Epoch 197/500\n",
      "6529/6529 [==============================] - 1s 127us/sample - loss: 3.6268 - AUC: 0.9419 - val_loss: 3.8817 - val_AUC: 0.8446\n",
      "Epoch 198/500\n",
      "6529/6529 [==============================] - 1s 139us/sample - loss: 3.6184 - AUC: 0.9386 - val_loss: 3.8733 - val_AUC: 0.8434\n",
      "Epoch 199/500\n",
      "6529/6529 [==============================] - 1s 154us/sample - loss: 3.5950 - AUC: 0.9422 - val_loss: 3.8407 - val_AUC: 0.8447\n",
      "Epoch 200/500\n",
      "6529/6529 [==============================] - 1s 130us/sample - loss: 3.5847 - AUC: 0.9402 - val_loss: 3.8329 - val_AUC: 0.8456\n",
      "Epoch 201/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 3.5712 - AUC: 0.9394 - val_loss: 3.8102 - val_AUC: 0.8448\n",
      "Epoch 202/500\n",
      "6529/6529 [==============================] - 1s 123us/sample - loss: 3.5491 - AUC: 0.9425 - val_loss: 3.8243 - val_AUC: 0.8429\n",
      "Epoch 203/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 3.5376 - AUC: 0.9411 - val_loss: 3.7834 - val_AUC: 0.8452\n",
      "Epoch 204/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 3.5172 - AUC: 0.9437 - val_loss: 3.7800 - val_AUC: 0.8441\n",
      "Epoch 205/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 3.5071 - AUC: 0.9420 - val_loss: 3.7527 - val_AUC: 0.8456\n",
      "Epoch 206/500\n",
      "6529/6529 [==============================] - 1s 123us/sample - loss: 3.4916 - AUC: 0.9420 - val_loss: 3.7316 - val_AUC: 0.8458\n",
      "Epoch 207/500\n",
      "6529/6529 [==============================] - 1s 156us/sample - loss: 3.4703 - AUC: 0.9456 - val_loss: 3.7303 - val_AUC: 0.8459\n",
      "Epoch 208/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 3.4581 - AUC: 0.9450 - val_loss: 3.7139 - val_AUC: 0.8444\n",
      "Epoch 209/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 3.4382 - AUC: 0.9472 - val_loss: 3.7050 - val_AUC: 0.8458\n",
      "Epoch 210/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 3.4325 - AUC: 0.9436 - val_loss: 3.6971 - val_AUC: 0.8457\n",
      "Epoch 211/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 3.4180 - AUC: 0.9438 - val_loss: 3.6937 - val_AUC: 0.8464\n",
      "Epoch 212/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 3.3911 - AUC: 0.9495 - val_loss: 3.6712 - val_AUC: 0.8451\n",
      "Epoch 213/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 3.3865 - AUC: 0.9457 - val_loss: 3.6426 - val_AUC: 0.8460\n",
      "Epoch 214/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 3.3744 - AUC: 0.9453 - val_loss: 3.6395 - val_AUC: 0.8459\n",
      "Epoch 215/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 3.3562 - AUC: 0.9467 - val_loss: 3.6266 - val_AUC: 0.8450\n",
      "Epoch 216/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 3.3470 - AUC: 0.9448 - val_loss: 3.6180 - val_AUC: 0.8457\n",
      "Epoch 217/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 3.3320 - AUC: 0.9454 - val_loss: 3.6071 - val_AUC: 0.8460\n",
      "Epoch 218/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 3.3099 - AUC: 0.9496 - val_loss: 3.6045 - val_AUC: 0.8458\n",
      "Epoch 219/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 3.3010 - AUC: 0.9475 - val_loss: 3.5786 - val_AUC: 0.8471\n",
      "Epoch 220/500\n",
      "6529/6529 [==============================] - 1s 144us/sample - loss: 3.2893 - AUC: 0.9462 - val_loss: 3.5764 - val_AUC: 0.8446\n",
      "Epoch 221/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 3.2711 - AUC: 0.9487 - val_loss: 3.5473 - val_AUC: 0.8463\n",
      "Epoch 222/500\n",
      "6529/6529 [==============================] - 1s 144us/sample - loss: 3.2578 - AUC: 0.9492 - val_loss: 3.5504 - val_AUC: 0.8446\n",
      "Epoch 223/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 3.2500 - AUC: 0.9463 - val_loss: 3.5373 - val_AUC: 0.8459\n",
      "Epoch 224/500\n",
      "6529/6529 [==============================] - 1s 148us/sample - loss: 3.2381 - AUC: 0.9464 - val_loss: 3.5135 - val_AUC: 0.8466\n",
      "Epoch 225/500\n",
      "6529/6529 [==============================] - 1s 127us/sample - loss: 3.2191 - AUC: 0.9494 - val_loss: 3.5040 - val_AUC: 0.8466\n",
      "Epoch 226/500\n",
      "6529/6529 [==============================] - 1s 150us/sample - loss: 3.2007 - AUC: 0.9511 - val_loss: 3.4884 - val_AUC: 0.8452\n",
      "Epoch 227/500\n",
      "6529/6529 [==============================] - 1s 150us/sample - loss: 3.1933 - AUC: 0.9502 - val_loss: 3.4823 - val_AUC: 0.8462\n",
      "Epoch 228/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 3.1797 - AUC: 0.9497 - val_loss: 3.4663 - val_AUC: 0.8463\n",
      "Epoch 229/500\n",
      "6529/6529 [==============================] - 1s 129us/sample - loss: 3.1625 - AUC: 0.9517 - val_loss: 3.4373 - val_AUC: 0.8464\n",
      "Epoch 230/500\n",
      "6529/6529 [==============================] - 1s 150us/sample - loss: 3.1556 - AUC: 0.9494 - val_loss: 3.4591 - val_AUC: 0.8455\n",
      "Epoch 231/500\n",
      "6529/6529 [==============================] - 1s 130us/sample - loss: 3.1411 - AUC: 0.9506 - val_loss: 3.4422 - val_AUC: 0.8458\n",
      "Epoch 232/500\n",
      "6529/6529 [==============================] - 1s 137us/sample - loss: 3.1177 - AUC: 0.9547 - val_loss: 3.4169 - val_AUC: 0.8463\n",
      "Epoch 233/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 3.1118 - AUC: 0.9529 - val_loss: 3.3993 - val_AUC: 0.8463\n",
      "Epoch 234/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 3.0940 - AUC: 0.9545 - val_loss: 3.3861 - val_AUC: 0.8446\n",
      "Epoch 235/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 3.0843 - AUC: 0.9543 - val_loss: 3.3801 - val_AUC: 0.8462\n",
      "Epoch 236/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 3.0771 - AUC: 0.9520 - val_loss: 3.3790 - val_AUC: 0.8469\n",
      "Epoch 237/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 3.0551 - AUC: 0.9564 - val_loss: 3.3693 - val_AUC: 0.8460\n",
      "Epoch 238/500\n",
      "6529/6529 [==============================] - 1s 150us/sample - loss: 3.0435 - AUC: 0.9562 - val_loss: 3.3628 - val_AUC: 0.8455\n",
      "Epoch 239/500\n",
      "6529/6529 [==============================] - 1s 127us/sample - loss: 3.0345 - AUC: 0.9547 - val_loss: 3.3438 - val_AUC: 0.8460\n",
      "Epoch 240/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 3.0191 - AUC: 0.9566 - val_loss: 3.3409 - val_AUC: 0.8452\n",
      "Epoch 241/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 3.0079 - AUC: 0.9566 - val_loss: 3.3297 - val_AUC: 0.8450\n",
      "Epoch 242/500\n",
      "6529/6529 [==============================] - 1s 146us/sample - loss: 3.0007 - AUC: 0.9543 - val_loss: 3.2989 - val_AUC: 0.8462\n",
      "Epoch 243/500\n",
      "6529/6529 [==============================] - 1s 124us/sample - loss: 2.9901 - AUC: 0.9542 - val_loss: 3.2904 - val_AUC: 0.8456\n",
      "Epoch 244/500\n",
      "6529/6529 [==============================] - 1s 146us/sample - loss: 2.9738 - AUC: 0.9566 - val_loss: 3.3011 - val_AUC: 0.8454\n",
      "Epoch 245/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 2.9652 - AUC: 0.9554 - val_loss: 3.2694 - val_AUC: 0.8470\n",
      "Epoch 246/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 2.9615 - AUC: 0.9521 - val_loss: 3.2909 - val_AUC: 0.8457\n",
      "Epoch 247/500\n",
      "6529/6529 [==============================] - 1s 139us/sample - loss: 2.9371 - AUC: 0.9578 - val_loss: 3.2657 - val_AUC: 0.8467\n",
      "Epoch 248/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 2.9296 - AUC: 0.9563 - val_loss: 3.2394 - val_AUC: 0.8465\n",
      "Epoch 249/500\n",
      "6529/6529 [==============================] - 1s 122us/sample - loss: 2.9165 - AUC: 0.9568 - val_loss: 3.2457 - val_AUC: 0.8456\n",
      "Epoch 250/500\n",
      "6529/6529 [==============================] - 1s 153us/sample - loss: 2.9081 - AUC: 0.9562 - val_loss: 3.2167 - val_AUC: 0.8466\n",
      "Epoch 251/500\n",
      "6529/6529 [==============================] - 1s 133us/sample - loss: 2.8925 - AUC: 0.9584 - val_loss: 3.2081 - val_AUC: 0.8470\n",
      "Epoch 252/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 2.8845 - AUC: 0.9574 - val_loss: 3.2156 - val_AUC: 0.8461\n",
      "Epoch 253/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 2.8830 - AUC: 0.9531 - val_loss: 3.1919 - val_AUC: 0.8469\n",
      "Epoch 254/500\n",
      "6529/6529 [==============================] - 1s 159us/sample - loss: 2.8594 - AUC: 0.9585 - val_loss: 3.1752 - val_AUC: 0.8466\n",
      "Epoch 255/500\n",
      "6529/6529 [==============================] - 1s 127us/sample - loss: 2.8416 - AUC: 0.9613 - val_loss: 3.1700 - val_AUC: 0.8470\n",
      "Epoch 256/500\n",
      "6529/6529 [==============================] - 1s 159us/sample - loss: 2.8341 - AUC: 0.9599 - val_loss: 3.1503 - val_AUC: 0.8463\n",
      "Epoch 257/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 2.8230 - AUC: 0.9603 - val_loss: 3.1540 - val_AUC: 0.8476\n",
      "Epoch 258/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 2.8112 - AUC: 0.9610 - val_loss: 3.1527 - val_AUC: 0.8464\n",
      "Epoch 259/500\n",
      "6529/6529 [==============================] - 1s 135us/sample - loss: 2.8048 - AUC: 0.9598 - val_loss: 3.1327 - val_AUC: 0.8468\n",
      "Epoch 260/500\n",
      "6529/6529 [==============================] - 1s 139us/sample - loss: 2.7997 - AUC: 0.9576 - val_loss: 3.1239 - val_AUC: 0.8477\n",
      "Epoch 261/500\n",
      "6529/6529 [==============================] - 1s 120us/sample - loss: 2.7754 - AUC: 0.9628 - val_loss: 3.1182 - val_AUC: 0.8456\n",
      "Epoch 262/500\n",
      "6529/6529 [==============================] - 1s 143us/sample - loss: 2.7767 - AUC: 0.9586 - val_loss: 3.1140 - val_AUC: 0.8476\n",
      "Epoch 263/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 2.7599 - AUC: 0.9615 - val_loss: 3.0878 - val_AUC: 0.8469\n",
      "Epoch 264/500\n",
      "6529/6529 [==============================] - 1s 132us/sample - loss: 2.7517 - AUC: 0.9610 - val_loss: 3.0966 - val_AUC: 0.8463\n",
      "Epoch 265/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 2.7436 - AUC: 0.9602 - val_loss: 3.0718 - val_AUC: 0.8479\n",
      "Epoch 266/500\n",
      "6529/6529 [==============================] - 1s 138us/sample - loss: 2.7305 - AUC: 0.9612 - val_loss: 3.0697 - val_AUC: 0.8451\n",
      "Epoch 267/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 2.7224 - AUC: 0.9611 - val_loss: 3.0578 - val_AUC: 0.8461\n",
      "Epoch 268/500\n",
      "6529/6529 [==============================] - 1s 151us/sample - loss: 2.7113 - AUC: 0.9614 - val_loss: 3.0591 - val_AUC: 0.8470\n",
      "Epoch 269/500\n",
      "6529/6529 [==============================] - 1s 132us/sample - loss: 2.6908 - AUC: 0.9657 - val_loss: 3.0362 - val_AUC: 0.8456\n",
      "Epoch 270/500\n",
      "6529/6529 [==============================] - 1s 125us/sample - loss: 2.6821 - AUC: 0.9653 - val_loss: 3.0293 - val_AUC: 0.8462\n",
      "Epoch 271/500\n",
      "6529/6529 [==============================] - 1s 150us/sample - loss: 2.6847 - AUC: 0.9608 - val_loss: 3.0215 - val_AUC: 0.8450\n",
      "Epoch 272/500\n",
      "6529/6529 [==============================] - 1s 122us/sample - loss: 2.6710 - AUC: 0.9623 - val_loss: 3.0054 - val_AUC: 0.8465\n",
      "Epoch 273/500\n",
      "6529/6529 [==============================] - 1s 147us/sample - loss: 2.6578 - AUC: 0.9640 - val_loss: 3.0093 - val_AUC: 0.8442\n",
      "Epoch 274/500\n",
      "6529/6529 [==============================] - 1s 128us/sample - loss: 2.6509 - AUC: 0.9628 - val_loss: 3.0108 - val_AUC: 0.8445\n",
      "Epoch 275/500\n",
      "6529/6529 [==============================] - 1s 131us/sample - loss: 2.6439 - AUC: 0.9623 - val_loss: 3.0179 - val_AUC: 0.8436\n",
      "Epoch 276/500\n",
      "6529/6529 [==============================] - 1s 126us/sample - loss: 2.6316 - AUC: 0.9633 - val_loss: 3.0092 - val_AUC: 0.8462\n",
      "Epoch 277/500\n",
      "6529/6529 [==============================] - 1s 152us/sample - loss: 2.6215 - AUC: 0.9636 - val_loss: 2.9782 - val_AUC: 0.8457\n",
      "Epoch 278/500\n",
      "6529/6529 [==============================] - 1s 132us/sample - loss: 2.6136 - AUC: 0.9632 - val_loss: 2.9568 - val_AUC: 0.8456\n",
      "Epoch 279/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 2.6041 - AUC: 0.9636 - val_loss: 2.9742 - val_AUC: 0.8473\n",
      "Epoch 280/500\n",
      "6529/6529 [==============================] - 1s 141us/sample - loss: 2.5974 - AUC: 0.9628 - val_loss: 2.9386 - val_AUC: 0.8457\n",
      "Epoch 281/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 2.5984 - AUC: 0.9596 - val_loss: 2.9434 - val_AUC: 0.8456\n",
      "Epoch 282/500\n",
      "6529/6529 [==============================] - 1s 125us/sample - loss: 2.5755 - AUC: 0.9644 - val_loss: 2.9256 - val_AUC: 0.8459\n",
      "Epoch 283/500\n",
      "6529/6529 [==============================] - 1s 127us/sample - loss: 2.5626 - AUC: 0.9657 - val_loss: 2.9396 - val_AUC: 0.8446\n",
      "Epoch 284/500\n",
      "6529/6529 [==============================] - 1s 145us/sample - loss: 2.5546 - AUC: 0.9659 - val_loss: 2.9156 - val_AUC: 0.8457\n",
      "Epoch 285/500\n",
      "6529/6529 [==============================] - 1s 118us/sample - loss: 2.5532 - AUC: 0.9636 - val_loss: 2.8996 - val_AUC: 0.8453\n",
      "Epoch 286/500\n",
      "6529/6529 [==============================] - 1s 142us/sample - loss: 2.5390 - AUC: 0.9651 - val_loss: 2.9017 - val_AUC: 0.8459\n",
      "Epoch 287/500\n",
      "6529/6529 [==============================] - 1s 144us/sample - loss: 2.5275 - AUC: 0.9665 - val_loss: 2.8874 - val_AUC: 0.8453\n",
      "Epoch 288/500\n",
      "6529/6529 [==============================] - 1s 134us/sample - loss: 2.5088 - AUC: 0.9700 - val_loss: 2.8902 - val_AUC: 0.8455\n",
      "Epoch 289/500\n",
      "6529/6529 [==============================] - 1s 126us/sample - loss: 2.5108 - AUC: 0.9668 - val_loss: 2.8949 - val_AUC: 0.8440\n",
      "Epoch 290/500\n",
      "6529/6529 [==============================] - 1s 140us/sample - loss: 2.5032 - AUC: 0.9661 - val_loss: 2.8802 - val_AUC: 0.8457\n",
      "Epoch 291/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 2.4983 - AUC: 0.9653 - val_loss: 2.8685 - val_AUC: 0.8454\n",
      "Epoch 292/500\n",
      "6529/6529 [==============================] - 1s 136us/sample - loss: 2.4925 - AUC: 0.9640 - val_loss: 2.8565 - val_AUC: 0.8463\n",
      "Epoch 293/500\n",
      "6529/6529 [==============================] - 1s 154us/sample - loss: 2.4782 - AUC: 0.9665 - val_loss: 2.8672 - val_AUC: 0.8446\n",
      "Epoch 294/500\n",
      "6529/6529 [==============================] - 1s 129us/sample - loss: 2.4667 - AUC: 0.9678 - val_loss: 2.8381 - val_AUC: 0.8441\n",
      "Epoch 295/500\n",
      "6529/6529 [==============================] - 1s 116us/sample - loss: 2.4521 - AUC: 0.9700 - val_loss: 2.8324 - val_AUC: 0.8460\n",
      "Epoch 296/500\n",
      "6529/6529 [==============================] - 1s 132us/sample - loss: 2.4527 - AUC: 0.9672 - val_loss: 2.8220 - val_AUC: 0.8450\n",
      "Epoch 297/500\n",
      "6529/6529 [==============================] - 1s 119us/sample - loss: 2.4513 - AUC: 0.9649 - val_loss: 2.8303 - val_AUC: 0.8438\n",
      "Epoch 298/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 2.4326 - AUC: 0.9687 - val_loss: 2.8197 - val_AUC: 0.8455\n",
      "Epoch 299/500\n",
      "6529/6529 [==============================] - 1s 115us/sample - loss: 2.4192 - AUC: 0.9705 - val_loss: 2.8180 - val_AUC: 0.8446\n",
      "Epoch 300/500\n",
      "6529/6529 [==============================] - 1s 132us/sample - loss: 2.4207 - AUC: 0.9674 - val_loss: 2.8253 - val_AUC: 0.8439\n",
      "Epoch 301/500\n",
      "6529/6529 [==============================] - 1s 115us/sample - loss: 2.4107 - AUC: 0.9680 - val_loss: 2.7950 - val_AUC: 0.8440\n",
      "Epoch 302/500\n",
      "6529/6529 [==============================] - 1s 115us/sample - loss: 2.3975 - AUC: 0.9704 - val_loss: 2.8003 - val_AUC: 0.8432\n",
      "Epoch 303/500\n",
      "6529/6529 [==============================] - 1s 115us/sample - loss: 2.3920 - AUC: 0.9693 - val_loss: 2.7844 - val_AUC: 0.8437\n",
      "Epoch 304/500\n",
      "6529/6529 [==============================] - 1s 120us/sample - loss: 2.3843 - AUC: 0.9696 - val_loss: 2.7777 - val_AUC: 0.8424\n",
      "Epoch 305/500\n",
      "6529/6529 [==============================] - 1s 115us/sample - loss: 2.3770 - AUC: 0.9693 - val_loss: 2.7747 - val_AUC: 0.8430\n",
      "Epoch 306/500\n",
      "6529/6529 [==============================] - 1s 120us/sample - loss: 2.3733 - AUC: 0.9681 - val_loss: 2.7618 - val_AUC: 0.8433\n",
      "Epoch 307/500\n",
      "6529/6529 [==============================] - 1s 126us/sample - loss: 2.3671 - AUC: 0.9678 - val_loss: 2.7629 - val_AUC: 0.8419\n",
      "Epoch 308/500\n",
      "6529/6529 [==============================] - 1s 116us/sample - loss: 2.3480 - AUC: 0.9720 - val_loss: 2.7500 - val_AUC: 0.8438\n",
      "Epoch 309/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 2.3484 - AUC: 0.9690 - val_loss: 2.7351 - val_AUC: 0.8423\n",
      "Epoch 310/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 2.2900 - AUC: 0.9679 - val_loss: 2.6889 - val_AUC: 0.8434\n",
      "Epoch 319/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 2.2763 - AUC: 0.9700 - val_loss: 2.6853 - val_AUC: 0.8430\n",
      "Epoch 320/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 2.2648 - AUC: 0.9720 - val_loss: 2.6760 - val_AUC: 0.8443\n",
      "Epoch 321/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 2.2578 - AUC: 0.9724 - val_loss: 2.6846 - val_AUC: 0.8431\n",
      "Epoch 322/500\n",
      "6529/6529 [==============================] - 1s 104us/sample - loss: 2.2519 - AUC: 0.9716 - val_loss: 2.6776 - val_AUC: 0.8438\n",
      "Epoch 323/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 2.2436 - AUC: 0.9721 - val_loss: 2.6632 - val_AUC: 0.8423\n",
      "Epoch 324/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 2.2315 - AUC: 0.9742 - val_loss: 2.6628 - val_AUC: 0.8428\n",
      "Epoch 325/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 2.2274 - AUC: 0.9730 - val_loss: 2.6617 - val_AUC: 0.8422\n",
      "Epoch 326/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 2.2278 - AUC: 0.9712 - val_loss: 2.6450 - val_AUC: 0.8422\n",
      "Epoch 327/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 2.2098 - AUC: 0.9749 - val_loss: 2.6478 - val_AUC: 0.8424\n",
      "Epoch 328/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 2.2101 - AUC: 0.9728 - val_loss: 2.6390 - val_AUC: 0.8424\n",
      "Epoch 329/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 2.2010 - AUC: 0.9737 - val_loss: 2.6426 - val_AUC: 0.8419\n",
      "Epoch 330/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 2.1979 - AUC: 0.9726 - val_loss: 2.6213 - val_AUC: 0.8424\n",
      "Epoch 331/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 2.1953 - AUC: 0.9714 - val_loss: 2.6317 - val_AUC: 0.8423\n",
      "Epoch 332/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 2.1824 - AUC: 0.9735 - val_loss: 2.6046 - val_AUC: 0.8424\n",
      "Epoch 333/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 2.1763 - AUC: 0.9737 - val_loss: 2.6250 - val_AUC: 0.8421\n",
      "Epoch 334/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 2.1689 - AUC: 0.9740 - val_loss: 2.5940 - val_AUC: 0.8434\n",
      "Epoch 335/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 2.1669 - AUC: 0.9726 - val_loss: 2.6044 - val_AUC: 0.8423\n",
      "Epoch 336/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 2.1592 - AUC: 0.9732 - val_loss: 2.5809 - val_AUC: 0.8419\n",
      "Epoch 337/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 2.1533 - AUC: 0.9735 - val_loss: 2.5941 - val_AUC: 0.8427\n",
      "Epoch 338/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 2.1390 - AUC: 0.9760 - val_loss: 2.5944 - val_AUC: 0.8412\n",
      "Epoch 339/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 2.1428 - AUC: 0.9729 - val_loss: 2.5748 - val_AUC: 0.8421\n",
      "Epoch 340/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 2.1252 - AUC: 0.9764 - val_loss: 2.5629 - val_AUC: 0.8416\n",
      "Epoch 341/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 2.1245 - AUC: 0.9747 - val_loss: 2.5781 - val_AUC: 0.8421\n",
      "Epoch 342/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 2.1172 - AUC: 0.9753 - val_loss: 2.5749 - val_AUC: 0.8426\n",
      "Epoch 343/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 2.1163 - AUC: 0.9741 - val_loss: 2.5657 - val_AUC: 0.8421\n",
      "Epoch 344/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 2.1094 - AUC: 0.9743 - val_loss: 2.5536 - val_AUC: 0.8405\n",
      "Epoch 345/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 2.1044 - AUC: 0.9739 - val_loss: 2.5488 - val_AUC: 0.8413\n",
      "Epoch 346/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 2.0928 - AUC: 0.9759 - val_loss: 2.5400 - val_AUC: 0.8408\n",
      "Epoch 347/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 2.0868 - AUC: 0.9761 - val_loss: 2.5315 - val_AUC: 0.8408\n",
      "Epoch 348/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 2.0808 - AUC: 0.9760 - val_loss: 2.5397 - val_AUC: 0.8412\n",
      "Epoch 349/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 2.0787 - AUC: 0.9750 - val_loss: 2.5225 - val_AUC: 0.8413\n",
      "Epoch 350/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 2.0721 - AUC: 0.9754 - val_loss: 2.5387 - val_AUC: 0.8416\n",
      "Epoch 351/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 2.0644 - AUC: 0.9758 - val_loss: 2.5167 - val_AUC: 0.8416\n",
      "Epoch 352/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 2.0608 - AUC: 0.9754 - val_loss: 2.5198 - val_AUC: 0.8426\n",
      "Epoch 353/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 2.0555 - AUC: 0.9752 - val_loss: 2.5223 - val_AUC: 0.8418\n",
      "Epoch 354/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 2.0513 - AUC: 0.9746 - val_loss: 2.5151 - val_AUC: 0.8401\n",
      "Epoch 355/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 2.0538 - AUC: 0.9726 - val_loss: 2.5110 - val_AUC: 0.8434\n",
      "Epoch 356/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 2.0279 - AUC: 0.9789 - val_loss: 2.4978 - val_AUC: 0.8422\n",
      "Epoch 357/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 2.0297 - AUC: 0.9770 - val_loss: 2.5110 - val_AUC: 0.8423\n",
      "Epoch 358/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 2.0260 - AUC: 0.9759 - val_loss: 2.4938 - val_AUC: 0.8426\n",
      "Epoch 359/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 2.0144 - AUC: 0.9776 - val_loss: 2.4972 - val_AUC: 0.8418\n",
      "Epoch 360/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 2.0176 - AUC: 0.9758 - val_loss: 2.4789 - val_AUC: 0.8427\n",
      "Epoch 361/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.9966 - AUC: 0.9798 - val_loss: 2.4864 - val_AUC: 0.8416\n",
      "Epoch 362/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 2.0003 - AUC: 0.9777 - val_loss: 2.4787 - val_AUC: 0.8423\n",
      "Epoch 363/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.9972 - AUC: 0.9768 - val_loss: 2.4563 - val_AUC: 0.8414\n",
      "Epoch 364/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.9947 - AUC: 0.9763 - val_loss: 2.4935 - val_AUC: 0.8409\n",
      "Epoch 365/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.9858 - AUC: 0.9776 - val_loss: 2.5027 - val_AUC: 0.8414\n",
      "Epoch 366/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.9875 - AUC: 0.9755 - val_loss: 2.4690 - val_AUC: 0.8422\n",
      "Epoch 367/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.9753 - AUC: 0.9774 - val_loss: 2.4536 - val_AUC: 0.8413\n",
      "Epoch 368/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.9691 - AUC: 0.9780 - val_loss: 2.4610 - val_AUC: 0.8408\n",
      "Epoch 369/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.9620 - AUC: 0.9782 - val_loss: 2.4590 - val_AUC: 0.8399\n",
      "Epoch 370/500\n",
      "6529/6529 [==============================] - 1s 104us/sample - loss: 1.9535 - AUC: 0.9799 - val_loss: 2.4365 - val_AUC: 0.8409\n",
      "Epoch 371/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.9474 - AUC: 0.9800 - val_loss: 2.4416 - val_AUC: 0.8412\n",
      "Epoch 372/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.9479 - AUC: 0.9786 - val_loss: 2.4286 - val_AUC: 0.8413\n",
      "Epoch 373/500\n",
      "6529/6529 [==============================] - 1s 104us/sample - loss: 1.9434 - AUC: 0.9783 - val_loss: 2.4178 - val_AUC: 0.8408\n",
      "Epoch 374/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.9414 - AUC: 0.9779 - val_loss: 2.4320 - val_AUC: 0.8409\n",
      "Epoch 375/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.9314 - AUC: 0.9791 - val_loss: 2.4394 - val_AUC: 0.8405\n",
      "Epoch 376/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.9296 - AUC: 0.9782 - val_loss: 2.4385 - val_AUC: 0.8408\n",
      "Epoch 377/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.9238 - AUC: 0.9786 - val_loss: 2.4094 - val_AUC: 0.8399\n",
      "Epoch 378/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.9199 - AUC: 0.9785 - val_loss: 2.4058 - val_AUC: 0.8411\n",
      "Epoch 379/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.9062 - AUC: 0.9808 - val_loss: 2.3943 - val_AUC: 0.8413\n",
      "Epoch 380/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.9125 - AUC: 0.9777 - val_loss: 2.4054 - val_AUC: 0.8419\n",
      "Epoch 381/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.9045 - AUC: 0.9790 - val_loss: 2.4010 - val_AUC: 0.8412\n",
      "Epoch 382/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.9014 - AUC: 0.9784 - val_loss: 2.4175 - val_AUC: 0.8410\n",
      "Epoch 383/500\n",
      "6529/6529 [==============================] - 1s 102us/sample - loss: 1.8924 - AUC: 0.9792 - val_loss: 2.3783 - val_AUC: 0.8388\n",
      "Epoch 384/500\n",
      "6529/6529 [==============================] - 1s 102us/sample - loss: 1.8834 - AUC: 0.9808 - val_loss: 2.3708 - val_AUC: 0.8409\n",
      "Epoch 385/500\n",
      "6529/6529 [==============================] - 1s 102us/sample - loss: 1.8823 - AUC: 0.9798 - val_loss: 2.3874 - val_AUC: 0.8401\n",
      "Epoch 386/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.8783 - AUC: 0.9799 - val_loss: 2.3971 - val_AUC: 0.8397\n",
      "Epoch 387/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.8709 - AUC: 0.9810 - val_loss: 2.3610 - val_AUC: 0.8405\n",
      "Epoch 388/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.8658 - AUC: 0.9806 - val_loss: 2.3595 - val_AUC: 0.8399\n",
      "Epoch 389/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.8676 - AUC: 0.9790 - val_loss: 2.3956 - val_AUC: 0.8401\n",
      "Epoch 390/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.8499 - AUC: 0.9824 - val_loss: 2.3690 - val_AUC: 0.8408\n",
      "Epoch 391/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 1.8525 - AUC: 0.9807 - val_loss: 2.3599 - val_AUC: 0.8408\n",
      "Epoch 392/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.8477 - AUC: 0.9809 - val_loss: 2.3467 - val_AUC: 0.8410\n",
      "Epoch 393/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.8454 - AUC: 0.9805 - val_loss: 2.3417 - val_AUC: 0.8398\n",
      "Epoch 394/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.8438 - AUC: 0.9797 - val_loss: 2.3752 - val_AUC: 0.8395\n",
      "Epoch 395/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 1.8316 - AUC: 0.9817 - val_loss: 2.3532 - val_AUC: 0.8393\n",
      "Epoch 396/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.8265 - AUC: 0.9818 - val_loss: 2.3456 - val_AUC: 0.8392\n",
      "Epoch 397/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.8217 - AUC: 0.9821 - val_loss: 2.3471 - val_AUC: 0.8397\n",
      "Epoch 398/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.8262 - AUC: 0.9798 - val_loss: 2.3364 - val_AUC: 0.8398\n",
      "Epoch 399/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.8158 - AUC: 0.9818 - val_loss: 2.3469 - val_AUC: 0.8381\n",
      "Epoch 400/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 1.8208 - AUC: 0.9793 - val_loss: 2.3456 - val_AUC: 0.8393\n",
      "Epoch 401/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.8012 - AUC: 0.9834 - val_loss: 2.3264 - val_AUC: 0.8386\n",
      "Epoch 402/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.7993 - AUC: 0.9826 - val_loss: 2.3424 - val_AUC: 0.8380\n",
      "Epoch 403/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.7947 - AUC: 0.9828 - val_loss: 2.3596 - val_AUC: 0.8378\n",
      "Epoch 404/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 1.7975 - AUC: 0.9814 - val_loss: 2.3531 - val_AUC: 0.8404\n",
      "Epoch 405/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 1.7912 - AUC: 0.9814 - val_loss: 2.3213 - val_AUC: 0.8386\n",
      "Epoch 406/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 1.7870 - AUC: 0.9817 - val_loss: 2.3194 - val_AUC: 0.8387\n",
      "Epoch 407/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 1.7772 - AUC: 0.9829 - val_loss: 2.3106 - val_AUC: 0.8375\n",
      "Epoch 408/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 1.7738 - AUC: 0.9831 - val_loss: 2.3348 - val_AUC: 0.8375\n",
      "Epoch 409/500\n",
      "6529/6529 [==============================] - 1s 113us/sample - loss: 1.7763 - AUC: 0.9812 - val_loss: 2.3152 - val_AUC: 0.8369\n",
      "Epoch 410/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.7668 - AUC: 0.9825 - val_loss: 2.3137 - val_AUC: 0.8389\n",
      "Epoch 411/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.7685 - AUC: 0.9809 - val_loss: 2.2930 - val_AUC: 0.8364\n",
      "Epoch 412/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.7613 - AUC: 0.9819 - val_loss: 2.3211 - val_AUC: 0.8381\n",
      "Epoch 413/500\n",
      "6529/6529 [==============================] - 1s 113us/sample - loss: 1.7547 - AUC: 0.9825 - val_loss: 2.2934 - val_AUC: 0.8370\n",
      "Epoch 414/500\n",
      "6529/6529 [==============================] - 1s 114us/sample - loss: 1.7579 - AUC: 0.9812 - val_loss: 2.2838 - val_AUC: 0.8389\n",
      "Epoch 415/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.7513 - AUC: 0.9818 - val_loss: 2.3030 - val_AUC: 0.8371\n",
      "Epoch 416/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.7414 - AUC: 0.9835 - val_loss: 2.2933 - val_AUC: 0.8390\n",
      "Epoch 417/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.7404 - AUC: 0.9826 - val_loss: 2.3051 - val_AUC: 0.8391\n",
      "Epoch 418/500\n",
      "6529/6529 [==============================] - 1s 114us/sample - loss: 1.7254 - AUC: 0.9852 - val_loss: 2.3154 - val_AUC: 0.8386\n",
      "Epoch 419/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.7295 - AUC: 0.9830 - val_loss: 2.2816 - val_AUC: 0.8363\n",
      "Epoch 420/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.7299 - AUC: 0.9824 - val_loss: 2.2925 - val_AUC: 0.8371\n",
      "Epoch 421/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.7224 - AUC: 0.9835 - val_loss: 2.2616 - val_AUC: 0.8395\n",
      "Epoch 422/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.7254 - AUC: 0.9819 - val_loss: 2.2534 - val_AUC: 0.8399\n",
      "Epoch 423/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.7212 - AUC: 0.9822 - val_loss: 2.3047 - val_AUC: 0.8383\n",
      "Epoch 424/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.7092 - AUC: 0.9839 - val_loss: 2.2570 - val_AUC: 0.8370\n",
      "Epoch 425/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.7048 - AUC: 0.9840 - val_loss: 2.2546 - val_AUC: 0.8362\n",
      "Epoch 426/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.7081 - AUC: 0.9824 - val_loss: 2.2363 - val_AUC: 0.8391\n",
      "Epoch 427/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.6961 - AUC: 0.9842 - val_loss: 2.2803 - val_AUC: 0.8376\n",
      "Epoch 428/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.6913 - AUC: 0.9849 - val_loss: 2.2602 - val_AUC: 0.8376\n",
      "Epoch 429/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 1.6925 - AUC: 0.9833 - val_loss: 2.2477 - val_AUC: 0.8368\n",
      "Epoch 430/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 1.6834 - AUC: 0.9849 - val_loss: 2.2345 - val_AUC: 0.8376\n",
      "Epoch 431/500\n",
      "6529/6529 [==============================] - 1s 104us/sample - loss: 1.6845 - AUC: 0.9839 - val_loss: 2.2440 - val_AUC: 0.8377\n",
      "Epoch 432/500\n",
      "6529/6529 [==============================] - 1s 104us/sample - loss: 1.6791 - AUC: 0.9842 - val_loss: 2.2644 - val_AUC: 0.8370\n",
      "Epoch 433/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.6821 - AUC: 0.9831 - val_loss: 2.2543 - val_AUC: 0.8383\n",
      "Epoch 434/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.6717 - AUC: 0.9846 - val_loss: 2.2478 - val_AUC: 0.8361\n",
      "Epoch 435/500\n",
      "6529/6529 [==============================] - 1s 104us/sample - loss: 1.6693 - AUC: 0.9839 - val_loss: 2.2516 - val_AUC: 0.8369\n",
      "Epoch 436/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.6666 - AUC: 0.9841 - val_loss: 2.2228 - val_AUC: 0.8364\n",
      "Epoch 437/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.6542 - AUC: 0.9862 - val_loss: 2.2468 - val_AUC: 0.8351\n",
      "Epoch 438/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.6551 - AUC: 0.9850 - val_loss: 2.2607 - val_AUC: 0.8354\n",
      "Epoch 439/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.6530 - AUC: 0.9846 - val_loss: 2.2234 - val_AUC: 0.8373\n",
      "Epoch 440/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.6514 - AUC: 0.9844 - val_loss: 2.2505 - val_AUC: 0.8379\n",
      "Epoch 441/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 1.6448 - AUC: 0.9852 - val_loss: 2.2174 - val_AUC: 0.8380\n",
      "Epoch 442/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 1.6346 - AUC: 0.9868 - val_loss: 2.2161 - val_AUC: 0.8379\n",
      "Epoch 443/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.6397 - AUC: 0.9851 - val_loss: 2.2148 - val_AUC: 0.8380\n",
      "Epoch 444/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.6335 - AUC: 0.9855 - val_loss: 2.2191 - val_AUC: 0.8365\n",
      "Epoch 445/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.6305 - AUC: 0.9854 - val_loss: 2.2160 - val_AUC: 0.8385\n",
      "Epoch 446/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.6201 - AUC: 0.9869 - val_loss: 2.2100 - val_AUC: 0.8374\n",
      "Epoch 447/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.6213 - AUC: 0.9861 - val_loss: 2.2249 - val_AUC: 0.8370\n",
      "Epoch 448/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.6186 - AUC: 0.9856 - val_loss: 2.1984 - val_AUC: 0.8371\n",
      "Epoch 449/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 1.6167 - AUC: 0.9857 - val_loss: 2.2205 - val_AUC: 0.8362\n",
      "Epoch 450/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.6153 - AUC: 0.9850 - val_loss: 2.2105 - val_AUC: 0.8375\n",
      "Epoch 451/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.6110 - AUC: 0.9854 - val_loss: 2.2075 - val_AUC: 0.8382\n",
      "Epoch 452/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.6114 - AUC: 0.9842 - val_loss: 2.2219 - val_AUC: 0.8369\n",
      "Epoch 453/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.6019 - AUC: 0.9860 - val_loss: 2.2279 - val_AUC: 0.8345\n",
      "Epoch 454/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.6026 - AUC: 0.9853 - val_loss: 2.1825 - val_AUC: 0.8365\n",
      "Epoch 455/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.5943 - AUC: 0.9861 - val_loss: 2.2071 - val_AUC: 0.8352\n",
      "Epoch 456/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.5925 - AUC: 0.9861 - val_loss: 2.2146 - val_AUC: 0.8353\n",
      "Epoch 457/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.5851 - AUC: 0.9868 - val_loss: 2.1904 - val_AUC: 0.8373\n",
      "Epoch 458/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.5835 - AUC: 0.9865 - val_loss: 2.1804 - val_AUC: 0.8332\n",
      "Epoch 459/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.5858 - AUC: 0.9853 - val_loss: 2.1830 - val_AUC: 0.8357\n",
      "Epoch 460/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.5735 - AUC: 0.9877 - val_loss: 2.1925 - val_AUC: 0.8348\n",
      "Epoch 461/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.5806 - AUC: 0.9852 - val_loss: 2.2022 - val_AUC: 0.8357\n",
      "Epoch 462/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.5670 - AUC: 0.9874 - val_loss: 2.1721 - val_AUC: 0.8355\n",
      "Epoch 463/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 1.5673 - AUC: 0.9867 - val_loss: 2.1776 - val_AUC: 0.8382\n",
      "Epoch 464/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.5662 - AUC: 0.9863 - val_loss: 2.1898 - val_AUC: 0.8358\n",
      "Epoch 465/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.5711 - AUC: 0.9849 - val_loss: 2.1650 - val_AUC: 0.8357\n",
      "Epoch 466/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.5599 - AUC: 0.9866 - val_loss: 2.1796 - val_AUC: 0.8347\n",
      "Epoch 467/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.5518 - AUC: 0.9873 - val_loss: 2.1655 - val_AUC: 0.8354\n",
      "Epoch 468/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.5554 - AUC: 0.9861 - val_loss: 2.1887 - val_AUC: 0.8344\n",
      "Epoch 469/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.5437 - AUC: 0.9879 - val_loss: 2.1776 - val_AUC: 0.8342\n",
      "Epoch 470/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.5391 - AUC: 0.9882 - val_loss: 2.1610 - val_AUC: 0.8345\n",
      "Epoch 471/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.5467 - AUC: 0.9862 - val_loss: 2.1605 - val_AUC: 0.8346\n",
      "Epoch 472/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.5345 - AUC: 0.9878 - val_loss: 2.1371 - val_AUC: 0.8360\n",
      "Epoch 473/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.5346 - AUC: 0.9872 - val_loss: 2.1583 - val_AUC: 0.8339\n",
      "Epoch 474/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.5399 - AUC: 0.9858 - val_loss: 2.1275 - val_AUC: 0.8363\n",
      "Epoch 475/500\n",
      "6529/6529 [==============================] - 1s 112us/sample - loss: 1.5379 - AUC: 0.9853 - val_loss: 2.1698 - val_AUC: 0.8346\n",
      "Epoch 476/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.5230 - AUC: 0.9880 - val_loss: 2.1364 - val_AUC: 0.8366\n",
      "Epoch 477/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.5345 - AUC: 0.9851 - val_loss: 2.1357 - val_AUC: 0.8363\n",
      "Epoch 478/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.5198 - AUC: 0.9877 - val_loss: 2.1348 - val_AUC: 0.8370\n",
      "Epoch 479/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.5216 - AUC: 0.9863 - val_loss: 2.1556 - val_AUC: 0.8360\n",
      "Epoch 480/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.5081 - AUC: 0.9886 - val_loss: 2.1465 - val_AUC: 0.8355\n",
      "Epoch 481/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.5047 - AUC: 0.9889 - val_loss: 2.1430 - val_AUC: 0.8346\n",
      "Epoch 482/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.5073 - AUC: 0.9875 - val_loss: 2.1316 - val_AUC: 0.8340\n",
      "Epoch 483/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.5049 - AUC: 0.9876 - val_loss: 2.1600 - val_AUC: 0.8340\n",
      "Epoch 484/500\n",
      "6529/6529 [==============================] - 1s 111us/sample - loss: 1.5021 - AUC: 0.9872 - val_loss: 2.1389 - val_AUC: 0.8341\n",
      "Epoch 485/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.4973 - AUC: 0.9879 - val_loss: 2.1424 - val_AUC: 0.8342\n",
      "Epoch 486/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.4926 - AUC: 0.9879 - val_loss: 2.1168 - val_AUC: 0.8341\n",
      "Epoch 487/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.4905 - AUC: 0.9880 - val_loss: 2.1233 - val_AUC: 0.8346\n",
      "Epoch 488/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.4874 - AUC: 0.9885 - val_loss: 2.1190 - val_AUC: 0.8332\n",
      "Epoch 489/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.4862 - AUC: 0.9883 - val_loss: 2.1290 - val_AUC: 0.8343\n",
      "Epoch 490/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.4884 - AUC: 0.9869 - val_loss: 2.1549 - val_AUC: 0.8328\n",
      "Epoch 491/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.4923 - AUC: 0.9857 - val_loss: 2.1468 - val_AUC: 0.8339\n",
      "Epoch 492/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.4794 - AUC: 0.9878 - val_loss: 2.1357 - val_AUC: 0.8328\n",
      "Epoch 493/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.4762 - AUC: 0.9882 - val_loss: 2.1250 - val_AUC: 0.8323\n",
      "Epoch 494/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.4806 - AUC: 0.9863 - val_loss: 2.1420 - val_AUC: 0.8329\n",
      "Epoch 495/500\n",
      "6529/6529 [==============================] - 1s 107us/sample - loss: 1.4736 - AUC: 0.9873 - val_loss: 2.1363 - val_AUC: 0.8326\n",
      "Epoch 496/500\n",
      "6529/6529 [==============================] - 1s 106us/sample - loss: 1.4657 - AUC: 0.9887 - val_loss: 2.1070 - val_AUC: 0.8307\n",
      "Epoch 497/500\n",
      "6529/6529 [==============================] - 1s 105us/sample - loss: 1.4542 - AUC: 0.9899 - val_loss: 2.1232 - val_AUC: 0.8322\n",
      "Epoch 498/500\n",
      "6529/6529 [==============================] - 1s 108us/sample - loss: 1.4609 - AUC: 0.9886 - val_loss: 2.1279 - val_AUC: 0.8318\n",
      "Epoch 499/500\n",
      "6529/6529 [==============================] - 1s 109us/sample - loss: 1.4554 - AUC: 0.9889 - val_loss: 2.1227 - val_AUC: 0.8306\n",
      "Epoch 500/500\n",
      "6529/6529 [==============================] - 1s 110us/sample - loss: 1.4471 - AUC: 0.9901 - val_loss: 2.1374 - val_AUC: 0.8319\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, y, validation_data=(xv, yv),\n",
    "                 callbacks=[early_stop],\n",
    "                 epochs=500, batch_size=80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4d12161-b0ac-4f76-9f94-40f4f9002d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca1fcb1b-15f9-491e-aef7-60504781bf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7491515871017256"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(yt,model.predict(xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7795332b-b697-4cd1-8e47-4516335e20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.where(model.predict(xt)>0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93e920cb-4b9f-46d1-b08b-908298fea8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_savey = pd.DataFrame(data={'smiles':list(x_smiles)})\n",
    "df_savey['y']=pred\n",
    "df_savey.to_csv('output_classification_ames_nn.csv',index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc41dd9-a77c-452a-aad8-446c9c591ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
