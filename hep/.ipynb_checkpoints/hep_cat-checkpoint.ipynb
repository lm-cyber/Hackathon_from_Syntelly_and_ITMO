{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5622f572-8bc1-4abb-98d2-6ba9816047d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre deepchem\n",
    "!pip install --user --upgrade catboost\n",
    "!pip install --user --upgrade ipywidgets\n",
    "!pip install shap\n",
    "!pip install sklearn\n",
    "!pip install --upgrade numpy\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c91b42-1cac-4a69-b641-e4a35d09f0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py:119: PkgResourcesDeprecationWarning: 0.18ubuntu0.18.04.1 is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "from deepchem.molnet.load_function.molnet_loader import TransformerGenerator, _MolnetLoader\n",
    "\n",
    "from deepchem.data import Dataset\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import catboost\n",
    "from catboost import *\n",
    "from catboost import datasets\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c72caad-0a1b-4b7d-ae63-40bce249a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Solution/hep/\"\n",
    "save_dir = \"/Solution/hep/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4069eb0f-0303-460d-b52d-85223157a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"hep\"\n",
    "data_hep = \"/Solution/hep/train_hep.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02195ca-7b44-4e93-99ce-6931738eb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_field=\"smiles\"\n",
    "TASKS = ['TOXRIC_Toxicity Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89dd7e1d-95a6-4181-b976-d59030b17752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLoader(_MolnetLoader):\n",
    "\n",
    "    def create_dataset(self) -> Dataset:\n",
    "        loader = dc.data.CSVLoader(tasks=self.tasks,\n",
    "                                   feature_field=feature_field,\n",
    "                                   featurizer=self.featurizer)\n",
    "        return loader.create_dataset(data_hep, shard_size=8192)\n",
    "\n",
    "\n",
    "def load_tox21(\n",
    "    featurizer: Union[dc.feat.Featurizer, str] = 'ECFP',\n",
    "    splitter: Union[dc.splits.Splitter, str, None] = 'scaffold',\n",
    "    transformers: List[Union[TransformerGenerator, str]] = ['balancing'],\n",
    "    reload: bool = True,\n",
    "    data_dir: Optional[str] = data_dir,\n",
    "    save_dir: Optional[str] = save_dir,\n",
    "    **kwargs\n",
    ") -> Tuple[List[str], Tuple[Dataset, ...], List[dc.trans.Transformer]]:\n",
    "    \n",
    "    loader = MyLoader(featurizer, splitter, transformers, TASKS,\n",
    "                          data_dir, save_dir, **kwargs)\n",
    "    return loader.load_dataset(task, reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d0adc37-0b65-48f7-b2fb-3f804c1d20d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to featurize datapoint 3, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 117, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 302, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 653, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 724, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 729, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 870, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 975, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1182, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1252, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1309, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1415, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1427, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1556, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1614, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1712, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1713, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1714, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1715, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1741, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1813, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1836, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1962, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 1989, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2028, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2049, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2165, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2166, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2170, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2173, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2195, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2230, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2268, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2279, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2302, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2318, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2331, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2407, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2409, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2480, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2500, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "Failed to featurize datapoint 2554, . Appending empty array\n",
      "Exception message: newOrder argument must be non-empty\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "tasks, datasets, transformers = load_tox21()\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a51b895b-16c4-4dda-ae33-106511111c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = train_dataset.to_dataframe()\n",
    "df_t = test_dataset.to_dataframe()\n",
    "df_v = valid_dataset.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e4d327b-cb46-4d8c-be4d-3474c731c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_tr.drop(['y','w','ids'],axis=1)\n",
    "y = df_tr['y']\n",
    "xt = df_t.drop(['y','w','ids'],axis=1)\n",
    " \n",
    "x_smiles = df_t['ids'].to_numpy()\n",
    "\n",
    "yt = df_t['y']\n",
    "xv = df_v.drop(['y','w','ids'],axis=1)\n",
    "\n",
    "yv = df_v['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31267d2-3194-4dce-ace3-91255c80eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s):\n",
    "    seed_value= s\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f237cbf6-a455-4066-81fe-63f3922bad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bb1ad9-f87e-43e5-a815-06f94091c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_history(hist):\n",
    "    acc = hist.history['AUC']\n",
    "    val_acc = hist.history['val_AUC']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, '-', label='AUC')\n",
    "    plt.plot(epochs, val_acc, ':', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61e04477-3e03-4d07-a677-35398b3fb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = list(range(x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f092187-8201-4ef6-8e73-85c3a9ab8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(data=x, label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad3dbf70-b3e8-4830-b4c2-84849bf7ec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374c3312464e42cf98fd968325d9286d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-32f397194da4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5128\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   5129\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5130\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0m\u001b[1;32m   5131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2360\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2361\u001b[0m             )\n\u001b[1;32m   2362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100000,\n",
    "    learning_rate=0.001,\n",
    "    loss_function='CrossEntropy',\n",
    "    eval_metric='AUC',\n",
    "    early_stopping_rounds=2000,\n",
    "    \n",
    "    # weight=w\n",
    "        # stratify=True\n",
    "\n",
    "\n",
    "    # task_type=\"GPU\"\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x, y,\n",
    "    # cat_features=cat_features,\n",
    "    eval_set=(xv, yv),\n",
    "    verbose=False,\n",
    "    plot=True,\n",
    "\n",
    ")\n",
    "print('Model is fitted: ' + str(model.is_fitted()))\n",
    "print('Model params:')\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffeed3b9-7da8-4230-8410-99225f2824d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8309366689648381"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yt,model.predict_proba(xt)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1bcf6da-674b-4a58-954d-4d764296d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(xt)\n",
    "df_savey = pd.DataFrame(data={'smiles':list(x_smiles)})\n",
    "df_savey['y']=pred\n",
    "df_savey.to_csv('output_classification_hep_catboost.csv',index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6706ba-b8b1-49b0-893e-540f1989dc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
