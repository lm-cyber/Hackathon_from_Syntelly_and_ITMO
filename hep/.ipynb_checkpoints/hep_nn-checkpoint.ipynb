{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5622f572-8bc1-4abb-98d2-6ba9816047d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "from deepchem.molnet.load_function.molnet_loader import TransformerGenerator, _MolnetLoader\n",
    "\n",
    "from deepchem.data import Dataset\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c641da8-9893-4818-a47f-551d28186adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Solution/hep/\"\n",
    "save_dir = \"/Solution/hep/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671fa5a-168a-477e-a329-04b1ae98a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"hep\"\n",
    "data_hep = \"/Solution/hep/train_hep.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca7e840-341f-4550-9d00-54bfc952c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_field=\"smiles\"\n",
    "TASKS = ['TOXRIC_Toxicity Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b3085-bd3a-4329-a8bf-d71895cc93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLoader(_MolnetLoader):\n",
    "\n",
    "    def create_dataset(self) -> Dataset:\n",
    "        loader = dc.data.CSVLoader(tasks=self.tasks,\n",
    "                                   feature_field=feature_field,\n",
    "                                   featurizer=self.featurizer)\n",
    "        return loader.create_dataset(data_hep, shard_size=8192)\n",
    "\n",
    "\n",
    "def load_tox21(\n",
    "    featurizer: Union[dc.feat.Featurizer, str] = 'ECFP',\n",
    "    splitter: Union[dc.splits.Splitter, str, None] = 'scaffold',\n",
    "    transformers: List[Union[TransformerGenerator, str]] = ['balancing'],\n",
    "    reload: bool = True,\n",
    "    data_dir: Optional[str] = data_dir,\n",
    "    save_dir: Optional[str] = save_dir,\n",
    "    **kwargs\n",
    ") -> Tuple[List[str], Tuple[Dataset, ...], List[dc.trans.Transformer]]:\n",
    "    \n",
    "    loader = MyLoader(featurizer, splitter, transformers, TASKS,\n",
    "                          data_dir, save_dir, **kwargs)\n",
    "    return loader.load_dataset(task, reload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ce014-3e8e-4ef9-9105-377bf046aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = load_tox21()\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33833192-8653-45ba-ace2-14f804ee45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = train_dataset.to_dataframe()\n",
    "df_t = test_dataset.to_dataframe()\n",
    "df_v = valid_dataset.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4d327b-cb46-4d8c-be4d-3474c731c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_tr.drop(['y','w','ids'],axis=1)\n",
    "y = df_tr['y']\n",
    "xt = df_t.drop(['y','w','ids'],axis=1)\n",
    "x_smiles = df_t['ids'].to_numpy()\n",
    "\n",
    "yt = df_t['y']\n",
    "xv = df_v.drop(['y','w','ids'],axis=1)\n",
    "\n",
    "yv = df_v['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b9a3f1-b1ee-4b79-bc4b-3bda7c8c44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len=len(x.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31267d2-3194-4dce-ace3-91255c80eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(s):\n",
    "    K.clear_session()\n",
    "    seed_value= s\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    import random\n",
    "    random.seed(seed_value)\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(seed_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f237cbf6-a455-4066-81fe-63f3922bad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82938259-c61a-4ac6-8c9d-53188c284c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_len, len1, len2, len3, regular, activ_f,momentum_batch_norm):\n",
    "\n",
    "    #dropout\n",
    "    prob_h1 = 0.25\n",
    "    prob_h2 = 0.15\n",
    "    prob_h3 = 0.1\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(input_len), dtype='float32'))\n",
    "    model.add(keras.layers.Dense(len1, input_dim=input_len, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h1))\n",
    "\n",
    "    model.add(keras.layers.Dense(len2, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h2))\n",
    "    \n",
    "    model.add(keras.layers.Dense(len2, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h2))\n",
    "\n",
    "    model.add(keras.layers.Dense(len3, kernel_regularizer = regular, activation=activ_f))\n",
    "    model.add(keras.layers.BatchNormalization(momentum=momentum_batch_norm))\n",
    "    model.add(keras.layers.Dropout(prob_h2))\n",
    "\n",
    "    model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd64e6e-dbd1-4714-930d-343dfc3e201a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 219,361\n",
      "Trainable params: 218,741\n",
      "Non-trainable params: 620\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reg = tf.keras.regularizers.l1_l2(0.0008,0.0008)\n",
    "model = build_model(input_len,200,50,10,reg,'relu',0.9)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a5978f-a399-400c-8e83-ff066bc5fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(0.0001)\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['AUC'])\n",
    "# # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef972fdc-0557-4fc4-986a-471eaf773c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 219,361\n",
      "Trainable params: 218,741\n",
      "Non-trainable params: 620\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9bb1ad9-f87e-43e5-a815-06f94091c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_history(hist):\n",
    "    acc = hist.history['AUC']\n",
    "    val_acc = hist.history['val_AUC']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, '-', label='AUC')\n",
    "    plt.plot(epochs, val_acc, ':', label='Validation AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c00f92-dc05-4254-81df-69d15bc845b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_delta_val = 0.0005\n",
    "patience_val = 1000\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=min_delta_val, \n",
    "                              patience=patience_val, \n",
    "                              verbose=0, \n",
    "                              mode='min',\n",
    "                              restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fbcc1b9-28e5-4d8c-adc5-16eb09871c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2277 samples, validate on 285 samples\n",
      "Epoch 1/500\n",
      "2080/2277 [==========================>...] - ETA: 0s - loss: 8.0164 - AUC: 0.5024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2277/2277 [==============================] - 2s 850us/sample - loss: 8.0042 - AUC: 0.5090 - val_loss: 7.8232 - val_AUC: 0.4329\n",
      "Epoch 2/500\n",
      "2277/2277 [==============================] - 0s 116us/sample - loss: 7.9914 - AUC: 0.5001 - val_loss: 7.9507 - val_AUC: 0.4221\n",
      "Epoch 3/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 7.9857 - AUC: 0.5100 - val_loss: 7.9643 - val_AUC: 0.4300\n",
      "Epoch 4/500\n",
      "2277/2277 [==============================] - 0s 113us/sample - loss: 7.9642 - AUC: 0.5139 - val_loss: 7.9487 - val_AUC: 0.4320\n",
      "Epoch 5/500\n",
      "2277/2277 [==============================] - 0s 129us/sample - loss: 7.9261 - AUC: 0.5345 - val_loss: 7.9475 - val_AUC: 0.4337\n",
      "Epoch 6/500\n",
      "2277/2277 [==============================] - 0s 123us/sample - loss: 7.9381 - AUC: 0.5214 - val_loss: 7.9485 - val_AUC: 0.4393\n",
      "Epoch 7/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 7.9414 - AUC: 0.5291 - val_loss: 7.9255 - val_AUC: 0.4420\n",
      "Epoch 8/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 7.9417 - AUC: 0.5213 - val_loss: 7.9130 - val_AUC: 0.4397\n",
      "Epoch 9/500\n",
      "2277/2277 [==============================] - 0s 120us/sample - loss: 7.9196 - AUC: 0.5231 - val_loss: 7.9104 - val_AUC: 0.4396\n",
      "Epoch 10/500\n",
      "2277/2277 [==============================] - 0s 131us/sample - loss: 7.8938 - AUC: 0.5377 - val_loss: 7.9028 - val_AUC: 0.4437\n",
      "Epoch 11/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 7.8543 - AUC: 0.5650 - val_loss: 7.8883 - val_AUC: 0.4508\n",
      "Epoch 12/500\n",
      "2277/2277 [==============================] - 0s 125us/sample - loss: 7.8383 - AUC: 0.5607 - val_loss: 7.8699 - val_AUC: 0.4506\n",
      "Epoch 13/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 7.8538 - AUC: 0.5595 - val_loss: 7.8792 - val_AUC: 0.4534\n",
      "Epoch 14/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 7.8393 - AUC: 0.5643 - val_loss: 7.8632 - val_AUC: 0.4530\n",
      "Epoch 15/500\n",
      "2277/2277 [==============================] - 0s 125us/sample - loss: 7.8069 - AUC: 0.5752 - val_loss: 7.8586 - val_AUC: 0.4540\n",
      "Epoch 16/500\n",
      "2277/2277 [==============================] - 0s 127us/sample - loss: 7.8477 - AUC: 0.5449 - val_loss: 7.8452 - val_AUC: 0.4608\n",
      "Epoch 17/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 7.7996 - AUC: 0.5778 - val_loss: 7.8449 - val_AUC: 0.4604\n",
      "Epoch 18/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 7.8055 - AUC: 0.5652 - val_loss: 7.8398 - val_AUC: 0.4629\n",
      "Epoch 19/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 7.7801 - AUC: 0.5834 - val_loss: 7.8309 - val_AUC: 0.4656\n",
      "Epoch 20/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 7.7729 - AUC: 0.5809 - val_loss: 7.8067 - val_AUC: 0.4627\n",
      "Epoch 21/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 7.7621 - AUC: 0.5802 - val_loss: 7.8169 - val_AUC: 0.4661\n",
      "Epoch 22/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 7.7374 - AUC: 0.5962 - val_loss: 7.7951 - val_AUC: 0.4683\n",
      "Epoch 23/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 7.7213 - AUC: 0.6035 - val_loss: 7.7937 - val_AUC: 0.4666\n",
      "Epoch 24/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 7.7160 - AUC: 0.5977 - val_loss: 7.7857 - val_AUC: 0.4668\n",
      "Epoch 25/500\n",
      "2277/2277 [==============================] - 0s 115us/sample - loss: 7.7185 - AUC: 0.5960 - val_loss: 7.7685 - val_AUC: 0.4731\n",
      "Epoch 26/500\n",
      "2277/2277 [==============================] - 0s 123us/sample - loss: 7.6896 - AUC: 0.6123 - val_loss: 7.7628 - val_AUC: 0.4720\n",
      "Epoch 27/500\n",
      "2277/2277 [==============================] - 0s 130us/sample - loss: 7.7022 - AUC: 0.6034 - val_loss: 7.7475 - val_AUC: 0.4746\n",
      "Epoch 28/500\n",
      "2277/2277 [==============================] - 0s 130us/sample - loss: 7.6811 - AUC: 0.6200 - val_loss: 7.7471 - val_AUC: 0.4719\n",
      "Epoch 29/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 7.6902 - AUC: 0.6047 - val_loss: 7.7389 - val_AUC: 0.4708\n",
      "Epoch 30/500\n",
      "2277/2277 [==============================] - 0s 116us/sample - loss: 7.6446 - AUC: 0.6351 - val_loss: 7.7284 - val_AUC: 0.4784\n",
      "Epoch 31/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 7.6416 - AUC: 0.6279 - val_loss: 7.7309 - val_AUC: 0.4810\n",
      "Epoch 32/500\n",
      "2277/2277 [==============================] - 0s 123us/sample - loss: 7.6440 - AUC: 0.6209 - val_loss: 7.7134 - val_AUC: 0.4834\n",
      "Epoch 33/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 7.6253 - AUC: 0.6333 - val_loss: 7.7121 - val_AUC: 0.4856\n",
      "Epoch 34/500\n",
      "2277/2277 [==============================] - 0s 116us/sample - loss: 7.6240 - AUC: 0.6309 - val_loss: 7.7061 - val_AUC: 0.4839\n",
      "Epoch 35/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 7.6307 - AUC: 0.6176 - val_loss: 7.6956 - val_AUC: 0.4863\n",
      "Epoch 36/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 7.6084 - AUC: 0.6444 - val_loss: 7.6934 - val_AUC: 0.4852\n",
      "Epoch 37/500\n",
      "2277/2277 [==============================] - 0s 123us/sample - loss: 7.6170 - AUC: 0.6309 - val_loss: 7.6811 - val_AUC: 0.4866\n",
      "Epoch 38/500\n",
      "2277/2277 [==============================] - 0s 123us/sample - loss: 7.6028 - AUC: 0.6300 - val_loss: 7.6649 - val_AUC: 0.4945\n",
      "Epoch 39/500\n",
      "2277/2277 [==============================] - 0s 123us/sample - loss: 7.5853 - AUC: 0.6336 - val_loss: 7.6563 - val_AUC: 0.4906\n",
      "Epoch 40/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 7.5650 - AUC: 0.6499 - val_loss: 7.6585 - val_AUC: 0.4913\n",
      "Epoch 41/500\n",
      "2277/2277 [==============================] - 0s 129us/sample - loss: 7.5963 - AUC: 0.6279 - val_loss: 7.6478 - val_AUC: 0.4915\n",
      "Epoch 42/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 7.5601 - AUC: 0.6497 - val_loss: 7.6429 - val_AUC: 0.4958\n",
      "Epoch 43/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 7.5425 - AUC: 0.6562 - val_loss: 7.6419 - val_AUC: 0.4928\n",
      "Epoch 44/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 7.5487 - AUC: 0.6485 - val_loss: 7.6251 - val_AUC: 0.4902\n",
      "Epoch 45/500\n",
      "2277/2277 [==============================] - 0s 115us/sample - loss: 7.5422 - AUC: 0.6448 - val_loss: 7.6173 - val_AUC: 0.4931\n",
      "Epoch 46/500\n",
      "2277/2277 [==============================] - 0s 128us/sample - loss: 7.5466 - AUC: 0.6480 - val_loss: 7.6155 - val_AUC: 0.4925\n",
      "Epoch 47/500\n",
      "2277/2277 [==============================] - 0s 133us/sample - loss: 7.5164 - AUC: 0.6565 - val_loss: 7.6027 - val_AUC: 0.5015\n",
      "Epoch 48/500\n",
      "2277/2277 [==============================] - 0s 127us/sample - loss: 7.5189 - AUC: 0.6584 - val_loss: 7.6000 - val_AUC: 0.5014\n",
      "Epoch 49/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 7.4693 - AUC: 0.6899 - val_loss: 7.5943 - val_AUC: 0.5041\n",
      "Epoch 50/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 7.5032 - AUC: 0.6613 - val_loss: 7.5889 - val_AUC: 0.5029\n",
      "Epoch 51/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 7.4598 - AUC: 0.6858 - val_loss: 7.5788 - val_AUC: 0.5021\n",
      "Epoch 52/500\n",
      "2277/2277 [==============================] - 0s 136us/sample - loss: 7.4756 - AUC: 0.6651 - val_loss: 7.5674 - val_AUC: 0.5020\n",
      "Epoch 53/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 7.4662 - AUC: 0.6719 - val_loss: 7.5618 - val_AUC: 0.5099\n",
      "Epoch 54/500\n",
      "2277/2277 [==============================] - 0s 125us/sample - loss: 7.4694 - AUC: 0.6733 - val_loss: 7.5528 - val_AUC: 0.5055\n",
      "Epoch 55/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 7.4511 - AUC: 0.6740 - val_loss: 7.5534 - val_AUC: 0.5118\n",
      "Epoch 56/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 7.4366 - AUC: 0.6841 - val_loss: 7.5443 - val_AUC: 0.5070\n",
      "Epoch 57/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 7.4361 - AUC: 0.6787 - val_loss: 7.5370 - val_AUC: 0.5165\n",
      "Epoch 58/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 7.4275 - AUC: 0.6801 - val_loss: 7.5274 - val_AUC: 0.5072\n",
      "Epoch 59/500\n",
      "2277/2277 [==============================] - 0s 131us/sample - loss: 7.4318 - AUC: 0.6744 - val_loss: 7.5300 - val_AUC: 0.5131\n",
      "Epoch 60/500\n",
      "2277/2277 [==============================] - 0s 133us/sample - loss: 7.4234 - AUC: 0.6773 - val_loss: 7.5215 - val_AUC: 0.5087\n",
      "Epoch 61/500\n",
      "2277/2277 [==============================] - 0s 115us/sample - loss: 7.3849 - AUC: 0.7028 - val_loss: 7.5170 - val_AUC: 0.5059\n",
      "Epoch 62/500\n",
      "2277/2277 [==============================] - 0s 125us/sample - loss: 7.4001 - AUC: 0.6929 - val_loss: 7.5053 - val_AUC: 0.5187\n",
      "Epoch 63/500\n",
      "2277/2277 [==============================] - 0s 137us/sample - loss: 7.3754 - AUC: 0.6967 - val_loss: 7.4864 - val_AUC: 0.5234\n",
      "Epoch 64/500\n",
      "2277/2277 [==============================] - 0s 128us/sample - loss: 7.3815 - AUC: 0.6944 - val_loss: 7.4884 - val_AUC: 0.5121\n",
      "Epoch 65/500\n",
      "2277/2277 [==============================] - 0s 131us/sample - loss: 7.3736 - AUC: 0.6943 - val_loss: 7.4760 - val_AUC: 0.5218\n",
      "Epoch 66/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 7.3637 - AUC: 0.6928 - val_loss: 7.4709 - val_AUC: 0.5244\n",
      "Epoch 67/500\n",
      "2277/2277 [==============================] - 0s 120us/sample - loss: 7.3559 - AUC: 0.6970 - val_loss: 7.4669 - val_AUC: 0.5219\n",
      "Epoch 68/500\n",
      "2277/2277 [==============================] - 0s 133us/sample - loss: 7.3428 - AUC: 0.7018 - val_loss: 7.4596 - val_AUC: 0.5203\n",
      "Epoch 69/500\n",
      "2277/2277 [==============================] - 0s 136us/sample - loss: 7.3369 - AUC: 0.6999 - val_loss: 7.4575 - val_AUC: 0.5239\n",
      "Epoch 70/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 7.3208 - AUC: 0.7094 - val_loss: 7.4482 - val_AUC: 0.5199\n",
      "Epoch 71/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 7.3136 - AUC: 0.7081 - val_loss: 7.4424 - val_AUC: 0.5129\n",
      "Epoch 72/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 7.3144 - AUC: 0.7035 - val_loss: 7.4311 - val_AUC: 0.5253\n",
      "Epoch 73/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 7.3229 - AUC: 0.6963 - val_loss: 7.4302 - val_AUC: 0.5205\n",
      "Epoch 74/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 7.2826 - AUC: 0.7229 - val_loss: 7.4216 - val_AUC: 0.5263\n",
      "Epoch 75/500\n",
      "2277/2277 [==============================] - 0s 120us/sample - loss: 7.2994 - AUC: 0.7044 - val_loss: 7.4118 - val_AUC: 0.5285\n",
      "Epoch 76/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 7.2717 - AUC: 0.7239 - val_loss: 7.4097 - val_AUC: 0.5251\n",
      "Epoch 77/500\n",
      "2277/2277 [==============================] - 0s 113us/sample - loss: 7.2799 - AUC: 0.7101 - val_loss: 7.4021 - val_AUC: 0.5286\n",
      "Epoch 78/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 7.2628 - AUC: 0.7208 - val_loss: 7.3944 - val_AUC: 0.5326\n",
      "Epoch 79/500\n",
      "2277/2277 [==============================] - 0s 131us/sample - loss: 7.2460 - AUC: 0.7259 - val_loss: 7.3792 - val_AUC: 0.5322\n",
      "Epoch 80/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 7.2511 - AUC: 0.7219 - val_loss: 7.3796 - val_AUC: 0.5313\n",
      "Epoch 81/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 7.2462 - AUC: 0.7286 - val_loss: 7.3776 - val_AUC: 0.5323\n",
      "Epoch 82/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 7.2431 - AUC: 0.7235 - val_loss: 7.3756 - val_AUC: 0.5290\n",
      "Epoch 83/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 7.2308 - AUC: 0.7239 - val_loss: 7.3578 - val_AUC: 0.5354\n",
      "Epoch 84/500\n",
      "2277/2277 [==============================] - 0s 136us/sample - loss: 7.2280 - AUC: 0.7266 - val_loss: 7.3521 - val_AUC: 0.5373\n",
      "Epoch 85/500\n",
      "2277/2277 [==============================] - 0s 127us/sample - loss: 7.2096 - AUC: 0.7267 - val_loss: 7.3397 - val_AUC: 0.5368\n",
      "Epoch 86/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 7.1945 - AUC: 0.7373 - val_loss: 7.3346 - val_AUC: 0.5356\n",
      "Epoch 87/500\n",
      "2277/2277 [==============================] - 0s 120us/sample - loss: 7.1894 - AUC: 0.7387 - val_loss: 7.3347 - val_AUC: 0.5329\n",
      "Epoch 88/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 7.1829 - AUC: 0.7374 - val_loss: 7.3313 - val_AUC: 0.5398\n",
      "Epoch 89/500\n",
      "2277/2277 [==============================] - 0s 123us/sample - loss: 7.1854 - AUC: 0.7327 - val_loss: 7.3147 - val_AUC: 0.5425\n",
      "Epoch 90/500\n",
      "2277/2277 [==============================] - 0s 120us/sample - loss: 7.1795 - AUC: 0.7351 - val_loss: 7.3093 - val_AUC: 0.5408\n",
      "Epoch 91/500\n",
      "2277/2277 [==============================] - 0s 132us/sample - loss: 7.1472 - AUC: 0.7547 - val_loss: 7.3107 - val_AUC: 0.5321\n",
      "Epoch 92/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 7.1678 - AUC: 0.7260 - val_loss: 7.2985 - val_AUC: 0.5423\n",
      "Epoch 93/500\n",
      "2277/2277 [==============================] - 0s 131us/sample - loss: 7.1434 - AUC: 0.7433 - val_loss: 7.2916 - val_AUC: 0.5451\n",
      "Epoch 94/500\n",
      "2277/2277 [==============================] - 0s 141us/sample - loss: 7.1329 - AUC: 0.7467 - val_loss: 7.2779 - val_AUC: 0.5422\n",
      "Epoch 95/500\n",
      "2277/2277 [==============================] - 0s 133us/sample - loss: 7.1483 - AUC: 0.7310 - val_loss: 7.2739 - val_AUC: 0.5482\n",
      "Epoch 96/500\n",
      "2277/2277 [==============================] - 0s 116us/sample - loss: 7.1103 - AUC: 0.7555 - val_loss: 7.2746 - val_AUC: 0.5504\n",
      "Epoch 97/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 7.1116 - AUC: 0.7545 - val_loss: 7.2628 - val_AUC: 0.5490\n",
      "Epoch 98/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 7.1134 - AUC: 0.7454 - val_loss: 7.2567 - val_AUC: 0.5422\n",
      "Epoch 99/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 7.1075 - AUC: 0.7455 - val_loss: 7.2498 - val_AUC: 0.5486\n",
      "Epoch 100/500\n",
      "2277/2277 [==============================] - 0s 123us/sample - loss: 7.0818 - AUC: 0.7590 - val_loss: 7.2417 - val_AUC: 0.5487\n",
      "Epoch 101/500\n",
      "2277/2277 [==============================] - 0s 131us/sample - loss: 7.1032 - AUC: 0.7391 - val_loss: 7.2342 - val_AUC: 0.5503\n",
      "Epoch 102/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 7.0780 - AUC: 0.7510 - val_loss: 7.2281 - val_AUC: 0.5503\n",
      "Epoch 103/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 7.0638 - AUC: 0.7633 - val_loss: 7.2239 - val_AUC: 0.5506\n",
      "Epoch 104/500\n",
      "2277/2277 [==============================] - 0s 131us/sample - loss: 7.0551 - AUC: 0.7639 - val_loss: 7.2181 - val_AUC: 0.5473\n",
      "Epoch 105/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 7.0515 - AUC: 0.7641 - val_loss: 7.2086 - val_AUC: 0.5515\n",
      "Epoch 106/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 7.0498 - AUC: 0.7534 - val_loss: 7.2016 - val_AUC: 0.5541\n",
      "Epoch 107/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 7.0418 - AUC: 0.7590 - val_loss: 7.1921 - val_AUC: 0.5556\n",
      "Epoch 108/500\n",
      "2277/2277 [==============================] - 0s 113us/sample - loss: 7.0298 - AUC: 0.7593 - val_loss: 7.1860 - val_AUC: 0.5540\n",
      "Epoch 109/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 7.0527 - AUC: 0.7363 - val_loss: 7.1779 - val_AUC: 0.5559\n",
      "Epoch 110/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 7.0142 - AUC: 0.7666 - val_loss: 7.1751 - val_AUC: 0.5534\n",
      "Epoch 111/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 7.0100 - AUC: 0.7677 - val_loss: 7.1683 - val_AUC: 0.5590\n",
      "Epoch 112/500\n",
      "2277/2277 [==============================] - 0s 125us/sample - loss: 6.9868 - AUC: 0.7767 - val_loss: 7.1628 - val_AUC: 0.5551\n",
      "Epoch 113/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 7.0073 - AUC: 0.7552 - val_loss: 7.1569 - val_AUC: 0.5599\n",
      "Epoch 114/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 6.9944 - AUC: 0.7620 - val_loss: 7.1491 - val_AUC: 0.5602\n",
      "Epoch 115/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 6.9824 - AUC: 0.7663 - val_loss: 7.1392 - val_AUC: 0.5610\n",
      "Epoch 116/500\n",
      "2277/2277 [==============================] - 0s 133us/sample - loss: 6.9757 - AUC: 0.7647 - val_loss: 7.1311 - val_AUC: 0.5629\n",
      "Epoch 117/500\n",
      "2277/2277 [==============================] - 0s 123us/sample - loss: 6.9605 - AUC: 0.7728 - val_loss: 7.1277 - val_AUC: 0.5603\n",
      "Epoch 118/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 6.9571 - AUC: 0.7723 - val_loss: 7.1193 - val_AUC: 0.5610\n",
      "Epoch 119/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 6.9690 - AUC: 0.7548 - val_loss: 7.1095 - val_AUC: 0.5675\n",
      "Epoch 120/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 6.9150 - AUC: 0.7952 - val_loss: 7.1078 - val_AUC: 0.5669\n",
      "Epoch 121/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 6.9482 - AUC: 0.7618 - val_loss: 7.0960 - val_AUC: 0.5674\n",
      "Epoch 122/500\n",
      "2277/2277 [==============================] - 0s 127us/sample - loss: 6.9180 - AUC: 0.7814 - val_loss: 7.0937 - val_AUC: 0.5729\n",
      "Epoch 123/500\n",
      "2277/2277 [==============================] - 0s 127us/sample - loss: 6.9213 - AUC: 0.7735 - val_loss: 7.0823 - val_AUC: 0.5681\n",
      "Epoch 124/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 6.9082 - AUC: 0.7806 - val_loss: 7.0695 - val_AUC: 0.5668\n",
      "Epoch 125/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 6.8958 - AUC: 0.7851 - val_loss: 7.0700 - val_AUC: 0.5726\n",
      "Epoch 126/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 6.8969 - AUC: 0.7769 - val_loss: 7.0615 - val_AUC: 0.5729\n",
      "Epoch 127/500\n",
      "2277/2277 [==============================] - 0s 136us/sample - loss: 6.8731 - AUC: 0.7911 - val_loss: 7.0538 - val_AUC: 0.5651\n",
      "Epoch 128/500\n",
      "2277/2277 [==============================] - 0s 125us/sample - loss: 6.8655 - AUC: 0.7904 - val_loss: 7.0515 - val_AUC: 0.5680\n",
      "Epoch 129/500\n",
      "2277/2277 [==============================] - 0s 128us/sample - loss: 6.8595 - AUC: 0.7909 - val_loss: 7.0445 - val_AUC: 0.5638\n",
      "Epoch 130/500\n",
      "2277/2277 [==============================] - 0s 128us/sample - loss: 6.8545 - AUC: 0.7893 - val_loss: 7.0312 - val_AUC: 0.5719\n",
      "Epoch 131/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 6.8471 - AUC: 0.7914 - val_loss: 7.0266 - val_AUC: 0.5746\n",
      "Epoch 132/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 6.8411 - AUC: 0.7892 - val_loss: 7.0178 - val_AUC: 0.5743\n",
      "Epoch 133/500\n",
      "2277/2277 [==============================] - 0s 128us/sample - loss: 6.8466 - AUC: 0.7830 - val_loss: 7.0116 - val_AUC: 0.5725\n",
      "Epoch 134/500\n",
      "2277/2277 [==============================] - 0s 140us/sample - loss: 6.8312 - AUC: 0.7878 - val_loss: 7.0091 - val_AUC: 0.5685\n",
      "Epoch 135/500\n",
      "2277/2277 [==============================] - 0s 133us/sample - loss: 6.8166 - AUC: 0.7955 - val_loss: 6.9928 - val_AUC: 0.5740\n",
      "Epoch 136/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 6.8176 - AUC: 0.7892 - val_loss: 6.9960 - val_AUC: 0.5721\n",
      "Epoch 137/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 6.8075 - AUC: 0.7865 - val_loss: 6.9853 - val_AUC: 0.5778\n",
      "Epoch 138/500\n",
      "2277/2277 [==============================] - 0s 120us/sample - loss: 6.7854 - AUC: 0.8059 - val_loss: 6.9799 - val_AUC: 0.5732\n",
      "Epoch 139/500\n",
      "2277/2277 [==============================] - 0s 137us/sample - loss: 6.7889 - AUC: 0.7979 - val_loss: 6.9695 - val_AUC: 0.5754\n",
      "Epoch 140/500\n",
      "2277/2277 [==============================] - 0s 128us/sample - loss: 6.7745 - AUC: 0.8046 - val_loss: 6.9632 - val_AUC: 0.5808\n",
      "Epoch 141/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 6.7617 - AUC: 0.8048 - val_loss: 6.9608 - val_AUC: 0.5748\n",
      "Epoch 142/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 6.7630 - AUC: 0.7987 - val_loss: 6.9498 - val_AUC: 0.5785\n",
      "Epoch 143/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 6.7510 - AUC: 0.8068 - val_loss: 6.9396 - val_AUC: 0.5791\n",
      "Epoch 144/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 6.7334 - AUC: 0.8172 - val_loss: 6.9327 - val_AUC: 0.5841\n",
      "Epoch 145/500\n",
      "2277/2277 [==============================] - 0s 137us/sample - loss: 6.7190 - AUC: 0.8183 - val_loss: 6.9285 - val_AUC: 0.5788\n",
      "Epoch 146/500\n",
      "2277/2277 [==============================] - 0s 128us/sample - loss: 6.7287 - AUC: 0.8046 - val_loss: 6.9218 - val_AUC: 0.5829\n",
      "Epoch 147/500\n",
      "2277/2277 [==============================] - 0s 128us/sample - loss: 6.7263 - AUC: 0.8035 - val_loss: 6.9127 - val_AUC: 0.5882\n",
      "Epoch 148/500\n",
      "2277/2277 [==============================] - 0s 113us/sample - loss: 6.7166 - AUC: 0.8061 - val_loss: 6.9053 - val_AUC: 0.5812\n",
      "Epoch 149/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 6.6857 - AUC: 0.8267 - val_loss: 6.8973 - val_AUC: 0.5933\n",
      "Epoch 150/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 6.6814 - AUC: 0.8218 - val_loss: 6.8909 - val_AUC: 0.5850\n",
      "Epoch 151/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 6.6878 - AUC: 0.8119 - val_loss: 6.8859 - val_AUC: 0.5835\n",
      "Epoch 152/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 6.6683 - AUC: 0.8225 - val_loss: 6.8828 - val_AUC: 0.5818\n",
      "Epoch 153/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 6.6644 - AUC: 0.8214 - val_loss: 6.8714 - val_AUC: 0.5902\n",
      "Epoch 154/500\n",
      "2277/2277 [==============================] - 0s 116us/sample - loss: 6.6590 - AUC: 0.8153 - val_loss: 6.8700 - val_AUC: 0.5830\n",
      "Epoch 155/500\n",
      "2277/2277 [==============================] - 0s 116us/sample - loss: 6.6566 - AUC: 0.8147 - val_loss: 6.8578 - val_AUC: 0.5878\n",
      "Epoch 156/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 6.6452 - AUC: 0.8200 - val_loss: 6.8467 - val_AUC: 0.5914\n",
      "Epoch 157/500\n",
      "2277/2277 [==============================] - 0s 129us/sample - loss: 6.6257 - AUC: 0.8291 - val_loss: 6.8379 - val_AUC: 0.5913\n",
      "Epoch 158/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 6.6174 - AUC: 0.8320 - val_loss: 6.8318 - val_AUC: 0.5852\n",
      "Epoch 159/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 6.6267 - AUC: 0.8187 - val_loss: 6.8307 - val_AUC: 0.5855\n",
      "Epoch 160/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 6.6148 - AUC: 0.8222 - val_loss: 6.8197 - val_AUC: 0.5864\n",
      "Epoch 161/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 6.5973 - AUC: 0.8267 - val_loss: 6.8099 - val_AUC: 0.5910\n",
      "Epoch 162/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 6.6018 - AUC: 0.8241 - val_loss: 6.8114 - val_AUC: 0.5949\n",
      "Epoch 163/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 6.5862 - AUC: 0.8253 - val_loss: 6.7996 - val_AUC: 0.5920\n",
      "Epoch 164/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 6.5642 - AUC: 0.8419 - val_loss: 6.7877 - val_AUC: 0.5923\n",
      "Epoch 165/500\n",
      "2277/2277 [==============================] - 0s 130us/sample - loss: 6.5761 - AUC: 0.8213 - val_loss: 6.7809 - val_AUC: 0.5962\n",
      "Epoch 166/500\n",
      "2277/2277 [==============================] - 0s 128us/sample - loss: 6.5620 - AUC: 0.8310 - val_loss: 6.7809 - val_AUC: 0.5903\n",
      "Epoch 167/500\n",
      "2277/2277 [==============================] - 0s 115us/sample - loss: 6.5603 - AUC: 0.8264 - val_loss: 6.7701 - val_AUC: 0.5908\n",
      "Epoch 168/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 6.5576 - AUC: 0.8240 - val_loss: 6.7649 - val_AUC: 0.5905\n",
      "Epoch 169/500\n",
      "2277/2277 [==============================] - 0s 116us/sample - loss: 6.5369 - AUC: 0.8312 - val_loss: 6.7517 - val_AUC: 0.5931\n",
      "Epoch 170/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 6.5336 - AUC: 0.8303 - val_loss: 6.7499 - val_AUC: 0.5933\n",
      "Epoch 171/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 6.5280 - AUC: 0.8304 - val_loss: 6.7393 - val_AUC: 0.5970\n",
      "Epoch 172/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 6.5215 - AUC: 0.8292 - val_loss: 6.7284 - val_AUC: 0.5969\n",
      "Epoch 173/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 6.4998 - AUC: 0.8395 - val_loss: 6.7303 - val_AUC: 0.5945\n",
      "Epoch 174/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 6.4881 - AUC: 0.8440 - val_loss: 6.7257 - val_AUC: 0.5982\n",
      "Epoch 175/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 6.5013 - AUC: 0.8276 - val_loss: 6.7081 - val_AUC: 0.5933\n",
      "Epoch 176/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 6.4984 - AUC: 0.8248 - val_loss: 6.7095 - val_AUC: 0.5904\n",
      "Epoch 177/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 6.4721 - AUC: 0.8398 - val_loss: 6.7021 - val_AUC: 0.5988\n",
      "Epoch 178/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 6.4734 - AUC: 0.8322 - val_loss: 6.6936 - val_AUC: 0.5965\n",
      "Epoch 179/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 6.4563 - AUC: 0.8390 - val_loss: 6.6834 - val_AUC: 0.5962\n",
      "Epoch 180/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 6.4535 - AUC: 0.8386 - val_loss: 6.6800 - val_AUC: 0.5970\n",
      "Epoch 181/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 6.4401 - AUC: 0.8433 - val_loss: 6.6681 - val_AUC: 0.5977\n",
      "Epoch 182/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 6.4350 - AUC: 0.8412 - val_loss: 6.6616 - val_AUC: 0.6014\n",
      "Epoch 183/500\n",
      "2277/2277 [==============================] - 0s 133us/sample - loss: 6.4165 - AUC: 0.8506 - val_loss: 6.6563 - val_AUC: 0.5976\n",
      "Epoch 184/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 6.4204 - AUC: 0.8402 - val_loss: 6.6478 - val_AUC: 0.6010\n",
      "Epoch 185/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 6.4126 - AUC: 0.8429 - val_loss: 6.6415 - val_AUC: 0.6017\n",
      "Epoch 186/500\n",
      "2277/2277 [==============================] - 0s 116us/sample - loss: 6.4055 - AUC: 0.8417 - val_loss: 6.6316 - val_AUC: 0.6023\n",
      "Epoch 187/500\n",
      "2277/2277 [==============================] - 0s 113us/sample - loss: 6.3822 - AUC: 0.8552 - val_loss: 6.6220 - val_AUC: 0.6059\n",
      "Epoch 188/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 6.3829 - AUC: 0.8466 - val_loss: 6.6239 - val_AUC: 0.5994\n",
      "Epoch 189/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 6.3810 - AUC: 0.8440 - val_loss: 6.6131 - val_AUC: 0.6036\n",
      "Epoch 190/500\n",
      "2277/2277 [==============================] - 0s 132us/sample - loss: 6.3612 - AUC: 0.8541 - val_loss: 6.6069 - val_AUC: 0.6038\n",
      "Epoch 191/500\n",
      "2277/2277 [==============================] - 0s 130us/sample - loss: 6.3601 - AUC: 0.8474 - val_loss: 6.5987 - val_AUC: 0.6037\n",
      "Epoch 192/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 6.3496 - AUC: 0.8524 - val_loss: 6.5851 - val_AUC: 0.6082\n",
      "Epoch 193/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 6.3535 - AUC: 0.8432 - val_loss: 6.5793 - val_AUC: 0.6077\n",
      "Epoch 194/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 6.3305 - AUC: 0.8584 - val_loss: 6.5765 - val_AUC: 0.6040\n",
      "Epoch 195/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 6.3181 - AUC: 0.8592 - val_loss: 6.5644 - val_AUC: 0.6064\n",
      "Epoch 196/500\n",
      "2277/2277 [==============================] - 0s 133us/sample - loss: 6.3237 - AUC: 0.8516 - val_loss: 6.5602 - val_AUC: 0.6057\n",
      "Epoch 197/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 6.3054 - AUC: 0.8578 - val_loss: 6.5524 - val_AUC: 0.6059\n",
      "Epoch 198/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 6.3012 - AUC: 0.8561 - val_loss: 6.5532 - val_AUC: 0.6018\n",
      "Epoch 199/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 6.2969 - AUC: 0.8531 - val_loss: 6.5426 - val_AUC: 0.6061\n",
      "Epoch 200/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 6.2845 - AUC: 0.8590 - val_loss: 6.5353 - val_AUC: 0.6055\n",
      "Epoch 201/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 6.2757 - AUC: 0.8606 - val_loss: 6.5172 - val_AUC: 0.6078\n",
      "Epoch 202/500\n",
      "2277/2277 [==============================] - 0s 144us/sample - loss: 6.2696 - AUC: 0.8592 - val_loss: 6.5124 - val_AUC: 0.6098\n",
      "Epoch 203/500\n",
      "2277/2277 [==============================] - 0s 142us/sample - loss: 6.2651 - AUC: 0.8569 - val_loss: 6.5059 - val_AUC: 0.6129\n",
      "Epoch 204/500\n",
      "2277/2277 [==============================] - 0s 141us/sample - loss: 6.2492 - AUC: 0.8635 - val_loss: 6.5010 - val_AUC: 0.6066\n",
      "Epoch 205/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 6.2390 - AUC: 0.8655 - val_loss: 6.4957 - val_AUC: 0.6087\n",
      "Epoch 206/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 6.2410 - AUC: 0.8594 - val_loss: 6.4911 - val_AUC: 0.6045\n",
      "Epoch 207/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 6.2210 - AUC: 0.8692 - val_loss: 6.4708 - val_AUC: 0.6090\n",
      "Epoch 208/500\n",
      "2277/2277 [==============================] - 0s 139us/sample - loss: 6.2125 - AUC: 0.8661 - val_loss: 6.4664 - val_AUC: 0.6126\n",
      "Epoch 209/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 6.2081 - AUC: 0.8652 - val_loss: 6.4695 - val_AUC: 0.6069\n",
      "Epoch 210/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 6.2118 - AUC: 0.8595 - val_loss: 6.4595 - val_AUC: 0.6087\n",
      "Epoch 211/500\n",
      "2277/2277 [==============================] - 0s 125us/sample - loss: 6.1773 - AUC: 0.8786 - val_loss: 6.4463 - val_AUC: 0.6146\n",
      "Epoch 212/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 6.1884 - AUC: 0.8645 - val_loss: 6.4434 - val_AUC: 0.6100\n",
      "Epoch 213/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 6.1690 - AUC: 0.8728 - val_loss: 6.4371 - val_AUC: 0.6108\n",
      "Epoch 214/500\n",
      "2277/2277 [==============================] - 0s 138us/sample - loss: 6.1573 - AUC: 0.8771 - val_loss: 6.4228 - val_AUC: 0.6147\n",
      "Epoch 215/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 6.1584 - AUC: 0.8697 - val_loss: 6.4223 - val_AUC: 0.6114\n",
      "Epoch 216/500\n",
      "2277/2277 [==============================] - 0s 130us/sample - loss: 6.1586 - AUC: 0.8649 - val_loss: 6.4126 - val_AUC: 0.6123\n",
      "Epoch 217/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 6.1320 - AUC: 0.8800 - val_loss: 6.4050 - val_AUC: 0.6111\n",
      "Epoch 218/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 6.1229 - AUC: 0.8805 - val_loss: 6.3945 - val_AUC: 0.6118\n",
      "Epoch 219/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 6.1251 - AUC: 0.8729 - val_loss: 6.3911 - val_AUC: 0.6130\n",
      "Epoch 220/500\n",
      "2277/2277 [==============================] - 0s 137us/sample - loss: 6.1167 - AUC: 0.8737 - val_loss: 6.3845 - val_AUC: 0.6132\n",
      "Epoch 221/500\n",
      "2277/2277 [==============================] - 0s 130us/sample - loss: 6.0912 - AUC: 0.8888 - val_loss: 6.3742 - val_AUC: 0.6193\n",
      "Epoch 222/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 6.0901 - AUC: 0.8832 - val_loss: 6.3693 - val_AUC: 0.6175\n",
      "Epoch 223/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 6.0915 - AUC: 0.8776 - val_loss: 6.3557 - val_AUC: 0.6180\n",
      "Epoch 224/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 6.0792 - AUC: 0.8812 - val_loss: 6.3542 - val_AUC: 0.6155\n",
      "Epoch 225/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 6.0761 - AUC: 0.8773 - val_loss: 6.3448 - val_AUC: 0.6172\n",
      "Epoch 226/500\n",
      "2277/2277 [==============================] - 0s 127us/sample - loss: 6.0689 - AUC: 0.8781 - val_loss: 6.3368 - val_AUC: 0.6151\n",
      "Epoch 227/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 6.0591 - AUC: 0.8765 - val_loss: 6.3331 - val_AUC: 0.6147\n",
      "Epoch 228/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 6.0496 - AUC: 0.8838 - val_loss: 6.3233 - val_AUC: 0.6175\n",
      "Epoch 229/500\n",
      "2277/2277 [==============================] - 0s 124us/sample - loss: 6.0307 - AUC: 0.8871 - val_loss: 6.3107 - val_AUC: 0.6218\n",
      "Epoch 230/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 6.0425 - AUC: 0.8738 - val_loss: 6.3110 - val_AUC: 0.6184\n",
      "Epoch 231/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 6.0239 - AUC: 0.8825 - val_loss: 6.3017 - val_AUC: 0.6212\n",
      "Epoch 232/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 6.0147 - AUC: 0.8825 - val_loss: 6.2926 - val_AUC: 0.6170\n",
      "Epoch 233/500\n",
      "2277/2277 [==============================] - 0s 131us/sample - loss: 6.0159 - AUC: 0.8777 - val_loss: 6.2878 - val_AUC: 0.6232\n",
      "Epoch 234/500\n",
      "2277/2277 [==============================] - 0s 115us/sample - loss: 6.0000 - AUC: 0.8865 - val_loss: 6.2820 - val_AUC: 0.6225\n",
      "Epoch 235/500\n",
      "2277/2277 [==============================] - 0s 120us/sample - loss: 5.9849 - AUC: 0.8893 - val_loss: 6.2780 - val_AUC: 0.6217\n",
      "Epoch 236/500\n",
      "2277/2277 [==============================] - 0s 126us/sample - loss: 5.9688 - AUC: 0.8960 - val_loss: 6.2619 - val_AUC: 0.6221\n",
      "Epoch 237/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 5.9711 - AUC: 0.8905 - val_loss: 6.2612 - val_AUC: 0.6207\n",
      "Epoch 238/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 5.9603 - AUC: 0.8916 - val_loss: 6.2513 - val_AUC: 0.6238\n",
      "Epoch 239/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 5.9552 - AUC: 0.8914 - val_loss: 6.2375 - val_AUC: 0.6257\n",
      "Epoch 240/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 5.9413 - AUC: 0.8944 - val_loss: 6.2371 - val_AUC: 0.6244\n",
      "Epoch 241/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 5.9351 - AUC: 0.8963 - val_loss: 6.2281 - val_AUC: 0.6235\n",
      "Epoch 242/500\n",
      "2277/2277 [==============================] - 0s 129us/sample - loss: 5.9345 - AUC: 0.8888 - val_loss: 6.2259 - val_AUC: 0.6255\n",
      "Epoch 243/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 5.9195 - AUC: 0.8918 - val_loss: 6.2167 - val_AUC: 0.6261\n",
      "Epoch 244/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 5.9108 - AUC: 0.8980 - val_loss: 6.2131 - val_AUC: 0.6178\n",
      "Epoch 245/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 5.9100 - AUC: 0.8915 - val_loss: 6.2017 - val_AUC: 0.6245\n",
      "Epoch 246/500\n",
      "2277/2277 [==============================] - 0s 122us/sample - loss: 5.8995 - AUC: 0.8929 - val_loss: 6.1918 - val_AUC: 0.6302\n",
      "Epoch 247/500\n",
      "2277/2277 [==============================] - 0s 115us/sample - loss: 5.8971 - AUC: 0.8911 - val_loss: 6.1890 - val_AUC: 0.6262\n",
      "Epoch 248/500\n",
      "2277/2277 [==============================] - 0s 121us/sample - loss: 5.8839 - AUC: 0.8927 - val_loss: 6.1859 - val_AUC: 0.6213\n",
      "Epoch 249/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 5.8745 - AUC: 0.8957 - val_loss: 6.1733 - val_AUC: 0.6213\n",
      "Epoch 250/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 5.8613 - AUC: 0.8988 - val_loss: 6.1679 - val_AUC: 0.6193\n",
      "Epoch 251/500\n",
      "2277/2277 [==============================] - 0s 116us/sample - loss: 5.8602 - AUC: 0.8937 - val_loss: 6.1603 - val_AUC: 0.6222\n",
      "Epoch 252/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 5.8383 - AUC: 0.9062 - val_loss: 6.1516 - val_AUC: 0.6199\n",
      "Epoch 253/500\n",
      "2277/2277 [==============================] - 0s 125us/sample - loss: 5.8368 - AUC: 0.8995 - val_loss: 6.1405 - val_AUC: 0.6294\n",
      "Epoch 254/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 5.8281 - AUC: 0.9009 - val_loss: 6.1383 - val_AUC: 0.6256\n",
      "Epoch 255/500\n",
      "2277/2277 [==============================] - 0s 117us/sample - loss: 5.8222 - AUC: 0.9034 - val_loss: 6.1311 - val_AUC: 0.6254\n",
      "Epoch 256/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 5.8088 - AUC: 0.9064 - val_loss: 6.1179 - val_AUC: 0.6282\n",
      "Epoch 257/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 5.8089 - AUC: 0.8998 - val_loss: 6.1188 - val_AUC: 0.6244\n",
      "Epoch 258/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 5.7865 - AUC: 0.9088 - val_loss: 6.1078 - val_AUC: 0.6264\n",
      "Epoch 259/500\n",
      "2277/2277 [==============================] - 0s 132us/sample - loss: 5.7844 - AUC: 0.9059 - val_loss: 6.1004 - val_AUC: 0.6243\n",
      "Epoch 260/500\n",
      "2277/2277 [==============================] - 0s 143us/sample - loss: 5.7759 - AUC: 0.9061 - val_loss: 6.0957 - val_AUC: 0.6230\n",
      "Epoch 261/500\n",
      "2277/2277 [==============================] - 0s 127us/sample - loss: 5.7768 - AUC: 0.8995 - val_loss: 6.0896 - val_AUC: 0.6281\n",
      "Epoch 262/500\n",
      "2277/2277 [==============================] - 0s 129us/sample - loss: 5.7568 - AUC: 0.9090 - val_loss: 6.0792 - val_AUC: 0.6213\n",
      "Epoch 263/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 5.7550 - AUC: 0.9076 - val_loss: 6.0785 - val_AUC: 0.6245\n",
      "Epoch 264/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 5.7475 - AUC: 0.9072 - val_loss: 6.0665 - val_AUC: 0.6245\n",
      "Epoch 265/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 5.7491 - AUC: 0.9014 - val_loss: 6.0573 - val_AUC: 0.6296\n",
      "Epoch 266/500\n",
      "2277/2277 [==============================] - 0s 119us/sample - loss: 5.7290 - AUC: 0.9093 - val_loss: 6.0531 - val_AUC: 0.6231\n",
      "Epoch 267/500\n",
      "2277/2277 [==============================] - 0s 134us/sample - loss: 5.7165 - AUC: 0.9115 - val_loss: 6.0506 - val_AUC: 0.6249\n",
      "Epoch 268/500\n",
      "2277/2277 [==============================] - 0s 136us/sample - loss: 5.7343 - AUC: 0.8972 - val_loss: 6.0372 - val_AUC: 0.6263\n",
      "Epoch 269/500\n",
      "2277/2277 [==============================] - 0s 118us/sample - loss: 5.7119 - AUC: 0.9054 - val_loss: 6.0324 - val_AUC: 0.6248\n",
      "Epoch 270/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 5.7095 - AUC: 0.9022 - val_loss: 6.0255 - val_AUC: 0.6222\n",
      "Epoch 271/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 5.6894 - AUC: 0.9100 - val_loss: 6.0120 - val_AUC: 0.6273\n",
      "Epoch 272/500\n",
      "2277/2277 [==============================] - 0s 100us/sample - loss: 5.6873 - AUC: 0.9067 - val_loss: 6.0085 - val_AUC: 0.6294\n",
      "Epoch 273/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 5.6800 - AUC: 0.9062 - val_loss: 6.0008 - val_AUC: 0.6276\n",
      "Epoch 274/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 5.6672 - AUC: 0.9109 - val_loss: 5.9984 - val_AUC: 0.6315\n",
      "Epoch 275/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 5.6611 - AUC: 0.9074 - val_loss: 5.9871 - val_AUC: 0.6272\n",
      "Epoch 276/500\n",
      "2277/2277 [==============================] - 0s 101us/sample - loss: 5.6547 - AUC: 0.9073 - val_loss: 5.9767 - val_AUC: 0.6296\n",
      "Epoch 277/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.6523 - AUC: 0.9046 - val_loss: 5.9744 - val_AUC: 0.6284\n",
      "Epoch 278/500\n",
      "2277/2277 [==============================] - 0s 102us/sample - loss: 5.6132 - AUC: 0.9246 - val_loss: 5.9655 - val_AUC: 0.6301\n",
      "Epoch 279/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.6335 - AUC: 0.9074 - val_loss: 5.9558 - val_AUC: 0.6297\n",
      "Epoch 280/500\n",
      "2277/2277 [==============================] - 0s 101us/sample - loss: 5.6147 - AUC: 0.9151 - val_loss: 5.9649 - val_AUC: 0.6265\n",
      "Epoch 281/500\n",
      "2277/2277 [==============================] - 0s 101us/sample - loss: 5.6096 - AUC: 0.9162 - val_loss: 5.9470 - val_AUC: 0.6316\n",
      "Epoch 282/500\n",
      "2277/2277 [==============================] - 0s 100us/sample - loss: 5.5940 - AUC: 0.9180 - val_loss: 5.9389 - val_AUC: 0.6310\n",
      "Epoch 283/500\n",
      "2277/2277 [==============================] - 0s 100us/sample - loss: 5.5765 - AUC: 0.9263 - val_loss: 5.9391 - val_AUC: 0.6288\n",
      "Epoch 284/500\n",
      "2277/2277 [==============================] - 0s 102us/sample - loss: 5.5830 - AUC: 0.9177 - val_loss: 5.9284 - val_AUC: 0.6320\n",
      "Epoch 285/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.5846 - AUC: 0.9117 - val_loss: 5.9119 - val_AUC: 0.6290\n",
      "Epoch 286/500\n",
      "2277/2277 [==============================] - 0s 102us/sample - loss: 5.5569 - AUC: 0.9245 - val_loss: 5.9126 - val_AUC: 0.6240\n",
      "Epoch 287/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.5695 - AUC: 0.9119 - val_loss: 5.9002 - val_AUC: 0.6320\n",
      "Epoch 288/500\n",
      "2277/2277 [==============================] - 0s 99us/sample - loss: 5.5537 - AUC: 0.9183 - val_loss: 5.9015 - val_AUC: 0.6239\n",
      "Epoch 289/500\n",
      "2277/2277 [==============================] - 0s 99us/sample - loss: 5.5372 - AUC: 0.9222 - val_loss: 5.9004 - val_AUC: 0.6305\n",
      "Epoch 290/500\n",
      "2277/2277 [==============================] - 0s 100us/sample - loss: 5.5246 - AUC: 0.9272 - val_loss: 5.8964 - val_AUC: 0.6314\n",
      "Epoch 291/500\n",
      "2277/2277 [==============================] - 0s 100us/sample - loss: 5.5236 - AUC: 0.9214 - val_loss: 5.8796 - val_AUC: 0.6278\n",
      "Epoch 292/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 5.5124 - AUC: 0.9235 - val_loss: 5.8710 - val_AUC: 0.6275\n",
      "Epoch 293/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.5141 - AUC: 0.9189 - val_loss: 5.8646 - val_AUC: 0.6320\n",
      "Epoch 294/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 5.4963 - AUC: 0.9249 - val_loss: 5.8570 - val_AUC: 0.6282\n",
      "Epoch 295/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 5.5006 - AUC: 0.9178 - val_loss: 5.8527 - val_AUC: 0.6303\n",
      "Epoch 296/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 5.4824 - AUC: 0.9263 - val_loss: 5.8442 - val_AUC: 0.6307\n",
      "Epoch 297/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 5.4735 - AUC: 0.9234 - val_loss: 5.8399 - val_AUC: 0.6282\n",
      "Epoch 298/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 5.4699 - AUC: 0.9227 - val_loss: 5.8286 - val_AUC: 0.6302\n",
      "Epoch 299/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.4421 - AUC: 0.9353 - val_loss: 5.8184 - val_AUC: 0.6308\n",
      "Epoch 300/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.4486 - AUC: 0.9265 - val_loss: 5.8090 - val_AUC: 0.6296\n",
      "Epoch 301/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.4402 - AUC: 0.9278 - val_loss: 5.8156 - val_AUC: 0.6314\n",
      "Epoch 302/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 5.4371 - AUC: 0.9249 - val_loss: 5.8078 - val_AUC: 0.6280\n",
      "Epoch 303/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.4286 - AUC: 0.9281 - val_loss: 5.7981 - val_AUC: 0.6284\n",
      "Epoch 304/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.4178 - AUC: 0.9274 - val_loss: 5.7916 - val_AUC: 0.6294\n",
      "Epoch 305/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 5.4121 - AUC: 0.9265 - val_loss: 5.7818 - val_AUC: 0.6280\n",
      "Epoch 306/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.4154 - AUC: 0.9219 - val_loss: 5.7788 - val_AUC: 0.6273\n",
      "Epoch 307/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 5.3916 - AUC: 0.9310 - val_loss: 5.7663 - val_AUC: 0.6300\n",
      "Epoch 308/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.3886 - AUC: 0.9292 - val_loss: 5.7678 - val_AUC: 0.6308\n",
      "Epoch 309/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.3918 - AUC: 0.9213 - val_loss: 5.7653 - val_AUC: 0.6305\n",
      "Epoch 310/500\n",
      "2277/2277 [==============================] - 0s 102us/sample - loss: 5.3672 - AUC: 0.9311 - val_loss: 5.7511 - val_AUC: 0.6322\n",
      "Epoch 311/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 5.3592 - AUC: 0.9316 - val_loss: 5.7423 - val_AUC: 0.6300\n",
      "Epoch 312/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 5.3597 - AUC: 0.9283 - val_loss: 5.7343 - val_AUC: 0.6334\n",
      "Epoch 313/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.3455 - AUC: 0.9315 - val_loss: 5.7286 - val_AUC: 0.6343\n",
      "Epoch 314/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.3360 - AUC: 0.9331 - val_loss: 5.7283 - val_AUC: 0.6324\n",
      "Epoch 315/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.3379 - AUC: 0.9283 - val_loss: 5.7147 - val_AUC: 0.6365\n",
      "Epoch 316/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.3217 - AUC: 0.9328 - val_loss: 5.7114 - val_AUC: 0.6339\n",
      "Epoch 317/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 5.3188 - AUC: 0.9297 - val_loss: 5.7014 - val_AUC: 0.6333\n",
      "Epoch 318/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 5.3168 - AUC: 0.9266 - val_loss: 5.6943 - val_AUC: 0.6345\n",
      "Epoch 319/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 5.2904 - AUC: 0.9404 - val_loss: 5.6863 - val_AUC: 0.6359\n",
      "Epoch 320/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.2864 - AUC: 0.9362 - val_loss: 5.6890 - val_AUC: 0.6317\n",
      "Epoch 321/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 5.2721 - AUC: 0.9413 - val_loss: 5.6725 - val_AUC: 0.6312\n",
      "Epoch 322/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.2797 - AUC: 0.9316 - val_loss: 5.6753 - val_AUC: 0.6358\n",
      "Epoch 323/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.2676 - AUC: 0.9349 - val_loss: 5.6566 - val_AUC: 0.6333\n",
      "Epoch 324/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 5.2533 - AUC: 0.9388 - val_loss: 5.6562 - val_AUC: 0.6335\n",
      "Epoch 325/500\n",
      "2277/2277 [==============================] - 0s 113us/sample - loss: 5.2455 - AUC: 0.9392 - val_loss: 5.6502 - val_AUC: 0.6346\n",
      "Epoch 326/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 5.2375 - AUC: 0.9382 - val_loss: 5.6402 - val_AUC: 0.6296\n",
      "Epoch 327/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 5.2351 - AUC: 0.9361 - val_loss: 5.6347 - val_AUC: 0.6324\n",
      "Epoch 328/500\n",
      "2277/2277 [==============================] - 0s 114us/sample - loss: 5.2215 - AUC: 0.9400 - val_loss: 5.6280 - val_AUC: 0.6339\n",
      "Epoch 329/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 5.2249 - AUC: 0.9339 - val_loss: 5.6255 - val_AUC: 0.6312\n",
      "Epoch 330/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 5.2144 - AUC: 0.9364 - val_loss: 5.6164 - val_AUC: 0.6358\n",
      "Epoch 331/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.2059 - AUC: 0.9362 - val_loss: 5.6077 - val_AUC: 0.6349\n",
      "Epoch 332/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.1943 - AUC: 0.9403 - val_loss: 5.6062 - val_AUC: 0.6363\n",
      "Epoch 333/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.1981 - AUC: 0.9329 - val_loss: 5.5993 - val_AUC: 0.6319\n",
      "Epoch 334/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 5.1829 - AUC: 0.9373 - val_loss: 5.5901 - val_AUC: 0.6316\n",
      "Epoch 335/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 5.1570 - AUC: 0.9481 - val_loss: 5.5844 - val_AUC: 0.6355\n",
      "Epoch 336/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 5.1695 - AUC: 0.9375 - val_loss: 5.5772 - val_AUC: 0.6354\n",
      "Epoch 337/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 5.1538 - AUC: 0.9407 - val_loss: 5.5684 - val_AUC: 0.6360\n",
      "Epoch 338/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.1441 - AUC: 0.9435 - val_loss: 5.5601 - val_AUC: 0.6362\n",
      "Epoch 339/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.1277 - AUC: 0.9485 - val_loss: 5.5603 - val_AUC: 0.6323\n",
      "Epoch 340/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.1190 - AUC: 0.9479 - val_loss: 5.5429 - val_AUC: 0.6343\n",
      "Epoch 341/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.1268 - AUC: 0.9392 - val_loss: 5.5474 - val_AUC: 0.6332\n",
      "Epoch 342/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.1076 - AUC: 0.9469 - val_loss: 5.5346 - val_AUC: 0.6368\n",
      "Epoch 343/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 5.1053 - AUC: 0.9441 - val_loss: 5.5321 - val_AUC: 0.6333\n",
      "Epoch 344/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 5.0949 - AUC: 0.9461 - val_loss: 5.5287 - val_AUC: 0.6362\n",
      "Epoch 345/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 5.0949 - AUC: 0.9414 - val_loss: 5.5181 - val_AUC: 0.6351\n",
      "Epoch 346/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.0927 - AUC: 0.9398 - val_loss: 5.5046 - val_AUC: 0.6343\n",
      "Epoch 347/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 5.0800 - AUC: 0.9409 - val_loss: 5.5045 - val_AUC: 0.6339\n",
      "Epoch 348/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 5.0737 - AUC: 0.9426 - val_loss: 5.4952 - val_AUC: 0.6360\n",
      "Epoch 349/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 5.0572 - AUC: 0.9462 - val_loss: 5.4906 - val_AUC: 0.6349\n",
      "Epoch 350/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.0416 - AUC: 0.9508 - val_loss: 5.4859 - val_AUC: 0.6330\n",
      "Epoch 351/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.0471 - AUC: 0.9449 - val_loss: 5.4797 - val_AUC: 0.6367\n",
      "Epoch 352/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 5.0305 - AUC: 0.9502 - val_loss: 5.4752 - val_AUC: 0.6389\n",
      "Epoch 353/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 5.0331 - AUC: 0.9464 - val_loss: 5.4652 - val_AUC: 0.6329\n",
      "Epoch 354/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.0291 - AUC: 0.9423 - val_loss: 5.4575 - val_AUC: 0.6353\n",
      "Epoch 355/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 5.0113 - AUC: 0.9485 - val_loss: 5.4446 - val_AUC: 0.6350\n",
      "Epoch 356/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 5.0115 - AUC: 0.9436 - val_loss: 5.4479 - val_AUC: 0.6348\n",
      "Epoch 357/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.9997 - AUC: 0.9469 - val_loss: 5.4398 - val_AUC: 0.6335\n",
      "Epoch 358/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.9916 - AUC: 0.9479 - val_loss: 5.4389 - val_AUC: 0.6376\n",
      "Epoch 359/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.9740 - AUC: 0.9522 - val_loss: 5.4305 - val_AUC: 0.6329\n",
      "Epoch 360/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.9723 - AUC: 0.9500 - val_loss: 5.4204 - val_AUC: 0.6293\n",
      "Epoch 361/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.9647 - AUC: 0.9517 - val_loss: 5.4073 - val_AUC: 0.6321\n",
      "Epoch 362/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 4.9599 - AUC: 0.9482 - val_loss: 5.4216 - val_AUC: 0.6320\n",
      "Epoch 363/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 4.9561 - AUC: 0.9471 - val_loss: 5.4125 - val_AUC: 0.6307\n",
      "Epoch 364/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 4.9470 - AUC: 0.9484 - val_loss: 5.3957 - val_AUC: 0.6329\n",
      "Epoch 365/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 4.9337 - AUC: 0.9518 - val_loss: 5.3857 - val_AUC: 0.6368\n",
      "Epoch 366/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 4.9189 - AUC: 0.9555 - val_loss: 5.3875 - val_AUC: 0.6335\n",
      "Epoch 367/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.9238 - AUC: 0.9500 - val_loss: 5.3780 - val_AUC: 0.6331\n",
      "Epoch 368/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.9187 - AUC: 0.9478 - val_loss: 5.3681 - val_AUC: 0.6336\n",
      "Epoch 369/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.9046 - AUC: 0.9518 - val_loss: 5.3582 - val_AUC: 0.6355\n",
      "Epoch 370/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.8914 - AUC: 0.9553 - val_loss: 5.3503 - val_AUC: 0.6301\n",
      "Epoch 371/500\n",
      "2277/2277 [==============================] - 0s 101us/sample - loss: 4.8913 - AUC: 0.9527 - val_loss: 5.3540 - val_AUC: 0.6329\n",
      "Epoch 372/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.8857 - AUC: 0.9517 - val_loss: 5.3493 - val_AUC: 0.6355\n",
      "Epoch 373/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.8810 - AUC: 0.9497 - val_loss: 5.3377 - val_AUC: 0.6340\n",
      "Epoch 374/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.8624 - AUC: 0.9556 - val_loss: 5.3327 - val_AUC: 0.6332\n",
      "Epoch 375/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.8472 - AUC: 0.9592 - val_loss: 5.3304 - val_AUC: 0.6324\n",
      "Epoch 376/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.8501 - AUC: 0.9551 - val_loss: 5.3275 - val_AUC: 0.6340\n",
      "Epoch 377/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.8432 - AUC: 0.9545 - val_loss: 5.3129 - val_AUC: 0.6352\n",
      "Epoch 378/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.8318 - AUC: 0.9575 - val_loss: 5.3133 - val_AUC: 0.6344\n",
      "Epoch 379/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.8183 - AUC: 0.9588 - val_loss: 5.3040 - val_AUC: 0.6317\n",
      "Epoch 380/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.8078 - AUC: 0.9614 - val_loss: 5.2928 - val_AUC: 0.6328\n",
      "Epoch 381/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.8117 - AUC: 0.9563 - val_loss: 5.2882 - val_AUC: 0.6355\n",
      "Epoch 382/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.8105 - AUC: 0.9539 - val_loss: 5.2908 - val_AUC: 0.6329\n",
      "Epoch 383/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.7812 - AUC: 0.9638 - val_loss: 5.2838 - val_AUC: 0.6288\n",
      "Epoch 384/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 4.7864 - AUC: 0.9593 - val_loss: 5.2706 - val_AUC: 0.6310\n",
      "Epoch 385/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.7810 - AUC: 0.9575 - val_loss: 5.2693 - val_AUC: 0.6320\n",
      "Epoch 386/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.7741 - AUC: 0.9577 - val_loss: 5.2655 - val_AUC: 0.6290\n",
      "Epoch 387/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.7826 - AUC: 0.9503 - val_loss: 5.2505 - val_AUC: 0.6315\n",
      "Epoch 388/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.7630 - AUC: 0.9558 - val_loss: 5.2453 - val_AUC: 0.6327\n",
      "Epoch 389/500\n",
      "2277/2277 [==============================] - 0s 111us/sample - loss: 4.7536 - AUC: 0.9574 - val_loss: 5.2406 - val_AUC: 0.6311\n",
      "Epoch 390/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.7360 - AUC: 0.9626 - val_loss: 5.2354 - val_AUC: 0.6282\n",
      "Epoch 391/500\n",
      "2277/2277 [==============================] - 0s 102us/sample - loss: 4.7251 - AUC: 0.9652 - val_loss: 5.2376 - val_AUC: 0.6319\n",
      "Epoch 392/500\n",
      "2277/2277 [==============================] - 0s 100us/sample - loss: 4.7310 - AUC: 0.9580 - val_loss: 5.2234 - val_AUC: 0.6339\n",
      "Epoch 393/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.7107 - AUC: 0.9652 - val_loss: 5.2141 - val_AUC: 0.6354\n",
      "Epoch 394/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.7176 - AUC: 0.9576 - val_loss: 5.2221 - val_AUC: 0.6325\n",
      "Epoch 395/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.7078 - AUC: 0.9584 - val_loss: 5.1987 - val_AUC: 0.6341\n",
      "Epoch 396/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.6931 - AUC: 0.9620 - val_loss: 5.2036 - val_AUC: 0.6328\n",
      "Epoch 397/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.6956 - AUC: 0.9591 - val_loss: 5.2003 - val_AUC: 0.6295\n",
      "Epoch 398/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.6898 - AUC: 0.9569 - val_loss: 5.1847 - val_AUC: 0.6356\n",
      "Epoch 399/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.6874 - AUC: 0.9549 - val_loss: 5.1803 - val_AUC: 0.6333\n",
      "Epoch 400/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.6681 - AUC: 0.9624 - val_loss: 5.1793 - val_AUC: 0.6328\n",
      "Epoch 401/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.6609 - AUC: 0.9617 - val_loss: 5.1689 - val_AUC: 0.6306\n",
      "Epoch 402/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.6500 - AUC: 0.9632 - val_loss: 5.1678 - val_AUC: 0.6311\n",
      "Epoch 403/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.6463 - AUC: 0.9624 - val_loss: 5.1625 - val_AUC: 0.6318\n",
      "Epoch 404/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.6281 - AUC: 0.9665 - val_loss: 5.1565 - val_AUC: 0.6302\n",
      "Epoch 405/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.6288 - AUC: 0.9634 - val_loss: 5.1447 - val_AUC: 0.6319\n",
      "Epoch 406/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.6327 - AUC: 0.9592 - val_loss: 5.1442 - val_AUC: 0.6302\n",
      "Epoch 407/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 4.6188 - AUC: 0.9632 - val_loss: 5.1421 - val_AUC: 0.6289\n",
      "Epoch 408/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.6142 - AUC: 0.9604 - val_loss: 5.1273 - val_AUC: 0.6285\n",
      "Epoch 409/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.6067 - AUC: 0.9621 - val_loss: 5.1214 - val_AUC: 0.6314\n",
      "Epoch 410/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.5974 - AUC: 0.9629 - val_loss: 5.1284 - val_AUC: 0.6283\n",
      "Epoch 411/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.5832 - AUC: 0.9665 - val_loss: 5.1131 - val_AUC: 0.6292\n",
      "Epoch 412/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.5919 - AUC: 0.9599 - val_loss: 5.1076 - val_AUC: 0.6297\n",
      "Epoch 413/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.5807 - AUC: 0.9606 - val_loss: 5.1105 - val_AUC: 0.6292\n",
      "Epoch 414/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.5692 - AUC: 0.9644 - val_loss: 5.0898 - val_AUC: 0.6311\n",
      "Epoch 415/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.5510 - AUC: 0.9688 - val_loss: 5.0896 - val_AUC: 0.6322\n",
      "Epoch 416/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.5510 - AUC: 0.9648 - val_loss: 5.0667 - val_AUC: 0.6348\n",
      "Epoch 417/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.5432 - AUC: 0.9670 - val_loss: 5.0705 - val_AUC: 0.6320\n",
      "Epoch 418/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.5372 - AUC: 0.9648 - val_loss: 5.0727 - val_AUC: 0.6331\n",
      "Epoch 419/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.5304 - AUC: 0.9645 - val_loss: 5.0619 - val_AUC: 0.6321\n",
      "Epoch 420/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.5230 - AUC: 0.9670 - val_loss: 5.0549 - val_AUC: 0.6347\n",
      "Epoch 421/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.5151 - AUC: 0.9657 - val_loss: 5.0486 - val_AUC: 0.6342\n",
      "Epoch 422/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.5108 - AUC: 0.9656 - val_loss: 5.0399 - val_AUC: 0.6338\n",
      "Epoch 423/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.5015 - AUC: 0.9658 - val_loss: 5.0391 - val_AUC: 0.6363\n",
      "Epoch 424/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.4959 - AUC: 0.9667 - val_loss: 5.0428 - val_AUC: 0.6362\n",
      "Epoch 425/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.4827 - AUC: 0.9683 - val_loss: 5.0248 - val_AUC: 0.6336\n",
      "Epoch 426/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.4753 - AUC: 0.9683 - val_loss: 5.0071 - val_AUC: 0.6342\n",
      "Epoch 427/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.4567 - AUC: 0.9746 - val_loss: 5.0177 - val_AUC: 0.6320\n",
      "Epoch 428/500\n",
      "2277/2277 [==============================] - 0s 101us/sample - loss: 4.4610 - AUC: 0.9688 - val_loss: 5.0100 - val_AUC: 0.6307\n",
      "Epoch 429/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.4447 - AUC: 0.9730 - val_loss: 5.0109 - val_AUC: 0.6339\n",
      "Epoch 430/500\n",
      "2277/2277 [==============================] - 0s 101us/sample - loss: 4.4573 - AUC: 0.9657 - val_loss: 5.0232 - val_AUC: 0.6322\n",
      "Epoch 431/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 4.4373 - AUC: 0.9694 - val_loss: 5.0031 - val_AUC: 0.6314\n",
      "Epoch 432/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.4343 - AUC: 0.9692 - val_loss: 4.9895 - val_AUC: 0.6303\n",
      "Epoch 433/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.4366 - AUC: 0.9650 - val_loss: 4.9746 - val_AUC: 0.6311\n",
      "Epoch 434/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.4090 - AUC: 0.9739 - val_loss: 4.9780 - val_AUC: 0.6318\n",
      "Epoch 435/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.4106 - AUC: 0.9708 - val_loss: 4.9684 - val_AUC: 0.6329\n",
      "Epoch 436/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.4047 - AUC: 0.9699 - val_loss: 4.9555 - val_AUC: 0.6321\n",
      "Epoch 437/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.4023 - AUC: 0.9696 - val_loss: 4.9630 - val_AUC: 0.6342\n",
      "Epoch 438/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.4027 - AUC: 0.9665 - val_loss: 4.9585 - val_AUC: 0.6312\n",
      "Epoch 439/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.3912 - AUC: 0.9682 - val_loss: 4.9494 - val_AUC: 0.6291\n",
      "Epoch 440/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.3731 - AUC: 0.9723 - val_loss: 4.9444 - val_AUC: 0.6334\n",
      "Epoch 441/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.3675 - AUC: 0.9721 - val_loss: 4.9257 - val_AUC: 0.6339\n",
      "Epoch 442/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 4.3659 - AUC: 0.9705 - val_loss: 4.9171 - val_AUC: 0.6317\n",
      "Epoch 443/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.3486 - AUC: 0.9756 - val_loss: 4.9232 - val_AUC: 0.6335\n",
      "Epoch 444/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.3547 - AUC: 0.9693 - val_loss: 4.9233 - val_AUC: 0.6321\n",
      "Epoch 445/500\n",
      "2277/2277 [==============================] - 0s 102us/sample - loss: 4.3399 - AUC: 0.9735 - val_loss: 4.9175 - val_AUC: 0.6316\n",
      "Epoch 446/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.3345 - AUC: 0.9725 - val_loss: 4.9052 - val_AUC: 0.6319\n",
      "Epoch 447/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.3352 - AUC: 0.9687 - val_loss: 4.9074 - val_AUC: 0.6317\n",
      "Epoch 448/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.3225 - AUC: 0.9718 - val_loss: 4.9003 - val_AUC: 0.6305\n",
      "Epoch 449/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.3090 - AUC: 0.9745 - val_loss: 4.8942 - val_AUC: 0.6311\n",
      "Epoch 450/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.2956 - AUC: 0.9788 - val_loss: 4.8827 - val_AUC: 0.6292\n",
      "Epoch 451/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.2948 - AUC: 0.9754 - val_loss: 4.8756 - val_AUC: 0.6305\n",
      "Epoch 452/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.2993 - AUC: 0.9711 - val_loss: 4.8610 - val_AUC: 0.6333\n",
      "Epoch 453/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.3025 - AUC: 0.9676 - val_loss: 4.8723 - val_AUC: 0.6344\n",
      "Epoch 454/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.2784 - AUC: 0.9738 - val_loss: 4.8619 - val_AUC: 0.6326\n",
      "Epoch 455/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.2797 - AUC: 0.9705 - val_loss: 4.8740 - val_AUC: 0.6312\n",
      "Epoch 456/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.2531 - AUC: 0.9790 - val_loss: 4.8503 - val_AUC: 0.6306\n",
      "Epoch 457/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.2589 - AUC: 0.9744 - val_loss: 4.8424 - val_AUC: 0.6326\n",
      "Epoch 458/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.2501 - AUC: 0.9742 - val_loss: 4.8567 - val_AUC: 0.6317\n",
      "Epoch 459/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.2544 - AUC: 0.9700 - val_loss: 4.8431 - val_AUC: 0.6315\n",
      "Epoch 460/500\n",
      "2277/2277 [==============================] - 0s 112us/sample - loss: 4.2515 - AUC: 0.9693 - val_loss: 4.8348 - val_AUC: 0.6311\n",
      "Epoch 461/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.2352 - AUC: 0.9727 - val_loss: 4.8197 - val_AUC: 0.6353\n",
      "Epoch 462/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.2307 - AUC: 0.9722 - val_loss: 4.8234 - val_AUC: 0.6312\n",
      "Epoch 463/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.2198 - AUC: 0.9740 - val_loss: 4.8119 - val_AUC: 0.6317\n",
      "Epoch 464/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.2074 - AUC: 0.9760 - val_loss: 4.8082 - val_AUC: 0.6333\n",
      "Epoch 465/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 4.2072 - AUC: 0.9742 - val_loss: 4.8049 - val_AUC: 0.6321\n",
      "Epoch 466/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.1978 - AUC: 0.9746 - val_loss: 4.8006 - val_AUC: 0.6334\n",
      "Epoch 467/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.2003 - AUC: 0.9710 - val_loss: 4.7926 - val_AUC: 0.6333\n",
      "Epoch 468/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.1869 - AUC: 0.9742 - val_loss: 4.7752 - val_AUC: 0.6333\n",
      "Epoch 469/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.1692 - AUC: 0.9792 - val_loss: 4.7854 - val_AUC: 0.6329\n",
      "Epoch 470/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.1706 - AUC: 0.9746 - val_loss: 4.7838 - val_AUC: 0.6335\n",
      "Epoch 471/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.1548 - AUC: 0.9782 - val_loss: 4.7829 - val_AUC: 0.6320\n",
      "Epoch 472/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 4.1595 - AUC: 0.9746 - val_loss: 4.7597 - val_AUC: 0.6330\n",
      "Epoch 473/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 4.1493 - AUC: 0.9762 - val_loss: 4.7625 - val_AUC: 0.6337\n",
      "Epoch 474/500\n",
      "2277/2277 [==============================] - 0s 110us/sample - loss: 4.1451 - AUC: 0.9761 - val_loss: 4.7406 - val_AUC: 0.6357\n",
      "Epoch 475/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.1250 - AUC: 0.9798 - val_loss: 4.7450 - val_AUC: 0.6336\n",
      "Epoch 476/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.1275 - AUC: 0.9780 - val_loss: 4.7468 - val_AUC: 0.6328\n",
      "Epoch 477/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.1241 - AUC: 0.9757 - val_loss: 4.7381 - val_AUC: 0.6335\n",
      "Epoch 478/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.1101 - AUC: 0.9788 - val_loss: 4.7262 - val_AUC: 0.6341\n",
      "Epoch 479/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.1038 - AUC: 0.9792 - val_loss: 4.7277 - val_AUC: 0.6355\n",
      "Epoch 480/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.1054 - AUC: 0.9759 - val_loss: 4.7171 - val_AUC: 0.6342\n",
      "Epoch 481/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.1018 - AUC: 0.9744 - val_loss: 4.7154 - val_AUC: 0.6367\n",
      "Epoch 482/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.1004 - AUC: 0.9733 - val_loss: 4.7140 - val_AUC: 0.6354\n",
      "Epoch 483/500\n",
      "2277/2277 [==============================] - 0s 109us/sample - loss: 4.0754 - AUC: 0.9792 - val_loss: 4.7044 - val_AUC: 0.6327\n",
      "Epoch 484/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.0815 - AUC: 0.9753 - val_loss: 4.6932 - val_AUC: 0.6366\n",
      "Epoch 485/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.0687 - AUC: 0.9789 - val_loss: 4.6890 - val_AUC: 0.6352\n",
      "Epoch 486/500\n",
      "2277/2277 [==============================] - 0s 108us/sample - loss: 4.0487 - AUC: 0.9837 - val_loss: 4.6857 - val_AUC: 0.6367\n",
      "Epoch 487/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.0578 - AUC: 0.9762 - val_loss: 4.6758 - val_AUC: 0.6372\n",
      "Epoch 488/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.0501 - AUC: 0.9781 - val_loss: 4.6818 - val_AUC: 0.6353\n",
      "Epoch 489/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.0375 - AUC: 0.9804 - val_loss: 4.6709 - val_AUC: 0.6335\n",
      "Epoch 490/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.0291 - AUC: 0.9816 - val_loss: 4.6634 - val_AUC: 0.6345\n",
      "Epoch 491/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 4.0331 - AUC: 0.9775 - val_loss: 4.6493 - val_AUC: 0.6351\n",
      "Epoch 492/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.0129 - AUC: 0.9812 - val_loss: 4.6613 - val_AUC: 0.6362\n",
      "Epoch 493/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 4.0178 - AUC: 0.9787 - val_loss: 4.6358 - val_AUC: 0.6373\n",
      "Epoch 494/500\n",
      "2277/2277 [==============================] - 0s 103us/sample - loss: 4.0096 - AUC: 0.9784 - val_loss: 4.6573 - val_AUC: 0.6382\n",
      "Epoch 495/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 4.0062 - AUC: 0.9782 - val_loss: 4.6516 - val_AUC: 0.6334\n",
      "Epoch 496/500\n",
      "2277/2277 [==============================] - 0s 106us/sample - loss: 3.9969 - AUC: 0.9790 - val_loss: 4.6222 - val_AUC: 0.6354\n",
      "Epoch 497/500\n",
      "2277/2277 [==============================] - 0s 107us/sample - loss: 3.9821 - AUC: 0.9812 - val_loss: 4.6259 - val_AUC: 0.6383\n",
      "Epoch 498/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 3.9842 - AUC: 0.9792 - val_loss: 4.6392 - val_AUC: 0.6360\n",
      "Epoch 499/500\n",
      "2277/2277 [==============================] - 0s 104us/sample - loss: 3.9765 - AUC: 0.9792 - val_loss: 4.6134 - val_AUC: 0.6378\n",
      "Epoch 500/500\n",
      "2277/2277 [==============================] - 0s 105us/sample - loss: 3.9735 - AUC: 0.9788 - val_loss: 4.6097 - val_AUC: 0.6366\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, y, validation_data=(xv, yv),\n",
    "                 callbacks=[early_stop],\n",
    "                 epochs=500, batch_size=80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4d12161-b0ac-4f76-9f94-40f4f9002d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1fcb1b-15f9-491e-aef7-60504781bf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789815817984833"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(yt,model.predict(xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7795332b-b697-4cd1-8e47-4516335e20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.where(model.predict(xt)>0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93e920cb-4b9f-46d1-b08b-908298fea8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_savey = pd.DataFrame(data={'smiles':list(x_smiles)})\n",
    "df_savey['y']=pred\n",
    "df_savey.to_csv('output_classification_hep_nn.csv',index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc41dd9-a77c-452a-aad8-446c9c591ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
